<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · MicrostructureNoise.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MicrostructureNoise.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"><li><a class="toctext" href="#Example-1">Example</a></li><li><a class="toctext" href="#Library-1">Library</a></li><li><a class="toctext" href="#Contribute-1">Contribute</a></li><li><a class="toctext" href="#References-1">References</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="MicrostructureNoise.jl-1" href="#MicrostructureNoise.jl-1">MicrostructureNoise.jl</a></h1><p><code>MicrostructureNoise</code> is a Julia package for Bayesian volatility estimation in presence of market microstructure noise. The underlying model is the stochastic differential equation </p><p>$ dX<em>t=b(t,X</em>t)\,dt + s(t)\,d W<em>t, \quad X</em>0=x_0, \quad t\in [0,T] .$</p><p>The estimation method is minimalistic in its assumptions on the volatility function <span>$s$</span>, which in particular can be a stochastic process. The process <span>$X$</span> is latent: observed is its noisy version on a discrete time grid,</p><p>$ Y<em>{i}=X</em>{t<em>{i}}+V</em>{i}, \quad 0&lt;t<em>1&lt;\cdots&lt;t</em>n=T.$</p><p>Here <span>$\{ V_i \}$</span> denote unobservable stochastic disturbances, and <span>$n$</span> is the total number of observations.</p><p>For data <span>$\{Y_i\}$</span> that are densely spaced in time, the drift function <span>$b$</span> has little effect on estimation accuracy of the volatility function <span>$s$</span>, and can be set to zero. This reduces the original model to the linear state space model, and statistical tools developed for the latter can be used to infer the unknown volatility. The posterior inference is performed via the Gibbs sampler, and relies on Kalman filtering ideas to reconstruct unobservable states <span>$\{X(t_i)\}$</span>.</p><p>Essential details of the procedure are as follows: The unknown squared volatility function <span>$s^2$</span> is a priori modelled as piecewise constant: Fix an integer <span>$m&lt;n$</span>. Then a unique decomposition <span>$n=mN+r$</span> with <span>$0\leq r&lt;m$</span> holds, where <span>$N=\lfloor {n}/{m}\rfloor$</span>. Now define bins <span>$B_k=[t_{m(k-1)},t_{mk})$</span>, <span>$k=1,\ldots,N-1$</span>, and <span>$B_N=[t_{m(N-1)},T]$</span>. The number <span>$N$</span> of bins is a hyperparameter. Let <span>$s$</span> be piecewise constant on bins <span>$B_k$</span>, so that</p><p>$ s^2=\sum<em>{k=1}^{N} \theta</em>k \mathbf{1}<em>{B</em>k}.$</p><p>The coefficients <span>$\{ \theta_k \}$</span> are assigned the inverse Gamma Markov chain prior, which induces smoothing among adjacent pieces of the function <span>$s^2$</span>. This prior is governed by the smoothing hyperparameter <span>$\alpha$</span>, which in turn is equipped with a hyperprior. The errors <span>$\{V_i\}$</span> are assumed to follow the Gaussian distribution with mean zero and variance <span>$\eta$</span>. The Bayesian model specification is completed by assigning the noise level <span>$\eta$</span> the inverse Gamma prior, and equipping the initial state <span>$X_0$</span> with the Gaussian prior. To sample from the joint posterior of the vector <span>$\{\theta_k\}$</span>, the noise level <span>$\eta$</span> and the smoothing hyperparameter <span>$\alpha$</span>, the Gibbs sampler is used. In each cycle of the sampler, the unobservable state vector <span>$\{X(t_i)\}$</span> is drawn from its full conditional distribution using the Forward Filtering Backward Simulation algorithm; this employs Kalman filter recursions in the forward pass.</p><p>Synthetic data examples show that the procedure adapts well to the unknown smoothness of the volatility <span>$s$</span>.</p><p>See the referenced article for additional details on prior specification, implementation, and numerical experiments.</p><h2><a class="nav-anchor" id="Example-1" href="#Example-1">Example</a></h2><pre><code class="language-none">using MicrostructureNoise, Distributions
# downloads a large file 
Base.download(&quot;https://www.truefx.com/dev/data//2015/MARCH-2015/EURUSD-2015-03.zip&quot;,&quot;./data/EURUSD-2015-03.zip&quot;)
run(`unzip ./data/EURUSD-2015-03.zip -d ./data`)
dat = readcsv(&quot;./data/EURUSD-2015-03.csv&quot;)
times = map(a -&gt; DateTime(a, &quot;yyyymmdd H:M:S.s&quot;), dat[1:10:130260,2])
tt = Float64[1/1000*(times[i].instant.periods.value-times[1].instant.periods.value) for i in 1:length(times)]
n = length(tt)-1
T = tt[end]
y = Float64.(dat[1:10:130260, 3])

prior = MicrostructureNoise.Prior(
N = 40,

α1 = 0.0,
β1 = 0.0,

αη = 0.3, 
βη = 0.3,

Πα = LogNormal(1., 0.5),
μ0 = 0.0,
C0 = 5.0
)

α = 0.3
σα = 0.1
td, θs, ηs, αs, p = MicrostructureNoise.MCMC(prior, tt, y, α, σα, 1500)

posterior = MicrostructureNoise.posterior_volatility(td, θs)</code></pre><h2><a class="nav-anchor" id="Library-1" href="#Library-1">Library</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MicrostructureNoise.Prior" href="#MicrostructureNoise.Prior"><code>MicrostructureNoise.Prior</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">MicrostructureNoise.Prior(; N, α1, β1, αη, βη, Πα, μ0, C0)
MicrostructureNoise.Prior(; kwargs...)</code></pre><p>Struct holding prior distribution parameters. <code>N</code> is the number of bins,  <code>InverseGamma(α1, β1)</code> is the prior of <code>θ[1]</code> on the first bin, the prior on the noise variance <code>η</code> is <code>InverseGamma(αη, βη)</code>, the hidden state <span>$X_0$</span> at start time is <code>Normal(μ0, C0)</code>,  and <code>Πα</code> is a prior <code>Distribution</code> for <code>α</code>,  for example <code>Πα = LogNormal(1., 0.5)</code>.</p><p>Note: All keyword arguments <code>N, α1, β1, αη, βη, Πα, μ0, C0</code> are mandatory.</p><p>Example:</p><pre><code class="language-none">prior = MicrostructureNoise.Prior(
N = 40, # number of bins

α1 = 0.0, # prior for the first bin
β1 = 0.0,

αη = 0.3, # noise variance prior InverseGamma(αη, βη)
βη = 0.3,

Πα = LogNormal(1., 0.5),
μ0 = 0.0,
C0 = 5.0
)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MicrostructureNoise.MCMC" href="#MicrostructureNoise.MCMC"><code>MicrostructureNoise.MCMC</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">MCMC(Π::Union{Prior,Dict}, t, y, α0::Float64, σα, iterations; 
    subinds = 1:1:iterations, η0::Float64 = 0.0, printiter = 100,
    fixalpha = false, fixeta = false, skipfirst = false) -&gt; td, θ, ηs, αs, pacc</code></pre><p>Run the Markov Chain Monte Carlo procedure for <code>iterations</code> iterations, on data <code>(t, y)</code>, where <code>t</code> are observation times and <code>y</code> are observations. <code>α0</code> is the initial guess for the smoothing parameter <code>α</code> (necessary), <code>η0</code> is the initial guess for the noise variance (optional), and <code>σα</code> is the stepsize for the random walk proposal for <code>α</code>.</p><p>Prints verbose output every <code>printiter</code> iteration.</p><p>Returns <code>td, θs, ηs, αs, pacc</code>, <code>td</code> is the time grid of the bin boundaries, <code>ηs</code>, <code>αs</code> are vectors of iterates, possible subsampled at indices <code>subinds</code>, <code>θs</code> is a Matrix with iterates of <code>θ</code> rows. <code>paccα</code> is the acceptance probability for the update step of <code>α</code>.</p><p><code>y[i]</code> is the observation at <code>t[i]</code>.</p><p>If <code>skipfirst = true</code> and <code>t</code> and <code>y</code> are of equal length, the observation <code>y[1]</code> (corresponding to <code>t[1]</code>) is ignored.</p><p>If <code>skipfirst = true</code> and <code>length(t) = length(y) + 1</code>,  <code>y[i]</code> is the observation at <code>t[i + 1]</code>.</p><p>Keyword args <code>fixalpha</code>, <code>fixeta</code> when set to <code>true</code> allow fixing <code>α</code> and <code>η</code> at their initial values. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MicrostructureNoise.Posterior" href="#MicrostructureNoise.Posterior"><code>MicrostructureNoise.Posterior</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">struct Posterior
    post_t # Time grid of the bins
    post_qlow # Lower boundary of marginal credible band
    post_median # Posterior median
    post_qup # Upper boundary of marginal credible band
    post_mean # Posterior mean of `s^2`
    post_mean_root # Posterior mean of `s`
    qu # `qu*100`-% marginal credible band
end</code></pre><p>Struct holding posterior information for squared volatility <code>s^2</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MicrostructureNoise.posterior_volatility" href="#MicrostructureNoise.posterior_volatility"><code>MicrostructureNoise.posterior_volatility</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">posterior_volatility(td, θs; burnin = size(θs, 2)÷3, qu = 0.90)</code></pre><p>Computes the <code>qu*100</code>-% marginal credible band for squared volatility <code>s^2</code> from <code>θ</code>.</p><p>Returns <code>Posterior</code> object with boundaries of the marginal credible band, posterior median and mean of <code>s^2</code>, as well as posterior mean of <code>s</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MicrostructureNoise.piecewise" href="#MicrostructureNoise.piecewise"><code>MicrostructureNoise.piecewise</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">piecewise(t, y, [endtime]) -&gt; t, xx</code></pre><p>If <code>(t, y)</code> is a jump process with piecewise constant paths and jumps  of size <code>y[i]-y[i-1]</code> at <code>t[i]</code>, piecewise returns coordinates path  for plotting purposes. The second argument allows to choose the right endtime of the last interval.</p></div></div></section><h2><a class="nav-anchor" id="Contribute-1" href="#Contribute-1">Contribute</a></h2><p>See <a href="https://github.com/mschauer/MicrostructureNoise.jl/issues/1">issue #1 (Roadmap/Contribution)</a> for questions and coordination of the development.</p><h2><a class="nav-anchor" id="References-1" href="#References-1">References</a></h2><ul><li><p>Shota Gugushvili, Frank van der Meulen, Moritz Schauer, and Peter Spreij: Nonparametric Bayesian volatility estimation. <a href="https://arxiv.org/abs/1801.09956">arxiv:1801.09956</a>, 2018.</p></li><li><p>Shota Gugushvili, Frank van der Meulen, Moritz Schauer, and Peter Spreij: Nonparametric Bayesian volatility learning under microstructure noise. In preparation.</p></li></ul><footer><hr/></footer></article></body></html>
