<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Kernels · MLKernels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MLKernels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../interface/">Interface</a></li><li class="current"><a class="toctext" href>Kernels</a><ul class="internal"><li><a class="toctext" href="#Mercer-Kernels-1">Mercer Kernels</a></li><li><a class="toctext" href="#Negative-Definite-Kernels-1">Negative Definite Kernels</a></li><li><a class="toctext" href="#Other-Kernels-1">Other Kernels</a></li></ul></li><li><a class="toctext" href="../kernel-theory/">Kernel Theory</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Kernels</a></li></ul></nav><hr/><div id="topbar"><span>Kernels</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Kernels-1" href="#Kernels-1">Kernels</a></h1><h2><a class="nav-anchor" id="Mercer-Kernels-1" href="#Mercer-Kernels-1">Mercer Kernels</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.ExponentialKernel" href="#MLKernels.ExponentialKernel"><code>MLKernels.ExponentialKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">ExponentialKernel([α=1])</code></pre><p>The exponential kernel is given by the formula:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = \exp\left(-\alpha ||\mathbf{x} - \mathbf{y}||\right) 
\qquad \alpha &gt; 0\]</div><p>where <span>$\alpha$</span> is a scaling parameter of the Euclidean distance. The exponential kernel,  also known as the Laplacian kernel, is an isotropic Mercer kernel. The constructor is  aliased by <code>LaplacianKernel</code>, so both names may be used:</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.SquaredExponentialKernel" href="#MLKernels.SquaredExponentialKernel"><code>MLKernels.SquaredExponentialKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SquaredExponentialKernel([α=1])</code></pre><p>The squared exponential kernel, or alternatively the Gaussian kernel, is identical to the  exponential kernel except that the Euclidean distance is squared:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = \exp\left(-\alpha ||\mathbf{x} - \mathbf{y}||^2\right) 
\qquad \alpha &gt; 0\]</div><p>where <span>$\alpha$</span> is a scaling parameter of the squared Euclidean distance. Just like the exponential kernel, the squared exponential kernel is an isotropic Mercer kernel. The squared exponential kernel is more commonly known as the radial basis kernel within machine learning communities.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.GammaExponentialKernel" href="#MLKernels.GammaExponentialKernel"><code>MLKernels.GammaExponentialKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">GammaExponentialKernel([α=1 [,γ=1]])</code></pre><p>The gamma exponential kernel is a generalization of the exponential and squared exponential  kernels:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = \exp\left(-\alpha ||\mathbf{x} - \mathbf{y}||^{\gamma} 
\right) \qquad \alpha &gt; 0, \; 0 &lt; \gamma \leq 1\]</div><p>where <span>$\alpha$</span> is a scaling parameter and <span>$\gamma$</span> is a shape parameter.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.RationalQuadraticKernel" href="#MLKernels.RationalQuadraticKernel"><code>MLKernels.RationalQuadraticKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">RationalQuadraticKernel([α=1 [,β=1]])</code></pre><p>The rational-quadratic kernel is given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) 
= \left(1 +\alpha ||\mathbf{x},\mathbf{y}||^2\right)^{-\beta} 
\qquad \alpha &gt; 0, \; \beta &gt; 0\]</div><p>where <span>$\alpha$</span> is a scaling parameter and <span>$\beta$</span> is a shape parameter. This kernel can  be seen as an infinite sum of Gaussian kernels. If one sets <span>$\alpha = \alpha_0 / \beta$</span>,  then taking the limit <span>$\beta \rightarrow \infty$</span> results in the Gaussian kernel with  scaling parameter <span>$\alpha_0$</span>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.GammaRationalKernel" href="#MLKernels.GammaRationalKernel"><code>MLKernels.GammaRationalKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">GammaRationalKernel([α [,β [,γ]]])</code></pre><p>The gamma-rational kernel is a generalization of the rational-quadratic kernel with an  additional shape parameter:</p><div>\[\kappa(\mathbf{x},\mathbf{y})
= \left(1 +\alpha ||\mathbf{x},\mathbf{y}||^{\gamma}\right)^{-\beta} 
\qquad \alpha &gt; 0, \; \beta &gt; 0, \; 0 &lt; \gamma \leq 1\]</div><p>where <span>$\alpha$</span> is a scaling parameter and <span>$\beta$</span> and <span>$\gamma$</span> are shape parameters.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.MaternKernel" href="#MLKernels.MaternKernel"><code>MLKernels.MaternKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">MaternKernel([ν=1 [,θ=1]])</code></pre><p>The Matern kernel is a Mercer kernel given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) =
\frac{1}{2^{\nu-1}\Gamma(\nu)}
\left(\frac{\sqrt{2\nu}||\mathbf{x}-\mathbf{y}||}{\theta}\right)^{\nu}
K_{\nu}\left(\frac{\sqrt{2\nu}||\mathbf{x}-\mathbf{y}||}{\theta}\right)\]</div><p>where <span>$\Gamma$</span> is the gamma function, <span>$K_{\nu}$</span> is the modified Bessel function of the second kind, <span>$\nu &gt; 0$</span> and <span>$\theta &gt; 0$</span>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.LinearKernel" href="#MLKernels.LinearKernel"><code>MLKernels.LinearKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">LinearKernel([a=1 [,c=1]])</code></pre><p>The linear kernel is a Mercer kernel given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = 
a \mathbf{x}^\intercal \mathbf{y} + c \qquad \alpha &gt; 0, \; c \geq 0\]</div></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.PolynomialKernel" href="#MLKernels.PolynomialKernel"><code>MLKernels.PolynomialKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PolynomialKernel([a=1 [,c=1 [,d=3]]])</code></pre><p>The polynomial kernel is a Mercer kernel given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = 
(a \mathbf{x}^\intercal \mathbf{y} + c)^d
\qquad \alpha &gt; 0, \; c \geq 0, \; d \in \mathbb{Z}_{+}\]</div></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.ExponentiatedKernel" href="#MLKernels.ExponentiatedKernel"><code>MLKernels.ExponentiatedKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">ExponentiatedKernel([a=1])</code></pre><p>The exponentiated kernel is a Mercer kernel given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = \exp\left(a \mathbf{x}^\intercal \mathbf{y} \right) 
\qquad a &gt; 0\]</div></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.PeriodicKernel" href="#MLKernels.PeriodicKernel"><code>MLKernels.PeriodicKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PeriodicKernel([α=1 [,p=π]])</code></pre><p>The periodic kernel is given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) =
\exp\left(-\alpha \sum_{i=1}^n \sin(p(x_i - y_i))^2\right)
\qquad p &gt;0, \; \alpha &gt; 0\]</div><p>where <span>$\mathbf{x}$</span> and <span>$\mathbf{y}$</span> are <span>$n$</span> dimensional vectors. The parameters <span>$p$</span>  and <span>$\alpha$</span> are scaling parameters for the periodicity and the magnitude, respectively.  This kernel is useful when data has periodicity to it.</p></div></div></section><h2><a class="nav-anchor" id="Negative-Definite-Kernels-1" href="#Negative-Definite-Kernels-1">Negative Definite Kernels</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.PowerKernel" href="#MLKernels.PowerKernel"><code>MLKernels.PowerKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PowerKernel([γ=1])</code></pre><p>The Power Kernel is a negative definite kernel given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = 
\|\mathbf{x} - \mathbf{y} \|^{2\gamma}
\qquad \gamma \in (0,1]\]</div></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.LogKernel" href="#MLKernels.LogKernel"><code>MLKernels.LogKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">LogKernel([α [,γ]])</code></pre><p>The Log Kernel is a negative definite kernel given by:</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = 
\log \left(1 + \alpha\|\mathbf{x} - \mathbf{y} \|^{2\gamma}\right)
\qquad \alpha &gt; 0, \; \gamma \in (0,1]\]</div></div></div></section><h2><a class="nav-anchor" id="Other-Kernels-1" href="#Other-Kernels-1">Other Kernels</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLKernels.SigmoidKernel" href="#MLKernels.SigmoidKernel"><code>MLKernels.SigmoidKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SigmoidKernel([a=1 [,c=1]])</code></pre><p>The Sigmoid Kernel is given by</p><div>\[\kappa(\mathbf{x},\mathbf{y}) = 
\tanh(a \mathbf{x}^\intercal \mathbf{y} + c) 
\qquad \alpha &gt; 0, \; c \geq 0\]</div><p>The sigmoid kernel is a not a true kernel, although it has been used in application. </p></div></div></section><footer><hr/><a class="previous" href="../interface/"><span class="direction">Previous</span><span class="title">Interface</span></a><a class="next" href="../kernel-theory/"><span class="direction">Next</span><span class="title">Kernel Theory</span></a></footer></article></body></html>
