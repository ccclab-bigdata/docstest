<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Compilation &amp; Execution · CUDAnative.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>CUDAnative.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../../man/usage/">Usage</a></li><li><a class="toctext" href="../../man/troubleshooting/">Troubleshooting</a></li><li><a class="toctext" href="../../man/performance/">Performance</a></li><li><a class="toctext" href="../../man/hacking/">Hacking</a></li></ul></li><li><span class="toctext">Library</span><ul><li class="current"><a class="toctext" href>Compilation &amp; Execution</a><ul class="internal"><li><a class="toctext" href="#Devices-1">Devices</a></li></ul></li><li><a class="toctext" href="../reflection/">Reflection</a></li><li><span class="toctext">Device Code</span><ul><li><a class="toctext" href="../device/intrinsics/">Intrinsics</a></li><li><a class="toctext" href="../device/array/">Arrays</a></li><li><a class="toctext" href="../device/libdevice/">libdevice</a></li></ul></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Library</li><li><a href>Compilation &amp; Execution</a></li></ul></nav><hr/><div id="topbar"><span>Compilation &amp; Execution</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Compilation-and-Execution-1" href="#Compilation-and-Execution-1">Compilation &amp; Execution</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.@cuda" href="#CUDAnative.@cuda"><code>CUDAnative.@cuda</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><pre><code class="language-none">@cuda [kwargs...] func(args...)</code></pre><p>High-level interface for executing code on a GPU. The <code>@cuda</code> macro should prefix a call, with <code>func</code> a callable function or object that should return nothing. It will be compiled to a CUDA function upon first use, and to a certain extent arguments will be converted and managed automatically using <code>cudaconvert</code>. Finally, a call to <code>CUDAdrv.cudacall</code> is performed, scheduling a kernel launch on the current CUDA context.</p><p>Several keyword arguments are supported that influence kernel compilation and execution. For more information, refer to the documentation of respectively <a href="#CUDAnative.cufunction"><code>cufunction</code></a> and <a href="#CUDAnative.Kernel"><code>CUDAnative.Kernel</code></a></p><p>The underlying operations (argument conversion, kernel compilation, kernel call) can be performed explicitly when more control is needed, e.g. to reflect on the resource usage of a kernel to determine the launch configuration:</p><pre><code class="language-none">args = ...
GC.@preserve args begin
    kernel_args = cudaconvert.(args)
    kernel_tt = Tuple{Core.Typeof.(kernel_args)...}
    kernel = cufunction(f, kernel_tt; compilation_kwargs)
    kernel(kernel_args...; launch_kwargs)
end</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.cufunction" href="#CUDAnative.cufunction"><code>CUDAnative.cufunction</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">cufunction(f, tt=Tuple{}; kwargs...)</code></pre><p>Low-level interface to compile a function invocation for the currently-active GPU, returning a callable kernel object. For a higher-level interface, use <a href="#CUDAnative.@cuda"><code>@cuda</code></a>.</p><p>The following keyword arguments are supported:</p><ul><li>minthreads: the required number of threads in a thread block.</li><li>maxthreads: the maximum number of threads in a thread block.</li><li>blocks<em>per</em>sm: a minimum number of thread blocks to be scheduled on a single multiprocessor.</li><li>maxregs: the maximum number of registers to be allocated to a single thread (only supported on LLVM 4.0+)</li></ul><p>The output of this function is automatically cached, i.e. you can simply call <code>cufunction</code> in a hot path without degrading performance. New code will be generated automatically, when when function changes, or when different types or keyword arguments are provided.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.Kernel" href="#CUDAnative.Kernel"><code>CUDAnative.Kernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">(::Kernel)(args...; kwargs...)</code></pre><p>Low-level interface to call a compiled kernel, passing GPU-compatible arguments in <code>args</code>. For a higher-level interface, use <a href="#CUDAnative.@cuda"><code>@cuda</code></a>.</p><p>The following keyword arguments are supported:</p><ul><li>threads (defaults to 1)</li><li>blocks (defaults to 1)</li><li>shmem (defaults to 0)</li><li>stream (defaults to the default stream)</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.compile" href="#CUDAnative.compile"><code>CUDAnative.compile</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">compile(dev::CuDevice, f, tt; kwargs...)</code></pre><p>Compile a function <code>f</code> invoked with types <code>tt</code> for device <code>dev</code>, returning the compiled function module respectively of type <code>CuFuction</code> and <code>CuModule</code>.</p><p>For a list of supported keyword arguments, refer to the documentation of <a href="#CUDAnative.cufunction"><code>cufunction</code></a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.cudaconvert" href="#CUDAnative.cudaconvert"><code>CUDAnative.cudaconvert</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">cudaconvert(x)</code></pre><p>This function is called for every argument to be passed to a kernel, allowing it to be converted to a GPU-friendly format. By default, the function does nothing and returns the input object <code>x</code> as-is.</p><p>Do not add methods to this function, but instead extend the underlying Adapt.jl package and register methods for the the <code>CUDAnative.Adaptor</code> type.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.nearest_warpsize" href="#CUDAnative.nearest_warpsize"><code>CUDAnative.nearest_warpsize</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">nearest_warpsize(dev::CuDevice, threads::Integer)</code></pre><p>Return the nearest number of threads that is a multiple of the warp size of a device.</p><p>This is a common requirement, eg. when using shuffle intrinsics.</p></div></div></section><h2><a class="nav-anchor" id="Devices-1" href="#Devices-1">Devices</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.device!" href="#CUDAnative.device!"><code>CUDAnative.device!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">device!(dev)</code></pre><p>Sets <code>dev</code> as the current active device for the calling host thread. Devices can be specified by integer id, or as a <code>CuDevice</code>. This is intended to be a low-cost operation, only performing significant work when calling it for the first time for each device.</p><p>If your library or code needs to perform an action when the active device changes, add a callback of the signature <code>(::CuDevice, ::CuContext)</code> to the <code>device!_listeners</code> set.</p></div></div><div><div><pre><code class="language-none">device!(f, dev)</code></pre><p>Sets the active device for the duration of <code>f</code>.</p></div></div></section><footer><hr/><a class="previous" href="../../man/hacking/"><span class="direction">Previous</span><span class="title">Hacking</span></a><a class="next" href="../reflection/"><span class="direction">Next</span><span class="title">Reflection</span></a></footer></article></body></html>
