<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · Word2Vec.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Word2Vec.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#Functions-1">Functions</a></li><li><a class="toctext" href="#Examples-1">Examples</a></li><li><a class="toctext" href="#References-1">References</a></li><li><a class="toctext" href="#Acknowledgements-1">Acknowledgements</a></li><li><a class="toctext" href="#Reporting-Bugs-1">Reporting Bugs</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Word2Vec-1" href="#Word2Vec-1">Word2Vec</a></h1><p><a href="LICENSE.md"><img src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" alt="License"/></a> <a href="https://travis-ci.org/JuliaText/Word2Vec.jl"><img src="https://travis-ci.org/JuliaText/Word2Vec.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://coveralls.io/github/JuliaText/Word2Vec.jl?branch=master"><img src="https://coveralls.io/repos/github/JuliaText/Word2Vec.jl/badge.svg?branch=master" alt="Coverage Status"/></a></p><p>Julia interface to <a href="https://code.google.com/p/word2vec/">word2vec</a></p><p>Word2Vec takes a text corpus as input and produces the word vectors as output. Training is done using the original C code, other functionalities are pure Julia. See <a href="http://nbviewer.ipython.org/github/JuliaText/Word2Vec.jl/blob/master/examples/demo.ipynb">demo</a> for more details.</p><ul><li><a href="https://github.com/JuliaText/Word2Vec.jl/blob/master/NEWS.md">Release Notes</a></li></ul><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><pre><code class="language-julia">Pkg.add(&quot;Word2Vec&quot;)</code></pre><p><strong>Note</strong>: Only linux and OS X are supported.</p><h2><a class="nav-anchor" id="Functions-1" href="#Functions-1">Functions</a></h2><p>All exported functions are documented, i.e., we can type <code>? functionname</code> to get help. For a list of functions, see <a href="https://github.com/JuliaText/Word2Vec.jl/blob/master/doc/README.md">here</a>.</p><h2><a class="nav-anchor" id="Examples-1" href="#Examples-1">Examples</a></h2><p>We first download some text corpus, for example http://mattmahoney.net/dc/text8.zip.</p><p>Suppose the file <span>$text8$</span> is stored in the current working directory. We can train the model with the function <span>$word2vec$</span>.</p><pre><code class="language-julia">julia&gt; word2vec(&quot;text8&quot;, &quot;text8-vec.txt&quot;, verbose = true)
Starting training using file text8
Vocab size: 71291
Words in train file: 16718843
Alpha: 0.000002  Progress: 100.04%  Words/thread/sec: 350.44k  </code></pre><p>Now we can import the word vectors <span>$text8-vec.txt$</span> to Julia.</p><pre><code class="language-julia">julia&gt; model = wordvectors(&quot;./text8-vec&quot;)
WordVectors 71291 words, 100-element Float64 vectors</code></pre><p>The vector representation of a word can be obtained using <span>$get_vector$</span>.</p><pre><code class="language-julia">julia&gt; get_vector(model, &quot;book&quot;)&#39;
100-element Array{Float64,1}:
 -0.05446138539336186
  0.001090934639284009
  0.06498087707990222
  ⋮
 -0.0024113040415322516
  0.04755140828570571
  0.039764719065723826</code></pre><p>The cosine similarity of <span>$book$</span>, for example, can be computed using <span>$cosine_similar_words$</span>.</p><pre><code class="language-julia">julia&gt; cosine_similar_words(model, &quot;book&quot;)
10-element Array{String,1}:
 &quot;book&quot;
 &quot;books&quot;
 &quot;diary&quot;
 &quot;story&quot;
 &quot;chapter&quot;
 &quot;novel&quot;
 &quot;preface&quot;
 &quot;poem&quot;
 &quot;tale&quot;
 &quot;bible&quot;</code></pre><p>Word vectors have many interesting properties. For example,  <span>$vector(&quot;king&quot;) - vector(&quot;man&quot;) + vector(&quot;woman&quot;)$</span> is close to <span>$vector(&quot;queen&quot;)$</span>.</p><pre><code class="language-julia">5-element Array{String,1}:
 &quot;queen&quot;
 &quot;empress&quot;
 &quot;prince&quot;
 &quot;princess&quot;
 &quot;throne&quot;</code></pre><h2><a class="nav-anchor" id="References-1" href="#References-1">References</a></h2><ul><li><p>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean, &quot;Efficient Estimation of Word Representations in Vector Space&quot;, <em>In Proceedings of Workshop at ICLR</em>, 2013. <a href="http://arxiv.org/pdf/1301.3781.pdf">[pdf]</a></p></li><li><p>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. &quot;Distributed Representations of Words and Phrases and their Compositionality&quot;, <em>In Proceedings of NIPS</em>, 2013. <a href="http://arxiv.org/pdf/1310.4546.pdf">[pdf]</a></p></li><li><p>Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig, &quot;Linguistic Regularities in Continuous Space Word Representations&quot;, <em>In Proceedings of NAACL HLT</em>, 2013. <a href="http://research.microsoft.com/pubs/189726/rvecs.pdf">[pdf]</a></p></li></ul><h2><a class="nav-anchor" id="Acknowledgements-1" href="#Acknowledgements-1">Acknowledgements</a></h2><p>The design of the package is inspired by Daniel Rodriguez (@danielfrg)&#39;s <a href="https://github.com/danielfrg/word2vec">Python word2vec interface</a>.</p><h2><a class="nav-anchor" id="Reporting-Bugs-1" href="#Reporting-Bugs-1">Reporting Bugs</a></h2><p>Please <a href="https://github.com/JuliaText/Word2Vec.jl/issues/new">file an issue</a> to report a bug or request a feature.</p><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
