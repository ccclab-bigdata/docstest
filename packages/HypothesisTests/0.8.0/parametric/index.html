<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parametric tests · HypothesisTests.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../index.html"><img class="logo" src="../assets/logo.png" alt="HypothesisTests.jl logo"/></a><h1>HypothesisTests.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">HypothesisTests package</a></li><li><a class="toctext" href="../methods/">Methods</a></li><li class="current"><a class="toctext" href>Parametric tests</a><ul class="internal"><li><a class="toctext" href="#Power-divergence-test-1">Power divergence test</a></li><li><a class="toctext" href="#t-test-1">t-test</a></li><li><a class="toctext" href="#z-test-1">z-test</a></li></ul></li><li><a class="toctext" href="../nonparametric/">Nonparametric tests</a></li><li><a class="toctext" href="../time_series/">Time series tests</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Parametric tests</a></li></ul></nav><hr/><div id="topbar"><span>Parametric tests</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Parametric-tests-1" href="#Parametric-tests-1">Parametric tests</a></h1><h2><a class="nav-anchor" id="Power-divergence-test-1" href="#Power-divergence-test-1">Power divergence test</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.PowerDivergenceTest" href="#HypothesisTests.PowerDivergenceTest"><code>HypothesisTests.PowerDivergenceTest</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PowerDivergenceTest(x[, y]; lambda = 1.0, theta0 = ones(length(x))/length(x))</code></pre><p>Perform a Power Divergence test.</p><p>If <code>y</code> is not given and <code>x</code> is a matrix with one row or column, or <code>x</code> is a vector, then a goodness-of-fit test is performed (<code>x</code> is treated as a one-dimensional contingency table). In this case, the hypothesis tested is whether the population probabilities equal those in <code>theta0</code>, or are all equal if <code>theta0</code> is not given.</p><p>If <code>x</code> is a matrix with at least two rows and columns, it is taken as a two-dimensional contingency table. Otherwise, <code>x</code> and <code>y</code> must be vectors of the same length. The contingency table is calculated using the <code>counts</code> function from the <code>StatsBase</code> package. Then the power divergence test is conducted under the null hypothesis that the joint distribution of the cell counts in a 2-dimensional contingency table is the product of the row and column marginals.</p><p>Note that the entries of <code>x</code> (and <code>y</code> if provided) must be non-negative integers.</p><p>The power divergence test is given by</p><div>\[    \dfrac{2}{λ(λ+1)}\sum_{i=1}^I \sum_{j=1}^J n_{ij} \left[(n_{ij}
    /\hat{n}_{ij})^λ -1\right]\]</div><p>where <span>$n_{ij}$</span> is the cell count in the <span>$i$</span> th row and <span>$j$</span> th column and <span>$λ$</span> is a real number determining the nature of the test to be performed:</p><ul><li><span>$λ = 1$</span>: equal to Pearson&#39;s chi-squared statistic</li><li><span>$λ \to 0$</span>: converges to the likelihood ratio test statistic</li><li><span>$λ \to -1$</span>: converges to the minimum discrimination information statistic (Gokhale and Kullback, 1978)</li><li><span>$λ = -2$</span>: equals Neyman modified chi-squared (Neyman, 1949)</li><li><span>$λ = -1/2$</span>: equals the Freeman-Tukey statistic (Freeman and Tukey, 1950).</li></ul><p>Under regularity conditions, the asymptotic distributions are identical (see Drost et. al. 1989). The <span>$χ^2$</span> null approximation works best for <span>$λ$</span> near <span>$2/3$</span>.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint-Tuple{PowerDivergenceTest}"><code>confint(::PowerDivergenceTest)</code></a></p><p><strong>References</strong></p><ul><li>Agresti, Alan. Categorical Data Analysis, 3rd Edition. Wiley, 2013.</li></ul></div></div></section><h3><a class="nav-anchor" id="Pearson-chi-squared-test-1" href="#Pearson-chi-squared-test-1">Pearson chi-squared test</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.ChisqTest" href="#HypothesisTests.ChisqTest"><code>HypothesisTests.ChisqTest</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">ChisqTest(x[, y][, theta0 = ones(length(x))/length(x)])</code></pre><p>Perform a Pearson chi-squared test (equivalent to a <a href="#HypothesisTests.PowerDivergenceTest"><code>PowerDivergenceTest</code></a> with <span>$λ = 1$</span>).</p><p>If <code>y</code> is not given and <code>x</code> is a matrix with one row or column, or <code>x</code> is a vector, then a goodness-of-fit test is performed (<code>x</code> is treated as a one-dimensional contingency table). In this case, the hypothesis tested is whether the population probabilities equal those in <code>theta0</code>, or are all equal if <code>theta0</code> is not given.</p><p>If <code>x</code> is a matrix with at least two rows and columns, it is taken as a two-dimensional contingency table. Otherwise, <code>x</code> and <code>y</code> must be vectors of the same length. The contingency table is calculated using <code>counts</code> function from the <code>StatsBase</code> package. Then the power divergence test is conducted under the null hypothesis that the joint distribution of the cell counts in a 2-dimensional contingency table is the product of the row and column marginals.</p><p>Note that the entries of <code>x</code> (and <code>y</code> if provided) must be non-negative integers.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><h3><a class="nav-anchor" id="Multinomial-likelihood-ratio-test-1" href="#Multinomial-likelihood-ratio-test-1">Multinomial likelihood ratio test</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.MultinomialLRT" href="#HypothesisTests.MultinomialLRT"><code>HypothesisTests.MultinomialLRT</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">MultinomialLRT(x[, y][, theta0 = ones(length(x))/length(x)])</code></pre><p>Perform a multinomial likelihood ratio test (equivalent to a <a href="#HypothesisTests.PowerDivergenceTest"><code>PowerDivergenceTest</code></a> with <span>$λ = 0$</span>).</p><p>If <code>y</code> is not given and <code>x</code> is a matrix with one row or column, or <code>x</code> is a vector, then a goodness-of-fit test is performed (<code>x</code> is treated as a one-dimensional contingency table). In this case, the hypothesis tested is whether the population probabilities equal those in <code>theta0</code>, or are all equal if <code>theta0</code> is not given.</p><p>If <code>x</code> is a matrix with at least two rows and columns, it is taken as a two-dimensional contingency table. Otherwise, <code>x</code> and <code>y</code> must be vectors of the same length. The contingency table is calculated using <code>counts</code> function from the <code>StatsBase</code> package. Then the power divergence test is conducted under the null hypothesis that the joint distribution of the cell counts in a 2-dimensional contingency table is the product of the row and column marginals.</p><p>Note that the entries of <code>x</code> (and <code>y</code> if provided) must be non-negative integers.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><h2><a class="nav-anchor" id="t-test-1" href="#t-test-1">t-test</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.OneSampleTTest" href="#HypothesisTests.OneSampleTTest"><code>HypothesisTests.OneSampleTTest</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">OneSampleTTest(xbar::Real, stddev::Real, n::Int, μ0::Real = 0)</code></pre><p>Perform a one sample t-test of the null hypothesis that <code>n</code> values with mean <code>xbar</code> and sample standard deviation <code>stddev</code>  come from a distribution with mean <code>μ0</code> against the alternative hypothesis that the distribution does not have mean <code>μ0</code>.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div><div><div><pre><code class="language-none">OneSampleTTest(v::AbstractVector{T&lt;:Real}, μ0::Real = 0)</code></pre><p>Perform a one sample t-test of the null hypothesis that the data in vector <code>v</code> comes from a distribution with mean <code>μ0</code> against the alternative hypothesis that the distribution does not have mean <code>μ0</code>.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div><div><div><pre><code class="language-none">OneSampleTTest(x::AbstractVector{T&lt;:Real}, y::AbstractVector{T&lt;:Real}, μ0::Real = 0)</code></pre><p>Perform a paired sample t-test of the null hypothesis that the differences between pairs of values in vectors <code>x</code> and <code>y</code> come from a distribution with mean <code>μ0</code> against the alternative hypothesis that the distribution does not have mean <code>μ0</code>.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.EqualVarianceTTest" href="#HypothesisTests.EqualVarianceTTest"><code>HypothesisTests.EqualVarianceTTest</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">EqualVarianceTTest(x::AbstractVector{T&lt;:Real}, y::AbstractVector{T&lt;:Real})</code></pre><p>Perform a two-sample t-test of the null hypothesis that <code>x</code> and <code>y</code> come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.UnequalVarianceTTest" href="#HypothesisTests.UnequalVarianceTTest"><code>HypothesisTests.UnequalVarianceTTest</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">UnequalVarianceTTest(x::AbstractVector{T&lt;:Real}, y::AbstractVector{T&lt;:Real})</code></pre><p>Perform an unequal variance two-sample t-test of the null hypothesis that <code>x</code> and <code>y</code> come from distributions with equal means against the alternative hypothesis that the distributions have different means.</p><p>This test is sometimes known as Welch&#39;s t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation:</p><div>\[    ν_{χ&#39;} ≈ \frac{\left(\sum_{i=1}^n k_i s_i^2\right)^2}{\sum_{i=1}^n
        \frac{(k_i s_i^2)^2}{ν_i}}\]</div><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><h2><a class="nav-anchor" id="z-test-1" href="#z-test-1">z-test</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.OneSampleZTest" href="#HypothesisTests.OneSampleZTest"><code>HypothesisTests.OneSampleZTest</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">OneSampleZTest(xbar::Real, stddev::Real, n::Int, μ0::Real = 0)</code></pre><p>Perform a one sample z-test of the null hypothesis that <code>n</code> values with mean <code>xbar</code> and population standard deviation <code>stddev</code>  come from a distribution with mean <code>μ0</code> against the alternative hypothesis that the distribution does not have mean <code>μ0</code>.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div><div><div><pre><code class="language-none">OneSampleZTest(v::AbstractVector{T&lt;:Real}, μ0::Real = 0)</code></pre><p>Perform a one sample z-test of the null hypothesis that the data in vector <code>v</code> comes from a distribution with mean <code>μ0</code> against the alternative hypothesis that the distribution does not have mean <code>μ0</code>.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div><div><div><pre><code class="language-none">OneSampleZTest(x::AbstractVector{T&lt;:Real}, y::AbstractVector{T&lt;:Real}, μ0::Real = 0)</code></pre><p>Perform a paired sample z-test of the null hypothesis that the differences between pairs of values in vectors <code>x</code> and <code>y</code> come from a distribution with mean <code>μ0</code> against the alternative hypothesis that the distribution does not have mean <code>μ0</code>.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.EqualVarianceZTest" href="#HypothesisTests.EqualVarianceZTest"><code>HypothesisTests.EqualVarianceZTest</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">EqualVarianceZTest(x::AbstractVector{T&lt;:Real}, y::AbstractVector{T&lt;:Real})</code></pre><p>Perform a two-sample z-test of the null hypothesis that <code>x</code> and <code>y</code> come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="HypothesisTests.UnequalVarianceZTest" href="#HypothesisTests.UnequalVarianceZTest"><code>HypothesisTests.UnequalVarianceZTest</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">UnequalVarianceZTest(x::AbstractVector{T&lt;:Real}, y::AbstractVector{T&lt;:Real})</code></pre><p>Perform an unequal variance two-sample z-test of the null hypothesis that <code>x</code> and <code>y</code> come from distributions with equal means against the alternative hypothesis that the distributions have different means.</p><p>Implements: <a href="../methods/#HypothesisTests.pvalue"><code>pvalue</code></a>, <a href="../methods/#StatsBase.confint"><code>confint</code></a></p></div></div></section><footer><hr/><a class="previous" href="../methods/"><span class="direction">Previous</span><span class="title">Methods</span></a><a class="next" href="../nonparametric/"><span class="direction">Next</span><span class="title">Nonparametric tests</span></a></footer></article></body></html>
