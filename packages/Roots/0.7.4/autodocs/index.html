<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · Roots.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Roots.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.A42" href="#Roots.A42"><code>Roots.A42</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Roots.A42()</code></pre><p>Bracketing method which finds the root of a continuous function within a provided interval [a, b], without requiring derivatives. It is based on algorithm 4.2 described in: 1. G. E. Alefeld, F. A. Potra, and Y. Shi, &quot;Algorithm 748: enclosing zeros of continuous functions,&quot; ACM Trans. Math. Softw. 21, 327–344 (1995), DOI: 10.1145/210089.210111. Originally by John Travers</p></div></div></section><pre><code class="language-none">Roots.AbstractAlefeldPotraShi</code></pre><pre><code class="language-none">Roots.AbstractBisection</code></pre><pre><code class="language-none">Roots.AbstractBracketing</code></pre><pre><code class="language-none">Roots.AbstractHalleyLikeMethod</code></pre><pre><code class="language-none">Roots.AbstractNonBracketing</code></pre><pre><code class="language-none">Roots.AbstractSecant</code></pre><pre><code class="language-none">Roots.AbstractTracks</code></pre><pre><code class="language-none">Roots.AbstractUnivariateZeroMethod</code></pre><pre><code class="language-none">Roots.AbstractUnivariateZeroState</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.AlefeldPotraShi" href="#Roots.AlefeldPotraShi"><code>Roots.AlefeldPotraShi</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Roots.AlefeldPotraShi()</code></pre><p>Follows algorithm in &quot;ON ENCLOSING SIMPLE ROOTS OF NONLINEAR EQUATIONS&quot;, by Alefeld, Potra, Shi; DOI: 10.1090/S0025-5718-1993-1192965-2 <a href="http://www.ams.org/journals/mcom/1993-61-204/S0025-5718-1993-1192965-2/S0025-5718-1993-1192965-2.pdf">link</a>. Efficiency is 1.618. Less efficient, but can be faster than A42() method.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Bisection" href="#Roots.Bisection"><code>Roots.Bisection</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Bisection()</code></pre><p>If possible, will use the bisection method over <code>Float64</code> values. The bisection method starts with a bracketing interval <code>[a,b]</code> and splits it into two intervals <code>[a,c]</code> and <code>[c,b]</code>, If <code>c</code> is not a zero, then one of these two will be a bracketing interval and the process continues. The computation of <code>c</code> is done by <code>_middle</code>, which reinterprets floating point values as unsigned integers and splits there. This method avoids floating point issues and when the tolerances are set to zero (the default) guarantees a &quot;best&quot; solution (one where a zero is found or the bracketing interval is of the type <code>[a, nextfloat(a)]</code>).</p><p>When tolerances are given, this algorithm terminates when the midpoint is approximately equal to an endpoint using absolute tolerance <code>xatol</code> and relative tolerance <code>xrtol</code>.</p><p>When a zero tolerance is given and the values are not <code>Float64</code> values, this will call the <code>A42</code> method.</p></div></div></section><pre><code class="language-none">Roots.BisectionExact</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Brent" href="#Roots.Brent"><code>Roots.Brent</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Roots.Brent()</code></pre><p>An implementation of <a href="https://en.wikipedia.org/wiki/Brent%27s_method">Brent&#39;s</a> (or Brent-Dekker) method. This method uses a choice of inverse quadratic interpolation or a secant step, falling back on bisection if necessary.</p></div></div></section><pre><code class="language-none">Roots.CallableFunction</code></pre><pre><code class="language-none">Roots.ConvergenceFailed</code></pre><pre><code class="language-none">Roots.DerivativeFree</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Esser" href="#Roots.Esser"><code>Roots.Esser</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order2B()</code></pre><p>Esser&#39;s method. This is a quadratically convergent method that, like Schroder&#39;s method, does not depend on the multiplicity of the zero. Schroder&#39;s method has update step x- r2/(r2-r1) * r1, where ri = f^(i-1)/f^(i). Esser approximates f&#39; ~ f[x-h, x+h], f&#39;&#39; ~ f[x-h,x,x+h], where h = fx, as with Steffensen&#39;s method, Requiring 3 function calls per step. This implementation uses a secant step when |fx| is considered too large.</p><p>Esser, H. Computing (1975) 14: 367. https://doi.org/10.1007/BF02253547 Eine stets quadratisch konvergente Modifikation des Steffensen-Verfahrens</p><p>Example</p><pre><code class="language-none">f(x) = cos(x) - x
g(x) = f(x)^2
x0 = pi/4
find_zero(f, x0, Order2(), verbose=true)        #  3 steps / 7 function calls
find_zero(f, x0, Roots.Order2B(), verbose=true) #  4 / 9
find_zero(g, x0, Order2(), verbose=true)        #  22 / 45
find_zero(g, x0, Roots.Order2B(), verbose=true) #  4 / 10</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.FalsePosition" href="#Roots.FalsePosition"><code>Roots.FalsePosition</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">FalsePosition()</code></pre><p>Use the <a href="https://en.wikipedia.org/wiki/False_position_method">false position</a> method to find a zero for the function <code>f</code> within the bracketing interval <code>[a,b]</code>.</p><p>The false position method is a modified bisection method, where the midpoint between <code>[a_k, b_k]</code> is chosen to be the intersection point of the secant line with the x axis, and not the average between the two values.</p><p>To speed up convergence for concave functions, this algorithm implements the 12 reduction factors of Galdino (<em>A family of regula falsi root-finding methods</em>). These are specified by number, as in <code>FalsePosition(2)</code> or by one of three names <code>FalsePosition(:pegasus)</code>, <code>FalsePosition(:illinois)</code>, or <code>FalsePosition(:anderson_bjork)</code> (the default). The default choice has generally better performance than the others, though there are exceptions.</p><p>For some problems, the number of function calls can be greater than for the <code>bisection64</code> method, but generally this algorithm will make fewer function calls.</p><p>Examples</p><pre><code class="language-none">find_zero(x -&gt; x^5 - x - 1, [-2, 2], FalsePosition())</code></pre></div></div></section><pre><code class="language-none">Roots.FirstDerivative</code></pre><pre><code class="language-none">Roots.FloatNN</code></pre><pre><code class="language-none">Roots.FnWrapper</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Halley" href="#Roots.Halley"><code>Roots.Halley</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Roots.Halley()</code></pre><p>Implements Halley&#39;s <a href="http://tinyurl.com/yd83eytb">method</a>, `x_n1 = xn - f/f&#39; * (1 - f/f&#39; * f&#39;&#39;/f&#39; * 1/2)^(-1) This method is cubically converging, but requires more function calls per step (3) than other methods.</p><p>Example</p><pre><code class="language-none">find_zero((sin, cos, x-&gt;-sin(x)), 3.0, Roots.Halley())</code></pre><p>If function evaluations are expensive one can pass in a function which returns (f, f/f&#39;,f&#39;/f&#39;&#39;) as follows</p><pre><code class="language-none">find_zero(x -&gt; (sin(x), sin(x)/cos(x), -cos(x)/sin(x)), 3.0, Roots.Halley())</code></pre><p>This can be advantageous if the derivatives are easily computed from the value of f, but otherwise would be expensive to compute.</p></div></div></section><pre><code class="language-none">Roots.Interval</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.King" href="#Roots.King"><code>Roots.King</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">King()
Order1B()</code></pre><p>A superlinear (order 1.6...) modification of the secant method for multiple roots. Presented in A SECANT METHOD FOR MULTIPLE ROOTS, by RICHARD F. KING, BIT 17 (1977), 321-328</p><p>The basic idea is similar to Schroder&#39;s method: apply the secant method to  f/f&#39;. However, this uses f&#39; ~ fp = (fx - f(x-fx))/fx (a Steffensen step). In this implementation, when <code>fx</code> is too big, a single secant step of <code>f</code> is used.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Newton" href="#Roots.Newton"><code>Roots.Newton</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Roots.Newton()</code></pre><p>Implements Newton&#39;s <a href="http://tinyurl.com/b4d7vls">method</a>: <code>x_n1 = xn - f(xn)/f&#39;(xn)</code>.  This is a quadratically converging method requiring one derivative. Two function calls per step.</p><p>Example</p><pre><code class="language-none">find_zero((sin,cos), 3.0, Roots.Newton())</code></pre><p>If function evaluations are expensive one can pass in a function which returns (f, f/f&#39;) as follows</p><pre><code class="language-none">find_zero(x -&gt; (sin(x), sin(x)/cos(x)), 3.0, Roots.Newton())</code></pre><p>This can be advantageous if the derivative is easily computed from the value of f, but otherwise would be expensive to compute.</p></div></div></section><pre><code class="language-none">Roots.NullTracks</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order0" href="#Roots.Order0"><code>Roots.Order0</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order0()</code></pre><p>The <code>Order0</code> method is engineered to be a more robust, though possibly slower, alternative to to the other derivative-free root-finding methods. The implementation roughly follows the algorithm described in <em>Personal Calculator Has Key to Solve Any Equation f(x) = 0</em>, the SOLVE button from the <a href="http://www.hpl.hp.com/hpjournal/pdfs/IssuePDFs/1979-12.pdf">HP-34C</a>. The basic idea is to use a secant step. If along the way a bracket is found, switch to bisection, using <code>AlefeldPotraShi</code>.  If the secant step fails to decrease the function value, a quadratic step is used up to 3 times.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order1" href="#Roots.Order1"><code>Roots.Order1</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order1()</code></pre><p>The <code>Order1()</code> method is an alias for <code>Secant</code>. It specifies the <a href="https://en.wikipedia.org/wiki/Secant_method">secant method</a>. This method keeps two values in its state, <code>x_n</code> and <code>x_n1</code>. The updated point is the intersection point of x axis with the secant line formed from the two points. The secant method uses 1 function evaluation per step and has order <code>(1+sqrt(5))/2</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order16" href="#Roots.Order16"><code>Roots.Order16</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order16()</code></pre><p>Implement the algorithm from <em>New Sixteenth-Order Derivative-Free Methods for Solving Nonlinear Equations</em> by R. Thukral, American Journal of Computational and Applied Mathematics p-ISSN: 2165-8935;    e-ISSN: 2165-8943; 2012;  2(3): 112-118 doi: 10.5923/j.ajcam.20120203.08.</p><p>Five function calls per step are required. Though rapidly converging, this method generally isn&#39;t faster (fewer function calls/steps) over other methods when using <code>Float64</code> values, but may be useful for solving over <code>BigFloat</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order1B" href="#Roots.Order1B"><code>Roots.Order1B</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">King()
Order1B()</code></pre><p>A superlinear (order 1.6...) modification of the secant method for multiple roots. Presented in A SECANT METHOD FOR MULTIPLE ROOTS, by RICHARD F. KING, BIT 17 (1977), 321-328</p><p>The basic idea is similar to Schroder&#39;s method: apply the secant method to  f/f&#39;. However, this uses f&#39; ~ fp = (fx - f(x-fx))/fx (a Steffensen step). In this implementation, when <code>fx</code> is too big, a single secant step of <code>f</code> is used.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order2" href="#Roots.Order2"><code>Roots.Order2</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order2()</code></pre><p>The quadratically converging <a href="https://en.wikipedia.org/wiki/Steffensen&#39;s_method#Simple_description">Steffensen</a> method is used for the derivative-free <code>Order2()</code> algorithm. Unlike the quadratically converging Newton&#39;s method, no derivative is necessary, though like Newton&#39;s method, two function calls per step are. Steffensen&#39;s algorithm is more sensitive than Newton&#39;s method to poor initial guesses when <code>f(x)</code> is large, due to how <code>f&#39;(x)</code> is approximated. This algorithm replaces a Steffensen step with a secant step when <code>f(x)</code> is large.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order2B" href="#Roots.Order2B"><code>Roots.Order2B</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order2B()</code></pre><p>Esser&#39;s method. This is a quadratically convergent method that, like Schroder&#39;s method, does not depend on the multiplicity of the zero. Schroder&#39;s method has update step x- r2/(r2-r1) * r1, where ri = f^(i-1)/f^(i). Esser approximates f&#39; ~ f[x-h, x+h], f&#39;&#39; ~ f[x-h,x,x+h], where h = fx, as with Steffensen&#39;s method, Requiring 3 function calls per step. This implementation uses a secant step when |fx| is considered too large.</p><p>Esser, H. Computing (1975) 14: 367. https://doi.org/10.1007/BF02253547 Eine stets quadratisch konvergente Modifikation des Steffensen-Verfahrens</p><p>Example</p><pre><code class="language-none">f(x) = cos(x) - x
g(x) = f(x)^2
x0 = pi/4
find_zero(f, x0, Order2(), verbose=true)        #  3 steps / 7 function calls
find_zero(f, x0, Roots.Order2B(), verbose=true) #  4 / 9
find_zero(g, x0, Order2(), verbose=true)        #  22 / 45
find_zero(g, x0, Roots.Order2B(), verbose=true) #  4 / 10</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order5" href="#Roots.Order5"><code>Roots.Order5</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order5()</code></pre><p>Implements an order 5 algorithm from <em>A New Fifth Order Derivative Free Newton-Type Method for Solving Nonlinear Equations</em> by Manoj Kumar, Akhilesh Kumar Singh, and Akanksha, Appl. Math. Inf. Sci. 9, No. 3, 1507-1513 (2015), DOI: 10.12785/amis/090346. Four function calls per step are needed.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Order8" href="#Roots.Order8"><code>Roots.Order8</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order8()</code></pre><p>Implements an eighth-order algorithm from <em>New Eighth-Order Derivative-Free Methods for Solving Nonlinear Equations</em> by Rajinder Thukral, International Journal of Mathematics and Mathematical Sciences Volume 2012 (2012), Article ID 493456, 12 pages DOI: 10.1155/2012/493456. Four function calls per step are required.</p></div></div></section><pre><code class="language-none">Roots.Roots</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Schroder" href="#Roots.Schroder"><code>Roots.Schroder</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Roots.Schroder()</code></pre><p>Schroder&#39;s method, like Halley&#39;s method, utilizes f, f&#39;, and f&#39;&#39;. Unlike Halley it is quadratically converging, but this is independent of the multiplicity of the zero (cf. Schröder, E. &quot;Über unendlich viele Algorithmen zur Auflösung der Gleichungen.&quot; Math. Ann. 2, 317-365, 1870; http://mathworld.wolfram.com/SchroedersMethod.html).</p><p>Example</p><pre><code class="language-none">m = 2
f(x) = (cos(x)-x)^m
fp(x) = (-x + cos(x))*(-2*sin(x) - 2)
fpp(x) = 2*((x - cos(x))*cos(x) + (sin(x) + 1)^2)
find_zero((f, fp, fpp), pi/4, Roots.Halley())    # 14 steps
find_zero((f, fp, fpp), 1.0, Roots.Schroder())    # 3 steps</code></pre><p>(Whereas, when <code>m=1</code>, Halley is 2 steps to Schroder&#39;s 3.)</p><p>If function evaluations are expensive one can pass in a function which returns (f, f/f&#39;,f&#39;/f&#39;&#39;) as follows</p><pre><code class="language-none">find_zero(x -&gt; (sin(x), sin(x)/cos(x), -cos(x)/sin(x)), 3.0, Roots.Schroder())</code></pre><p>This can be advantageous if the derivatives are easily computed from the value of f, but otherwise would be expensive to compute.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.Secant" href="#Roots.Secant"><code>Roots.Secant</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Order1()</code></pre><p>The <code>Order1()</code> method is an alias for <code>Secant</code>. It specifies the <a href="https://en.wikipedia.org/wiki/Secant_method">secant method</a>. This method keeps two values in its state, <code>x_n</code> and <code>x_n1</code>. The updated point is the intersection point of x axis with the secant line formed from the two points. The secant method uses 1 function evaluation per step and has order <code>(1+sqrt(5))/2</code>.</p></div></div></section><pre><code class="language-none">Roots.SecondDerivative</code></pre><pre><code class="language-none">Roots.StateConverged</code></pre><pre><code class="language-none">Roots.Steffensen</code></pre><pre><code class="language-none">Roots.Tracks</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.TupleWrapper" href="#Roots.TupleWrapper"><code>Roots.TupleWrapper</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">newton((f, f&#39;), x0; xatol=nothing, xrtol=nothing, maxevals=100)
newton(fΔf, x0; xatol=nothing, xrtol=nothing, maxevals=100)</code></pre><p>Newton&#39;s method.</p><p>Function may be passed in as a tuple (f, f&#39;) <em>or</em> as function which returns (f,f/f&#39;).</p><p>Examples:</p><pre><code class="language-none">newton((sin, cos), 3.0)
newton(x -&gt; (sin(x), sin(x)/cos(x)), 3.0, xatol=1e-10, xrtol=1e-10)</code></pre><p>Note: unlike the call <code>newton(f, fp, x0)</code>–which dispatches to a method of <code>find_zero</code>, these two interfaces will specialize on the function that is passed in. This means, these functions will be faster for subsequent calls, but may be slower for an initial call.</p><p>Convergence here is decided by x<em>n ≈ x</em>{n-1} using the tolerances specified, which both default to <code>eps(T)^4/5</code> in the appropriate units.</p></div></div></section><pre><code class="language-none">Roots.UnivariateZeroOptions</code></pre><pre><code class="language-none">Roots.UnivariateZeroState</code></pre><pre><code class="language-none">Roots.__middle</code></pre><pre><code class="language-none">Roots._callable_function</code></pre><pre><code class="language-none">Roots._default_secant_step</code></pre><pre><code class="language-none">Roots._fbracket</code></pre><pre><code class="language-none">Roots._fbracket_diff</code></pre><pre><code class="language-none">Roots._fbracket_ratio</code></pre><pre><code class="language-none">Roots._fz</code></pre><pre><code class="language-none">Roots._fz!</code></pre><pre><code class="language-none">Roots._is_f_approx_0</code></pre><pre><code class="language-none">Roots._method_lookup</code></pre><pre><code class="language-none">Roots._middle</code></pre><pre><code class="language-none">Roots._non_zero</code></pre><pre><code class="language-none">Roots._unitless</code></pre><pre><code class="language-none">Roots.adjust_bracket</code></pre><pre><code class="language-none">Roots.approx_close</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.assess_convergence" href="#Roots.assess_convergence"><code>Roots.assess_convergence</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Roots.assess_convergence(method, state, options)</p><p>Assess if algorithm has converged.</p><p>If alogrithm hasn&#39;t converged returns <code>false</code>.</p><p>If algorithm has stopped or converged, return <code>true</code> and sets one of <code>state.stopped</code>, <code>state.x_converged</code>,  <code>state.f_converged</code>, or <code>state.convergence_failed</code>; as well, a message may be set.</p><ul><li><p><code>state.x_converged = true</code> if <code>abs(xn1 - xn0) &lt; max(xatol, max(abs(xn1), abs(xn0)) * xrtol)</code></p></li><li><p><code>state.f_converged = true</code> if  <code>|f(xn1)| &lt; max(atol, |xn1|*rtol)</code></p></li><li><p><code>state.convergence_failed = true</code> if xn1 or fxn1 is <code>NaN</code> or an infinity</p></li><li><p><code>state.stopped = true</code> if the number of steps exceed <code>maxevals</code> or the number of function calls exceeds <code>maxfnevals</code>.</p></li></ul><p>In <code>find_zero</code>, stopped values (and x_converged) are checked for convergence with a relaxed tolerance.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.bisection" href="#Roots.bisection"><code>Roots.bisection</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">bisection(f, a, b; [xatol, xrtol])</code></pre><p>Performs bisection method to find a zero of a continuous function.</p><p>It is assumed that (a,b) is a bracket, that is, the function has different signs at a and b. The interval (a,b) is converted to floating point and shrunk when a or b is infinite. The function f may be infinite for the typical case. If f is not continuous, the algorithm may find jumping points over the x axis, not just zeros.</p><p>If non-trivial tolerances are specified, the process will terminate when the bracket (a,b) satisfies <code>isapprox(a, b, atol=xatol, rtol=xrtol)</code>. For zero tolerances, the default, for Float64, Float32, or Float16 values, the process will terminate at a value <code>x</code> with <code>f(x)=0</code> or <code>f(x)*f(prevfloat(x)) &lt; 0</code> or <code>f(x) * f(nextfloat(x)) &lt; 0</code>. For other number types, the A42 method is used.</p></div></div></section><pre><code class="language-none">Roots.bisection64</code></pre><pre><code class="language-none">Roots.bracket</code></pre><pre><code class="language-none">Roots.bracketing_error</code></pre><pre><code class="language-none">Roots.callable_function</code></pre><pre><code class="language-none">Roots.check_zero</code></pre><pre><code class="language-none">Roots.choose_smallest</code></pre><pre><code class="language-none">Roots.decide_convergence</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.default_tolerances" href="#Roots.default_tolerances"><code>Roots.default_tolerances</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">default_tolerances(Method, [T], [S])</code></pre><p>The default tolerances for most methods are <code>xatol=zero(T)</code>, <code>xrtol=eps(T)</code>, <code>atol=4eps(S)</code>, and <code>rtol=4eps(S)</code>, with the proper units (absolute tolerances have the units of <code>x</code> and <code>f(x)</code>; relative tolerances are unitless). For <code>Complex{T}</code> values, <code>T</code> is used.</p><p>The number of iterations is limited by <code>maxevals=40</code>, the number of function evaluations is not capped, due to <code>maxfnevals=typemax(Int)</code>, and <code>strict=false</code>.</p></div></div><div><div><pre><code class="language-none">default_tolerances(M, [T], [S])</code></pre><p>For <code>Bisection</code> (or <code>BisectionExact</code>), when the <code>x</code> values are of type <code>Float64</code>, <code>Float32</code>, or <code>Float16</code>, the default tolerances are zero and there is no limit on the number of iterations or function evalutions. In this case, the algorithm is guaranteed to converge to an exact zero, or a point where the function changes sign at one of the answer&#39;s adjacent floating point values.</p><p>For other types, the the <code>A42</code> method (with its tolerances) is used.</p></div></div><div><div><pre><code class="language-none">default_tolerances(::AbstractAlefeldPotraShi, T, S)</code></pre><p>The default tolerances for Alefeld, Potra, and Shi methods are <code>xatol=zero(T)</code>, <code>xrtol=2eps(T)</code>, <code>atol= zero(S), and rtol=zero(S)</code>, with appropriate units; <code>maxevals=45</code>, <code>maxfnevals = Inf</code>; and <code>strict=true</code>.</p></div></div></section><pre><code class="language-none">Roots.derivative_free</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.dfree" href="#Roots.dfree"><code>Roots.dfree</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">dfree(f, xs)</code></pre><p>A more robust secant method implementation</p><p>Solve for <code>f(x) = 0</code> using an alogorithm from <em>Personal Calculator Has Key to Solve Any Equation f(x) = 0</em>, the SOLVE button from the <a href="http://www.hpl.hp.com/hpjournal/pdfs/IssuePDFs/1979-12.pdf">HP-34C</a>.</p><p>This is also implemented as the <code>Order0</code> method for <code>find_zero</code>.</p><p>The inital values can be specified as a pair of two values, as in <code>(a,b)</code> or <code>[a,b]</code>, or as a single value, in which case a value of <code>b</code> is computed, possibly from <code>fb</code>.  The basic idea is to follow the secant method to convergence unless:</p><ul><li><p>a bracket is found, in which case bisection is used;</p></li><li><p>the secant method is not converging, in which case a few steps of a quadratic method are used to see if that improves matters.</p></li></ul><p>Convergence occurs when <code>f(m) == 0</code>, there is a sign change between <code>m</code> and an adjacent floating point value, or <code>f(m) &lt;= 2^3*eps(m)</code>.</p><p>A value of <code>NaN</code> is returned if the algorithm takes too many steps before identifying a zero.</p><p><strong>Examples</strong></p><pre><code class="language-julia">Roots.dfree(x -&gt; x^5 - x - 1, 1.0)</code></pre></div></div></section><pre><code class="language-none">Roots.do_steff_step</code></pre><pre><code class="language-none">Roots.eval</code></pre><pre><code class="language-none">Roots.f_ab</code></pre><pre><code class="language-none">Roots.f_abd</code></pre><pre><code class="language-none">Roots.find_non_zero</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.find_zero" href="#Roots.find_zero"><code>Roots.find_zero</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">find_zero(fs, x0, method; kwargs...)</code></pre><p>Interface to one of several methods for find zeros of a univariate function.</p><p><strong>Initial starting value</strong></p><p>For most methods, <code>x0</code> is a scalar value indicating the initial value in the iterative procedure. (Secant methods can have a tuple specify their initial values.) Values must be a subtype of <code>Number</code> and have methods for <code>float</code>, <code>real</code>, and <code>oneunit</code> defined.</p><p>For bracketing intervals, <code>x0</code> is specified as a tuple or a vector. A bracketing interval, (a,b), is one where f(a) and f(b) have different signs.</p><p><strong>Specifying a method</strong></p><p>A method is specified to indicate which algorithm to employ:</p><ul><li><p>There are methods for bisection where a bracket is specified: <code>Bisection</code>, <code>Roots.A42</code>, <code>FalsePosition</code></p></li><li><p>There are several derivative-free methods: cf. <code>Order0</code>, <code>Order1</code> (secant method), <code>Order2</code> (Steffensen), <code>Order5</code>, <code>Order8</code>, and <code>Order16</code>, where the number indicates the order of the convergence.</p></li><li><p>There are some classical methods where derivatives are required: <code>Roots.Newton</code>, <code>Roots.Halley</code>. (The are not exported.)</p></li></ul><p>For more detail, see the help page for each method (e.g., <code>?Order1</code>).</p><p>If no method is specified, the default method depends on <code>x0</code>:</p><ul><li><p>If <code>x0</code> is a scalar, the default is the slower, but more robust <code>Order0</code> method.</p></li><li><p>If <code>x0</code> is a tuple or vector indicating a <em>bracketing</em> interval, the <code>Bisection</code> method is used. (The exact algorithm depends on the number type, the tolerances, and <code>verbose</code>.)</p></li></ul><p><strong>Specifying the function</strong></p><p>The function(s) are passed as the first argument.</p><p>For the few methods that use a derivative (<code>Newton</code>, <code>Halley</code>, and optionally <code>Order5</code>) a tuple of functions is used.</p><p><strong>Optional arguments (tolerances, limit evaluations, tracing)</strong></p><ul><li><code>xatol</code> - absolute tolerance for <code>x</code> values. Passed to <code>isapprox(x_n, x_{n-1})</code></li><li><code>xrtol</code> - relative tolerance for <code>x</code> values. Passed to <code>isapprox(x_n, x_{n-1})</code></li><li><code>atol</code>  - absolute tolerance for <code>f(x)</code> values.</li><li><code>rtol</code>  - relative tolerance for <code>f(x)</code> values.</li><li><code>maxevals</code>   - limit on maximum number of iterations</li><li><code>maxfnevals</code> - limit on maximum number of function evaluations</li><li><code>strict</code> - if <code>false</code> (the default), when the algorithm stops, possible zeros are checked with a relaxed tolerance</li><li><code>verbose</code> - if <code>true</code> a trace of the algorithm will be shown on successful completion.</li></ul><p>See the help string for <code>Roots.assess_convergence</code> for details on convergence. See the help page for <code>Roots.default_tolerances(method)</code> for details on the default tolerances.</p><p>In general, with floating point numbers, convergence must be understood as not an absolute statement. Even if mathematically x is an answer the floating point realization, say xstar, it may be that f(xstar) - f(x) = f(xstar) ≈ f&#39;(x) ⋅ eps(x), so tolerances must be appreciated, and at times specified.</p><p>For the <code>Bisection</code> methods, convergence is guaranteed, so the tolerances are set to be 0 by default.</p><p>If a bracketing method is passed in after the method specification if a bracket is found, the method will switch. This is what <code>Order0</code> does by default, with a secant step initially.</p><p><strong>Examples:</strong></p><pre><code class="language-none"># default methods
find_zero(sin, 3)  # use Order0()
find_zero(sin, (3,4)) # use Bisection()

# specifying a method
find_zero(sin, 3.0, Order2())              # Use Steffensen method
find_zero(sin, big(3.0), Order16())        # rapid convergence
find_zero(sin, (3, 4), FalsePosition())    # fewer function calls than Bisection(), in this case
find_zero(sin, (3, 4), FalsePosition(8))   # 1 or 12 possible algorithms for false position
find_zero((sin,cos), 3.0, Roots.Newton())  # use Newton&#39;s method
find_zero((sin, cos, x-&gt;-sin(x)), 3.0, Roots.Halley())  # use Halley&#39;s method

# changing tolerances
fn, x0, xstar = (x -&gt; (2x*cos(x) + x^2 - 3)^10/(x^2 + 1), 3.0,  2.9806452794385368)
find_zero(fn, x0, Order2()) - xstar        # 0.014079847201995843
find_zero(fn, x0, Order2(), atol=0.0, rtol=0.0) # error: x_n ≉ x_{n-1}; just f(x_n) ≈ 0
fn, x0, xstar = (x -&gt; (sin(x)*cos(x) - x^3 + 1)^9,        1.0,  1.117078770687451)
find_zero(fn, x0, Order2())                # 1.1122461983100858
find_zero(fn, x0, Order2(), maxevals=3)    # Roots.ConvergenceFailed: 26 iterations needed

# tracing output
find_zero(x-&gt;sin(x), 3.0, Order2(), verbose=true)   # 3 iterations
find_zero(x-&gt;sin(x)^5, 3.0, Order2(), verbose=true) # 22 iterations</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.find_zeros" href="#Roots.find_zeros"><code>Roots.find_zeros</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>find<em>zeros(f, a, b; [no</em>pts=12, k=8, naive=false, xatol, xrtol, atol, rtol])</p><p>Search for zeros of f in the interval [a,b].</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">find_zeros(x -&gt; exp(x) - x^4, -5, 20)        # a few well-spaced zeros
find_zeros(x -&gt; sin(x^2) + cos(x)^2, 0, 10)  # many zeros
find_zeros(x -&gt; cos(x) + cos(2x), 0, 4pi)    # mix of simple, non-simple zeros
f(x) = (x-0.5) * (x-0.5001) * (x-1)          # nearby zeros
find_zeros(f, 0, 2)
f(x) = (x-0.5) * (x-0.5001) * (x-4) * (x-4.001) * (x-4.2)
find_zeros(f, 0, 10)
f(x) = (x-0.5)^2 * (x-0.5001)^3 * (x-4) * (x-4.001) * (x-4.2)^2  # hard to identify
find_zeros(f, 0, 10, no_pts=21)                # too hard for default</code></pre><p>Notes:</p><p>There are two typical cases where the number of zeros may be underreported:</p><ul><li><p>if the initial interval, [a,b], is too wide</p></li><li><p>if there are nearby zeros</p></li></ul><p>The basic algorithm checks for zeros among the endpoints, and then divides the interval (a,b) into <code>no_pts-1</code> subintervals and then proceeds to look for zeros through bisection or a derivative-free method.  As checking for a bracketing interval is relatively cheap and bisection is guaranteed to converge, each interval has <code>k</code> pairs of intermediate points checked for a bracket.</p><p>If any zeros are found, the algorithm uses these to partition (a,b) into subintervals. Each subinterval is shrunk so that the endpoints are not zeros and the process is repeated on the subinterval. If the initial interval is too large, then the naive scanning for zeros may be fruitless and no zeros will be reported. If there are nearby zeros, the shrinking of the interval may jump over them, though as seen in the examples, nearby roots can be identified correctly, though for really nearby points, or very flat functions, it may help to increase <code>no_pts</code>.</p><p>The tolerances are used to shrink the intervals, but not to find zeros within a search. For searches, bisection is guaranteed to converge with no specified tolerance. For the derivative free search, a modification of the <code>Order0</code> method is used, which at worst case compares <code>|f(x)| &lt;= 8*eps(x)</code> to identify a zero. The algorithm might identify more than one value for a zero, due to floating point approximations. If a potential pair of zeros satisfy <code>isapprox(a,b,atol=sqrt(xatol), rtol=sqrt(xrtol))</code> then they are consolidated.</p><p>The algorithm can make many function calls. When zeros are found in an interval, the naive search is carried out on each subinterval. To cut down on function calls, though with some increased chance of missing some zeros, the adaptive nature can be skipped with the argument <code>naive=true</code> or the number of points stepped down.</p><p>The algorithm is derived from one in a <a href="https://github.com/JuliaMath/Roots.jl/pull/113">PR</a> by @djsegal.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.fzero" href="#Roots.fzero"><code>Roots.fzero</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">fzero(f, x0; order=0; kwargs...)
fzero(f, x0, M; kwargs...)
fzero(f, x0, M, N; kwargs...)
fzero(f, x0; kwargs...)
fzero(f, a::Number, b::Numbers; kwargs...)
fzero(f, a::Number, b::Numbers; order=?, kwargs...)
fzero(f, fp, a::Number; kwargs...)</code></pre><p>Find zero of a function using one of several iterative algorithms.</p><ul><li><p><code>f</code>: a scalar function or callable object</p></li><li><p><code>x0</code>: an initial guess, a scalar value or tuple of two values</p></li><li><p><code>order</code>: An integer, symbol, or string indicating the algorithm to  use for <code>find_zero</code>. The <code>Order0</code> default may be specified directly  by <code>order=0</code>, <code>order=:0</code>, or <code>order=&quot;0&quot;</code>; <code>Order1()</code> by <code>order=1</code>,  <code>order=:1</code>, <code>order=&quot;1&quot;</code>, or <code>order=:secant</code>; <code>Order1B()</code> by  `order=&quot;1B&quot;, etc.</p></li><li><p><code>M</code>: a specific method, as would be passed to <code>find_zero</code>, bypassing the use of the <code>order</code> keyword</p></li><li><p><code>N</code>: a specific bracketing method. When given, if a bracket is identified, method <code>N</code> will be used to finish instead of method <code>M</code>.</p></li><li><p><code>a</code>, <code>b</code>: When two values are passed along, if no <code>order</code> value is specified, <code>Bisection</code> will be used over the bracketing interval <code>(a,b)</code>. If an <code>order</code> value is specified, the value of <code>x0</code> will be set to <code>(a,b)</code> and the specified method will be used.</p></li><li><p><code>fp</code>: when <code>fp</code> is specified (assumed to compute the derivative of <code>f</code>), Newton&#39;s method will be used</p></li><li><p><code>kwargs...</code>: See <code>find_zero</code> for the specification of tolerances and other keyword arguments</p></li></ul><p>Examples:</p><pre><code class="language-none">fzero(sin, 3)                  # use Order0() method, the default
fzero(sin, 3, order=:secant)   # use secant method (also just `order=1`)
fzero(sin, 3, Roots.Order1B()) # use secant method variant for multiple roots.
fzero(sin, 3, 4)               # use bisection method over (3,4)
fzero(sin, 3, 4, xatol=1e-6)   # use bisection method until |x_n - x_{n-1}| &lt;= 1e-6
fzero(sin, 3, 3.1, order=1)    # use secant method with x_0=3.0, x_1 = 3.1
fzero(sin, (3, 3.1), order=2)  # use Steffensen&#39;s method with x_0=3.0, x_1 = 3.1
fzero(sin, cos, 3)             # use Newton&#39;s method</code></pre><p>Note: unlike <code>find_zero</code>, <code>fzero</code> does not specialize on the type of the function argument. This has the advantage of making the first use of the function <code>f</code> faster, but subsequent uses slower.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.fzeros" href="#Roots.fzeros"><code>Roots.fzeros</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>fzeros(f, a, b; kwargs...)</code></p><p>Searches for all zeros of <code>f</code> within an interval <code>(a,b)</code>. Assume neither <code>a</code> or <code>b</code> is a zero.</p><p>Dispatches to <code>find_zeros(f, a, b; kwargs...)</code>.</p></div></div></section><pre><code class="language-none">Roots.fΔx</code></pre><pre><code class="language-none">Roots.fΔxΔΔx</code></pre><pre><code class="language-none">Roots.galdino</code></pre><pre><code class="language-none">Roots.galdino_reduction</code></pre><pre><code class="language-none">Roots.guarded_secant_step</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.halley" href="#Roots.halley"><code>Roots.halley</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">Roots.halley(f, fp, fpp, x0; kwargs...)</code></pre><p>Implementation of Halley&#39;s method (cf <code>?Roots.Halley()</code>).</p><p>Arguments:</p><ul><li><p><code>f::Function</code> – function to find zero of</p></li><li><p><code>fp::Function</code> – derivative of <code>f</code>.</p></li><li><p><code>fpp:Function</code> – second derivative of <code>f</code>.</p></li><li><p><code>x0::Number</code> – initial guess</p></li></ul><p>With the <code>FowardDiff</code> package derivatives may be computed automatically. For example,  defining <code>D(f) = x -&gt; ForwardDiff.derivative(f, float(x))</code> allows <code>D(f)</code> and <code>D(D(f))</code> to be used for the first and second derivatives, respectively.</p><p>Keyword arguments are passed to <code>find_zero</code> using the <code>Roots.Halley()</code> method.</p></div></div></section><pre><code class="language-none">Roots.has_converged</code></pre><pre><code class="language-none">Roots.identify_starting_point</code></pre><pre><code class="language-none">Roots.incfn</code></pre><pre><code class="language-none">Roots.include</code></pre><pre><code class="language-none">Roots.incsteps</code></pre><pre><code class="language-none">Roots.init_options</code></pre><pre><code class="language-none">Roots.init_options!</code></pre><pre><code class="language-none">Roots.init_state</code></pre><pre><code class="language-none">Roots.init_state!</code></pre><pre><code class="language-none">Roots.ipzero</code></pre><pre><code class="language-none">Roots.isbracket</code></pre><pre><code class="language-none">Roots.isissue</code></pre><pre><code class="language-none">Roots.isneg</code></pre><pre><code class="language-none">Roots.log_step</code></pre><pre><code class="language-none">Roots.make_intervals!</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.newton" href="#Roots.newton"><code>Roots.newton</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">Roots.newton(f, fp, x0; kwargs...)</code></pre><p>Implementation of Newton&#39;s method: <code>x_n1 = x_n - f(x_n)/ f&#39;(x_n)</code></p><p>Arguments:</p><ul><li><p><code>f::Function</code> – function to find zero of</p></li><li><p><code>fp::Function</code> – the derivative of <code>f</code>.</p></li><li><p><code>x0::Number</code> – initial guess. For Newton&#39;s method this may be complex.</p></li></ul><p>With the <code>FowardDiff</code> package derivatives may be computed automatically. For example,  defining <code>D(f) = x -&gt; ForwardDiff.derivative(f, float(x))</code> allows <code>D(f)</code> to be used for the first derivative.</p><p>Keyword arguments are passed to <code>find_zero</code> using the <code>Roots.Newton()</code> method.</p><p>See also <code>Roots.newton((f,fp), x0) and</code>Roots.newton(fΔf, x0)` for simpler implementations.</p></div></div></section><pre><code class="language-none">Roots.newton_quadratic</code></pre><pre><code class="language-none">Roots.not_near</code></pre><pre><code class="language-none">Roots.quad_vertex</code></pre><pre><code class="language-none">Roots.run_bisection</code></pre><pre><code class="language-none">Roots.secant</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.secant_method" href="#Roots.secant_method"><code>Roots.secant_method</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">secant_method(f, xs; [atol=0.0, rtol=8eps(), maxevals=1000])</code></pre><p>Perform secant method to solve f(x) = 0.</p><p>The secant method is an iterative method with update step given by b - fb/m where m is the slope of the secant line between (a,fa) and (b,fb).</p><p>The inital values can be specified as a pair of 2, as in <code>(a,b)</code> or <code>[a,b]</code>, or as a single value, in which case a value of <code>b</code> is chosen.</p><p>The algorithm returns m when <code>abs(fm) &lt;= max(atol, abs(m) * rtol)</code>. If this doesn&#39;t occur before <code>maxevals</code> steps or the algorithm encounters an issue, a value of <code>NaN</code> is returned. If too many steps are taken, the current value is checked to see if there is a sign change for neighboring floating point values.</p><p>The <code>Order1</code> method for <code>find_zero</code> also implements the secant method. This one will be faster, as there are fewer setup costs.</p><p>Examples:</p><pre><code class="language-julia">Roots.secant_method(sin, (3,4))
Roots.secant_method(x -&gt; x^5 -x - 1, 1.1)</code></pre><p>Note:</p><p>This function will specialize on the function <code>f</code>, so that the inital call can take more time than a call to the <code>Order1()</code> method, though subsequent calls will be much faster.  Using <code>FunctionWrappers.jl</code> can ensure that the initial call is also equally as fast as subsequent ones.</p></div></div></section><pre><code class="language-none">Roots.secant_step</code></pre><pre><code class="language-none">Roots.show_trace</code></pre><pre><code class="language-none">Roots.show_tracks</code></pre><pre><code class="language-none">Roots.sort_smallest</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Roots.steff_step" href="#Roots.steff_step"><code>Roots.steff_step</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>heuristic to get a decent first step with Steffensen steps</p></div></div></section><pre><code class="language-none">Roots.take_a42_step</code></pre><pre><code class="language-none">Roots.update_state</code></pre><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>
