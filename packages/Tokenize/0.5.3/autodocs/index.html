<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · Tokenize.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Tokenize.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><pre><code class="language-none">Tokenize.Lexers</code></pre><pre><code class="language-none">Tokenize.Tokenize</code></pre><pre><code class="language-none">Tokenize.Tokens</code></pre><pre><code class="language-none">Tokenize._precompile_</code></pre><pre><code class="language-none">Tokenize.eval</code></pre><pre><code class="language-none">Tokenize.include</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Tokenize.Lexers.tokenize" href="#Tokenize.Lexers.tokenize"><code>Tokenize.Lexers.tokenize</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">tokenize(x, T = Token)</code></pre><p>Returns an <code>Iterable</code> containing the tokenized input. Can be reverted by e.g. <code>join(untokenize.(tokenize(x)))</code>. Setting <code>T</code> chooses the type of token produced by the lexer (<code>Token</code> or <code>RawToken</code>).</p></div></div></section><pre><code class="language-none">Tokenize.untokenize</code></pre><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>
