var documenterSearchIndex = {"docs": [

{
    "location": "#",
    "page": "Introduction",
    "title": "Introduction",
    "category": "page",
    "text": ""
},

{
    "location": "#PDSampler.jl-Documentation-1",
    "page": "Introduction",
    "title": "PDSampler.jl Documentation",
    "category": "section",
    "text": "PDSampler.jl is a package designed to provide an efficient, flexible, and expandable framework for samplers based on Piecewise Deterministic Markov Processes and their applications. This includes the Bouncy Particle Sampler and the Zig-Zag Sampler. See the references at the bottom of this page.Pages = [\n    \"aboutpdsampler.md\",\n    ]\nDepth = 1The project is hosted by the Alan Turing Institute (ATI). If you encounter problems, please open an issue on Github. If you have comments or wish to collaborate, please open an issue on Github. "
},

{
    "location": "#Using-the-Package-1",
    "page": "Introduction",
    "title": "Using the Package",
    "category": "section",
    "text": "To install the package, use the following command inside the Julia REPL:Pkg.clone(\"PDSampler\")To load the package, use the command:using PDSamplerYou can also run the tests with Pkg.test(\"PDSampler\") and update to the latest Github version with Pkg.update(\"PDSampler\")."
},

{
    "location": "#Examples-1",
    "page": "Introduction",
    "title": "Examples",
    "category": "section",
    "text": "The following examples will introduce you to the functionalities of the package.Pages = [\n    \"examples/ex_gbps1.md\",\n    \"examples/ex_lbps1.md\"\n    ]\nDepth = 1"
},

{
    "location": "#Code-documentation-1",
    "page": "Introduction",
    "title": "Code documentation",
    "category": "section",
    "text": "These pages introduce you to the core of the package and its interface. This is useful if you are looking into expanding the code yourself to add a capacity or a specific model.Pages = [\n    \"techdoc/structure.md\",\n    \"techdoc/coretools.md\",\n    \"techdoc/models.md\",\n    \"techdoc/global.md\",\n    \"techdoc/local.md\"\n    ]\nDepth = 1"
},

{
    "location": "#Contributing-1",
    "page": "Introduction",
    "title": "Contributing",
    "category": "section",
    "text": "Pages = [\n    \"contributing/addingexample.md\",\n    \"contributing/addingfeature.md\"\n]\nDepth = 1"
},

{
    "location": "#References-1",
    "page": "Introduction",
    "title": "References",
    "category": "section",
    "text": "Alexandre Bouchard-Côté, Sebastian J. Vollmer and Arnaud Doucet, The Bouncy Particle Sampler: A Non-Reversible Rejection-Free Markov Chain Monte Carlo Method, arXiv preprint, 2015.\nJoris Bierkens, Alexandre Bouchard-Côté, Arnaud Doucet, Andrew B. Duncan, Paul Fearnhead, Gareth Roberts and Sebastian J. Vollmer, Piecewise Deterministic Markov Processes for Scalable Monte Carlo on Restricted Domains, arXiv preprint, 2017.\nJoris Bierkens, Paul Fearnhead and Gareth Roberts, The Zig-Zag Process and Super-Efficient Sampling for Bayesian Analysis of Big Data, arXiv preprint, 2016.\nChangye Wu, Christian Robert, Generalized Bouncy Particle Sampler, arXiv preprint, 2017."
},

{
    "location": "aboutpdsampler/#",
    "page": "About PDSampler",
    "title": "About PDSampler",
    "category": "page",
    "text": ""
},

{
    "location": "aboutpdsampler/#About-PDSampler-samplers-1",
    "page": "About PDSampler",
    "title": "About PDSampler samplers",
    "category": "section",
    "text": "This page aims at giving a very brief introduction to the concept of Piecewise Deterministic samplers (below we will refer to the algorithm but it should be understood as a class of algorithms). We also give some insight into how it is implemented although we cover the implementation in more details in the technical documentation. This is not meant to be a rigorous presentation of the algorithm (for this, please see the references at the bottom of this page). Rather, we focus here on the \"large building blocks\" behind the algorithm."
},

{
    "location": "aboutpdsampler/#Basic-idea-(global-samplers)-1",
    "page": "About PDSampler",
    "title": "Basic idea (global samplers)",
    "category": "section",
    "text": "The purpose of the algorithm is to be able to evaluate expected values with respect to an arbitrary target distribution which we assume admits a probability density function  pi. For simplicity, we assume that piCto mathbb R^+ with Csubseteq mathbb R^p, convex. The objective is therefore to compute a weighted integral of the form:\\begin{equation}     \\mathbb E{\\pi}[\\varphi(X)] = \\int{C} \\varphi(x)\\pi(x)\\,\\mathrm{d}x \\end{equation}For some reasonable test-function varphiCtomathbb R. The samples generated by this algorithm constitute a piecewise-linear path\\begin{equation}     x(t) = x^{(i)} + v^{(i)}(t-ti) \\quad \\text{for}\\quad t\\in[ti, t_{i+1}] \\end{equation}determined by an initial position x^(0) and velocity v^(0) at time t_0=0 and a set of positive event times t_1t_2dots. Under some conditions for the generation of the times and the velocities, the expected value can then be approximated with\\begin{eqnarray}     \\mathbb E{\\pi}[\\varphi(X)] &\\approx& {1\\over T} \\int0^T\\varphi(x(t))\\mathrm{d}t \\end{eqnarray}and the integral in the right hand side can be expressed as a sum of one-dimensional integrals along each linear segment of the path."
},

{
    "location": "aboutpdsampler/#Generating-times-and-velocities-1",
    "page": "About PDSampler",
    "title": "Generating times and velocities",
    "category": "section",
    "text": "The algorithm generates a sequence of triples of the form (t_i x^(i) v^(i)). Let us assume that the algorithm is currently at one of those event points and show how to compute the next triple. To do so, the algorithm executes the following steps:it generates a travel time tau drawing from a specific random process,\nthe next position is then obtained by traveling along the current ray for the travel time tau i.e.: x^(i+1) = x^(i) + tau v^(i),\na new velocity v^(i+1) is generated.First, we will explore how the travel time is generated and then, how the new velocity is computed."
},

{
    "location": "aboutpdsampler/#Sampling-a-travel-time-1",
    "page": "About PDSampler",
    "title": "Sampling a travel time",
    "category": "section",
    "text": "The effective travel time tau is obtained as the minimum of three times which we will denote by tau_b tau_h tau_r. Following the case, the computation of the new velocity will be different.The first (and most important) one, tau_b, is the first arrival time of an Inhomogenous Poisson Process (IPP) with an intensity that should verify some properties with respect to the target distribution. The Bouncy Particle Sampler (BPS) in particular considers the following intensity with U the negative log-likelihood of the (possibly unnormalised) target pi:\\begin{eqnarray}     \\lambda(\\tau; x, v) = \\langle \\nabla U(x + \\tau v ), v \\rangle^+ \\end{eqnarray}where x and v are the current points and f^+=max(f0). Sampling from an IPP is not trivial in general but there are a few well known techniques that can be applied depending on the target (see references and technical documentation).The other two times are easy to compute:the first, tau_h, is the time of first hit with the boundary of the domain C along the current ray x(t)=x^(i)+(t-t_i)v^(i) for tt_i. This guarantees that the trajectory stays in C and that if the path meets a boundary, it bounces against it.\nthe second, tau_r, is a refreshment time sampled from an exponential distribution with a fixed rate. This guarantees full exploration of C (see BPS paper for details).Note that in the Wu and Robert\'s Generalized Bouncy Particle Sampler (GBPS), no refreshment is needed."
},

{
    "location": "aboutpdsampler/#Computing-a-new-velocity-(BPS)-1",
    "page": "About PDSampler",
    "title": "Computing a new velocity (BPS)",
    "category": "section",
    "text": "Below we discuss the case of the BPS, the computations can be different for different samplers (such as the ZZ) but the essence of the method is the same.As mentioned above, we take tau = min(tau_b tau_h tau_r). Depending on the case, three actions can be takena bounce with tau = tau_b where the new velocity is obtained by specular reflection against the tangent to the gradient of the log-likelihood at the point x(tau_b),\na boundary bounce with tau=tau_h where the new velocity is obtained by specular reflection against the tangent to the boundary at the point of hit x(tau_h),\na refreshment with tau=tau_r where the new velocity is drawn from a reference process such as a spherical Gaussian.The update of the velocity goes as follows for the BPS (specular reflection):\\begin{equation}     v \\leftarrow v - 2\\langle \\nabla U(x), v\\rangle{\\nabla U(x)\\over \\|\\nabla U(x)\\|^2}. \\end{equation}The figure below illustrates the specular reflexion, starting at the red point and going along the current ray (red, dashed line), we have a new event corresponding to a bounce or a hit (blue dot). In both cases, a specular reflection is executed (blue dashed line). The black line represents the tangent to either the boundary at that point or to the log-likelihood depending on the case.(Image: )In Wu and Robert\'s Generalized Bouncy Particle Sampler, the update of the velocity for a standard \"bounce\" event, is a bit different and integrates a draw from a spherical gaussian which removes the need for refreshment (see references). This algorithm is implemented in the toolbox under the name \"GBPS\"."
},

{
    "location": "aboutpdsampler/#Putting-the-pieces-together-1",
    "page": "About PDSampler",
    "title": "Putting the pieces together",
    "category": "section",
    "text": "The simple global sampler can be expressed as follows:Initialize (x^(0) v^(0)) and T the trajectory length\nFor i=12dots, consider the ray x^(i-1)+t v^(i-1) for t0\nSimulate tau_b from an IPP along the ray\nCompute tau_h, simulate tau_r and let tau=min(tau_htau_rtau_b)\nFollowing the case in (b.) compute the new velocity v^(i)\nStore the new triple (t_i-1+tau x^(i-1)+tau v^(i-1) v^(i))\nif t_i ge T stop.\nReturn the path: (t_i x^(i) v^(i))_i=01dotsFollowing this representation, here are the key files of the code:A way to sample from an IPP:  ippsampler.jl.\nA way to define the geometry and in particular to compute the next boundary hit when traveling along a given ray: geometry.jl.\nA way to define how the velocity needs to be updated (reflection, refreshments): kernels.jl.\nA way to store a path formed of triples and compute integrals along it: path.jl.\nA core loop: simulate.jl.We describe those in details and give explanations as to how to expand the toolbox in the technical documentation part."
},

{
    "location": "aboutpdsampler/#Local-Samplers-1",
    "page": "About PDSampler",
    "title": "Local Samplers",
    "category": "section",
    "text": ""
},

{
    "location": "aboutpdsampler/#Basics-of-factor-graphs-1",
    "page": "About PDSampler",
    "title": "Basics of factor graphs",
    "category": "section",
    "text": "Piecewise Deterministic samplers can be adapted to explore the structure of the target distribution if it factorizes according to a factor graph i.e.:\\begin{equation}     \\pi(x) \\propto \\prod{f\\in F} \\gammaf (x_f), \\end{equation}where gamma_f are non-negative functions of the variables x_f=(x_f_1x_f_2dots), a subset of all the variables. A very simple example is a Hidden Markov Model corresponding to a factor graph in the form of a chain as illustrated below:(Image: )Distributions that factorize according to that factor graph have the form:\\begin{equation}     \\pi(x) \\propto \\gamma1(x1,x2)\\gamma2(x2,x3)\\gamma3(x3,x_4). \\end{equation}The idea behind the local samplers is to try to exploit the conditional dependence structure represented by the factor graph."
},

{
    "location": "aboutpdsampler/#Local-BPS-1",
    "page": "About PDSampler",
    "title": "Local BPS",
    "category": "section",
    "text": "A rough idea of how the local BPS works is that it corresponds to an interacting collection of global BPS samplers, one for each of the factors. In essence, each iteration of the algorithm works as follows:it picks a factor fin F following a priority queue,\na new event is computed for x_f following a global BPS-type procedure,\nthe priority queue is updated for the entries corresponding to f, and all fin F that share a variable with f.The priority queue therefore has one entry for each factor. These entries correspond to first arrival times of IPPs corresponding to the factor."
},

{
    "location": "aboutpdsampler/#Sampling-from-an-IPP-1",
    "page": "About PDSampler",
    "title": "Sampling from an IPP",
    "category": "section",
    "text": ""
},

{
    "location": "aboutpdsampler/#Inversion-1",
    "page": "About PDSampler",
    "title": "Inversion",
    "category": "section",
    "text": ""
},

{
    "location": "aboutpdsampler/#Thinning-1",
    "page": "About PDSampler",
    "title": "Thinning",
    "category": "section",
    "text": ""
},

{
    "location": "aboutpdsampler/#References-1",
    "page": "About PDSampler",
    "title": "References",
    "category": "section",
    "text": "Alexandre Bouchard-Côté, Sebastian J. Vollmer and Arnaud Doucet, The Bouncy Particle Sampler: A Non-Reversible Rejection-Free Markov Chain Monte Carlo Method, arXiv preprint, 2015.\nJoris Bierkens, Alexandre Bouchard-Côté, Arnaud Doucet, Andrew B. Duncan, Paul Fearnhead, Gareth Roberts and Sebastian J. Vollmer, Piecewise Deterministic Markov Processes for Scalable Monte Carlo on Restricted Domains, arXiv preprint, 2017.\nJoris Bierkens, Paul Fearnhead and Gareth Roberts, The Zig-Zag Process and Super-Efficient Sampling for Bayesian Analysis of Big Data, arXiv preprint, 2016.\nChangye Wu, Christian Robert, Generalized Bouncy Particle Sampler, arXiv preprint, 2017."
},

{
    "location": "examples/ex_gbps1/#",
    "page": "Global BPS",
    "title": "Global BPS",
    "category": "page",
    "text": ""
},

{
    "location": "examples/ex_gbps1/#Global-BPS-(Truncated-Gaussian)-1",
    "page": "Global BPS",
    "title": "Global BPS (Truncated Gaussian)",
    "category": "section",
    "text": "(the code for this example can be found here, note that the doc rendered here was automatically generated, if you want to fix it, please do it in the julia code directly)In this example we use the global Bouncy Particle Sampler on 2D Gaussian truncated to the positive orthan to show how to declare a BPS model.(Image: )Start by loading the library:using PDSampler, Random\nyou then need to define two elements:a geometry (boundaries)\nan energy (gradient of the log-likelihood of the target)The positive orthan corresponds to a simple Polygonal domain where the boundaries are the axes. The normal to these boundaries (ns) are therefore unit vectors and the intercepts (a) are zero. A polygonal domain is then declared with the constructor Polygonal.p = 2\n# normal to faces and intercepts\nns, a = diagm(0=>ones(p)), zeros(p)\ngeom  = Polygonal(ns, a)\nThe function nextboundary returns a function that can compute the next boundary on the current ray [x,x+tv] with t>0 as well as the time of the hit.nextbd(x, v) = nextboundary(geom, x, v)\nThe model then needs to be specified: you need to define a function of the form gradll(x) which can return the gradient of the log-likelihood at some point x. Here, let us consider a 2D gaussian.# here we build a valid precision matrix. The cholesky decomposition of\n# the covariance matrix will be useful later to build a sensible\n# starting point for the algorithm.\nRandom.seed!(12)\nP1  = randn(p,p)\nP1 *= P1\'\nP1 += norm(P1)/100*diagm(0=>ones(p))\nC1  = inv(P1); C1 += C1\'; C1/=2;\nL1  = cholesky(C1).L\nmu  = zeros(p) .+ 1.\nmvg = MvGaussianCanon(mu, P1)\nHere, we have defined the gaussian through the Canonical representation i.e.: by specifying a mean and a precision matrix.Every model must implement a gradloglik function returning the gradient of the log-likelihood at a point x.gradll(x) = gradloglik(mvg, x)\nNext, you need to define the function which can return the first arrival time of the corresponding Inhomogenous Poisson Process.Note that you could be using nextevent_zz here as well if you wanted to use the Zig-Zag sampler (and you could implement other kernels as well).nextev(x, v) = nextevent_bps(mvg, x, v)\nFor a Gaussian (and some other simple distributions), this is analytical through an inversion-like method.Finally, you need to specify the parameters of the simulation such as the starting point and velocity, the length of the path generated, the rate of refreshment and the maximum number of gradient evaluations.T    = 1000.0   # length of path generated\nlref = 2.0      # rate of refreshment\nx0   = mu+L1*randn(p) # sensible starting point\nv0   = randn(p) # starting velocity\nv0  /= norm(v0) # put it on the sphere (not necessary)\n# Define a simulation\nsim = Simulation( x0, v0, T, nextev, gradll,\n                  nextbd, lref ; maxgradeval = 10000)\nAnd finally, generate the path and recover some details about the simulation.(path, details) = simulate(sim)\nThe path object belongs to the type Path and can be sampled using samplepath.A crude sanity check is for example to check that the estimated mean obtained through quadrature along the path yields a similar result as a basic Monte Carlo estimator.# Building a basic MC estimator\n# (taking samples from 2D MVG that are in positive orthan)\nsN = 1000\ns  = broadcast(+, mu, L1*randn(p,sN))\nmt = zeros(2)\nnp = 0\n# Sum for all samples in the positive orthan\nss = [s; ones(sN)\']\nmt = sum(ss[:,i] for i in 1:sN if !any(e->e<0, ss[1:p,i]))\nmt = mt[1:p]/mt[end]\nYou can now compare the norm of mt (a crude MC estimator) to pathmean(path) (computing the integrals along the segments of the path) and you will see that the relative error is below 5%."
},

{
    "location": "examples/ex_lbps1/#",
    "page": "Local BPS",
    "title": "Local BPS",
    "category": "page",
    "text": ""
},

{
    "location": "examples/ex_lbps1/#Local-BPS-(Chain-of-Gaussians)-1",
    "page": "Local BPS",
    "title": "Local BPS (Chain of Gaussians)",
    "category": "section",
    "text": "(the code for this example can be found here, note that the doc rendered here was automatically generated, if you want to fix it, please do it in the julia code directly)The approach to using the local BPS is much the same as for the global one except that you need to specify a FactorGraph. That object will contain the structure of the factor graph (i.e.: which factor is connected to which variables) as well as the list of all factors (which have a lgradll and nextevent since each factor can be seen individually as a small BPS).Below, we show how to declare a chain of bivariate gaussians:using PDSampler, Random\nnfac = 3 # number of factors\n\nmvg = MvGaussianStandard(zeros(2),diagm(0=>ones(2)))\n\n# all factors have that same likelihood\nchainfactor(i) = Factor(\n                    (x,v)->nextevent_bps(mvg, x, v),\n                    (x)->gradloglik(mvg, x),\n                    i )\n\n# assemble into a chain graph\nchain = chaingraph([chainfactor(i) for i in 1:nfac])\nThis is a simple graph with a known structure so that it\'s already defined through the chaingraph function (in src/local/factorgraph.jl). For an arbitrary graph, you would need to provide two things:the structure of the factor graph: a list of list where each element corresponds to a factor and the corresponding list contains the indices of the variables attached to that factor\nthe list of factorsThe rest is very similar to the global BPS:Random.seed!(123)\nlambdaref  = .01\nmaxnevents = 10000\nT          = Inf\nnvars      = chain.structure.nvars\nx0         = randn(nvars)\nv0         = randn(nvars)\nv0        /= norm(v0)\n\nlsim = LocalSimulation(chain, x0, v0, T, maxnevents, lambdaref)\n\n(all_evlist, details) = simulate(lsim)\nThe all_evlist object contains a list of EventList corresponding to what happened on each of the factors. It can also be sampled using samplelocalpath (cf. src/local/event.jl)."
},

{
    "location": "techdoc/structure/#",
    "page": "Code structure",
    "title": "Code structure",
    "category": "page",
    "text": ""
},

{
    "location": "techdoc/structure/#Code-structure-1",
    "page": "Code structure",
    "title": "Code structure",
    "category": "section",
    "text": "In this part, we discuss briefly how the code is organised and the role of the key files as well as the workflow for extending the code."
},

{
    "location": "techdoc/structure/#General-notes-1",
    "page": "Code structure",
    "title": "General notes",
    "category": "section",
    "text": "A few design choices have been made and should be respected (or modified with a good reason and this section scrapped):Float stands for Float64 assuming that everything is done on 64-bit architecture.\nWhen possible, abstract types are created to suggest a hierarchy of types. This helps readability and generalisation (see for example in ippsampler.jl, abstract type: IPPSamplingMethod and Thinning <: IPPSamplingMethod and LinearBound <: Thinning)"
},

{
    "location": "techdoc/structure/#Source-files-1",
    "page": "Code structure",
    "title": "Source files",
    "category": "section",
    "text": "The structure of the src/ folder is as follows:├── PDSampler.jl\n├── geometry.jl\n├── ippsampler.jl\n├── kernels.jl\n├── local\n│   ├── event.jl\n│   ├── factorgraph.jl\n│   └── simulate.jl\n├── models\n│   ├── logreg.jl\n│   ├── mvgaussian.jl\n│   └── pmf.jl\n├── path.jl\n└── simulate.jlThe central file is PDSampler.jl which serves one key purpose: declaring what the package needs (Compat, Polynomials, ...) and including the files that contain the effective pieces of code. It also exports some generic functions that are used throughout the package.Note: in Julia everything should be wrapped around by a module. The using PkgName indicates that we want to have access to the functions exported by the package PkgName in the current scope (e.g.: the scope of the wrapping module or that of the REPL). The export functionName indicates that if another user wants to use our module (by entering using PDSampler) s/he will have access to all of those functions directly.Here is a high-level overview of the rest of the folder structure:geometry, ippsampler, kernels (specific documentation): generic tools used throughout the package\npath, simulate (specific documentation): tools to describe the path and how the simulation is run in the global case.\nmodels/* (specific documentation): to define specific models, their likelihood, gradient of log-likelihood etc.\nlocal/* (specific documentation): to define events, factor graphs and how to run the algorithm in the local case."
},

{
    "location": "techdoc/structure/#Test-files-1",
    "page": "Code structure",
    "title": "Test files",
    "category": "section",
    "text": "The test/ folder contains a number of test files (one for each source file and one per executable example):├── ex_gbps1.jl\n├── ex_lbps1.jl\n├── gaussian_test.jl\n├── geometry_test.jl\n├── ippsampler_test.jl\n├── kernels_test.jl\n├── local_event_test.jl\n├── local_factorgraph_test.jl\n├── local_simulate_test.jl\n├── logreg_test.jl\n├── path_test.jl\n├── pmf_test.jl\n├── runtests.jl\n└── simulate_test.jlNote that a few start with ex_ these are executable examples which also serve as partial tests and as documentation. The philosophy here is to have as many tests as possible that would break if anything is introduced in the code that could break other parts. These tests are not perfect and some may indeed need to be reinforced/fixed but at least provide some safeguards against harmful code modifications."
},

{
    "location": "techdoc/structure/#Doc-files-1",
    "page": "Code structure",
    "title": "Doc files",
    "category": "section",
    "text": "The docs/ folder contains a large number of files. The part that is of interest is represented below:├── build\n│   ├── ...\n├── make.jl\n├── readexamples.jl\n├── site\n│   ├── ...\n└── src\n    ├── aboutpdmp.md\n    ├── assets\n    │   ├── ...\n    ├── contributing\n    │   ├── addingexample.md\n    │   └── addingfeature.md\n    ├── examples\n    │   ├── ex_gbps1.md\n    │   └── ex_lbps1.md\n    ├── index.md\n    └── techdoc\n        ├── coretools.md\n        ├── global.md\n        ├── local.md\n        ├── models.md\n        ├── structure.md\n        └── types.mdThe make.jl file is the central file which dictates how the documentation is to be built. It can be executed in a Julia REPL (provided you have added the Documenter package) and you can then locally see the updated version of the documentation by opening build/index.html. The readexamples.jl file transforms the example files test/ex_* into publishable examples.Note: if you are editing the documentation and wish to compile it, the recommendation is to keep your REPL open. The first compiling will be a bit slow (Documenter warming up) the next ones will be pretty much instantaneous with possibly a lot of warning messages about docstrings not having been found for every function, you can safely ignore all of that and just refresh the page build/index.html in your browser."
},

{
    "location": "techdoc/coretools/#",
    "page": "Core tools",
    "title": "Core tools",
    "category": "page",
    "text": ""
},

{
    "location": "techdoc/coretools/#td-coretools-1",
    "page": "Core tools",
    "title": "Core tools",
    "category": "section",
    "text": "Link to the source files:geometry.jl\nippsampler.jl\nkernels.jl"
},

{
    "location": "techdoc/coretools/#Geometry-1",
    "page": "Core tools",
    "title": "Geometry",
    "category": "section",
    "text": "The geometry.jl code exports the following immutable types:Unconstrained <: Domain,\nPolygonal <: Domain.and a functionnextboundaryAny geometry type needs to have a nextboundary function associated with it of the form nextboundary(g, x, v) where g refers to a geometry object, x to the position and v to the velocity. The aim of that function is to:return a time of first hit tau_h (following the ray x+vt, for t0),\nreturn the normal to the boundary at that hitting point.So for example, the Unconstrained is an empty type and the associated nextboundary function just returns (NaN, NaN) indeed a boundary will never be crossed and there is no normal. These NaN are processed by calling functions.The Polygonal domain requires the definition of the normals and the intercepts. The nextboundary function is pretty simple (intersection of lines). Note a few tricks for numerical stability:near parallel case can be ignored (the crossing time will be huge compared to bouncing time or refreshment time and therefore we can just ignore it)\nnegative times can be ignored (we\'re only going forward)\ntimes that are very close to zero are ignored (means that we are currently already very close to the boundary meaning that we will bounce away)"
},

{
    "location": "techdoc/coretools/#Sampling-from-an-IPP-1",
    "page": "Core tools",
    "title": "Sampling from an IPP",
    "category": "section",
    "text": "The ippsampler.jl exports the following immutable types:NextEvent,\nLinearBound <: Thinning <: IPPSamplingMethod,and the following functionsnextevent_bps,\nnextevent_zz.The NextEvent type encapsulates an object returned when sampling from the IPP is required. It contains:a bouncing time\na function returning whether the bouncing time should be accepted or not (see Thinning)\na flipindex (see nextevent_zz)The functions nextevent_* are overloaded for the different possible sampling cases."
},

{
    "location": "techdoc/coretools/#Exact-sampling-1",
    "page": "Core tools",
    "title": "Exact sampling",
    "category": "section",
    "text": "Exact sampling is possible for specific distributions. In that case, the dobounce function returns true all the time. An example is the MvGaussian model for which we can indeed sample from the corresponding IPP analytically. See for example the definition ofnextevent_bps{T<:Vector{Float}}(g::MvGaussian, x::T, v::T)::NextEventNote the signature of the function. The first parameter indicates how the sampling should be done and the information to do so. The second and third parameters indicate the ray along which the bouncing time should be produced."
},

{
    "location": "techdoc/coretools/#Sampling-via-thinning-1",
    "page": "Core tools",
    "title": "Sampling via thinning",
    "category": "section",
    "text": "The LinearBound type allows to define a linear upper bound on the intensity of the IPP when you have access to a global bound on the eigenvalues of the Hessian (see this paper for more details). An accept reject step can then be performed in the nextevent_* function (dobounce).An example is the Bayesian logistic regression for which you do have such a bound.In that case the nextevent_bps returns a bouncing time computed thanks to the upper bound and the dobounce corresponds to a simple accept/reject step."
},

{
    "location": "techdoc/coretools/#Kernels-1",
    "page": "Core tools",
    "title": "Kernels",
    "category": "section",
    "text": "The kernels.jl code exports a few functions, all of which define how the velocity should be updated in a variety of circumstances. Some of these functions have an exclamation mark attached to them indicating that the transformation is done in place (for efficiency). The refresh_* functions help indicate how the velocity should be refreshed (e.g. drawn from a spherical gaussian). The reflect_* indicate how the velocity should bounce (e.g. specular reflection)."
},

{
    "location": "techdoc/models/#",
    "page": "Models",
    "title": "Models",
    "category": "page",
    "text": ""
},

{
    "location": "techdoc/models/#td-models-1",
    "page": "Models",
    "title": "Local sampler",
    "category": "section",
    "text": "Link to the source files:models/mvgaussian.jl\nmodels/logreg.jl\nmodels/pmf.jl"
},

{
    "location": "techdoc/models/#Generic-model-1",
    "page": "Models",
    "title": "Generic model",
    "category": "section",
    "text": "A model must be an immutable type with an associated gradloglik function. It is important this function be coded as efficiently as possible since it is called a large number of time in any simulation."
},

{
    "location": "techdoc/models/#Multivariate-Gaussian-1",
    "page": "Models",
    "title": "Multivariate Gaussian",
    "category": "section",
    "text": ""
},

{
    "location": "techdoc/models/#Hierarchy-of-types-1",
    "page": "Models",
    "title": "Hierarchy of types",
    "category": "section",
    "text": "Multiple parametrisation are possible. Some being more efficient than others while some are maybe more intuitive than others.MvGaussian (abstract)\n| — MvGaussianStandard\n| — MvDiagonalGaussian\n| — MvGaussianCanon\n| — MvGaussianNaturalIn the sequel we write mu the mean, Sigma the covariance matrix and Omega the precision matrix. The different way to parametrise the distributions are as follows:MvGaussianStandard, direct: (mu Sigma), indirect: (\\Omega\\mu,\\Omega)\nMvDiagonalGaussian, direct: (mu (sigma_i)), indirect: (sigma_i^2)\nMvGaussianCanon, direct: (mu Omega), indirect: (Omegamu)\nMvGaussianNatural, direct: (Omegamu-Omega)The preferred way is the \"canonical\" representation (most efficient).Note: \"direct\" means that these are the parameters passed to the constructor while \"indirect\" means that these values are computed when the constructor is called."
},

{
    "location": "techdoc/models/#Auxiliary-functions-1",
    "page": "Models",
    "title": "Auxiliary functions",
    "category": "section",
    "text": "Internally, the types mentioned above are shortened to MvGS, MvDG etc. Then a number of simplifying functions are defined (these simplify the computation of the log-likelihood and gradient of the log-likelihood)mvg_mu to recover mu\nmvg_precmu to recover Omegamu\nmvg_precmult taking a point and multiplying it by Omegagradloglik is then trivial to compute."
},

{
    "location": "techdoc/models/#Logistic-Regression-1",
    "page": "Models",
    "title": "Logistic Regression",
    "category": "section",
    "text": "The logistic regression considers a feature matrix X, a response y, the Lipschitz constant associated to it and dimensionality parameters."
},

{
    "location": "techdoc/models/#Auxiliary-functions-2",
    "page": "Models",
    "title": "Auxiliary functions",
    "category": "section",
    "text": "A number of auxiliary functions are defined to prevent numerical instabilities and ensure that the computation of the log-likelihood and gradient of the log-likelihood can be expressed simply.The gradloglik_cv considers a control-variate gradient developed around a given point (see this paper for more details).Note: the response is in -11."
},

{
    "location": "techdoc/models/#Probabilistic-Matrix-Factorisation-1",
    "page": "Models",
    "title": "Probabilistic Matrix Factorisation",
    "category": "section",
    "text": "This model considers a normal distribution on every entry of a matrix r_ij:\\begin{equation} \\mathcal N(r_{ij}; \\langle u,v\\rangle , \\sigma^2) \\end{equation}The resulting intensity can be shown to be a truncated cubic for which we can in fact also do exact sampling.The pmf_case* correspond to the various possible cases depending on where the roots of the cubic are."
},

{
    "location": "techdoc/global/#",
    "page": "Global sampler",
    "title": "Global sampler",
    "category": "page",
    "text": ""
},

{
    "location": "techdoc/global/#td-globalsampler-1",
    "page": "Global sampler",
    "title": "Global sampler",
    "category": "section",
    "text": "Link to the source files:path.jl\nsimulate.jl"
},

{
    "location": "techdoc/global/#Path-1",
    "page": "Global sampler",
    "title": "Path",
    "category": "section",
    "text": "The path.jl file exports a type Path and a few functions that apply on such an object.A Path object encapsulatesxs a matrix of size p times N_e where p is the dimension and N_e are the number of events recorded\nts a vectof of times associated with the events\np the dimension\nnseg the number of segments"
},

{
    "location": "techdoc/global/#Auxiliary-type-1",
    "page": "Global sampler",
    "title": "Auxiliary type",
    "category": "section",
    "text": "The type Segment is useful to encapsulate the information contained between two events. It contains:ta, tb the times at the two events\nxa, xb the positions\ntau (implicit) the travel time corresponding to the segment or (t_b-t_a)\nv (implicit) the velocity along the segment"
},

{
    "location": "techdoc/global/#Auxiliary-functions-1",
    "page": "Global sampler",
    "title": "Auxiliary functions",
    "category": "section",
    "text": "getsegment retrieves a segment starting at time Path.ts[j]\nsamplepath takes a time or a list of times and returns the position along the Path object at those times\nquadpathpoly does a simple analytical integration along the path for simple test functions of the form varphi(x)=P(x) where P is a polynomial (for each dimension)\npathmean computes the mean using quadpathpoly where the polynomial is just x\nesspath computation of the ESS corresponding to a number of samples equally spaced along the path. It tries to achieve a specific ratio and increases the number of samples until it achieves it."
},

{
    "location": "techdoc/global/#Simulate-1",
    "page": "Global sampler",
    "title": "Simulate",
    "category": "section",
    "text": "The simulate.jl file is the main file for the Global Sampler. It contains one main immutable object which contains all of the parameters of the simulation. This is convenient if multiple parameters need to be tested.A number of default parameters are pre-encoded but some parameters are essential (starting point, starting velocity, etc)."
},

{
    "location": "techdoc/global/#Simulate-function-1",
    "page": "Global sampler",
    "title": "Simulate function",
    "category": "section",
    "text": "This function should mimic rather closely the original paper. Note in the main loop:tau = min(bounce.tau, taubd, tauref)corresponds to finding which action needs to be executed (normal bounce, boundary bounce or refreshment). After this one of three branches is executed:if tau==bounce.tau\n    ...\nelseif tau==taubd\n    ...\nelse\n    ...\nendThe first branch corresponds to a bounce against the level set of the log-likelihood, the second to a boundary bounce and third a refreshment.In the first branch, an explicit call to bounce.dobounce checks whether to thin the event or not. If the time is accepted then the velocity is refreshed otherwise the whole loop is ignored."
},

{
    "location": "techdoc/local/#",
    "page": "Local sampler",
    "title": "Local sampler",
    "category": "page",
    "text": ""
},

{
    "location": "techdoc/local/#td-localsampler-1",
    "page": "Local sampler",
    "title": "Local sampler",
    "category": "section",
    "text": "Link to the source files:local/event.jl\nlocal/factorgraph.jl\nlocal/simulate.jl"
},

{
    "location": "techdoc/local/#Event-1",
    "page": "Local sampler",
    "title": "Event",
    "category": "section",
    "text": ""
},

{
    "location": "techdoc/local/#Hierarchy-of-types-1",
    "page": "Local sampler",
    "title": "Hierarchy of types",
    "category": "section",
    "text": "The events in the local settings are triples of the form (x,v,t). These can be encapsulated in the immutable Event type. Every node in the graph has a list of such events attached to it. For efficiency reasons, the list of event is not actually a list of Event but rather another type EventList which allows traversing the corresponding data structure efficiently.The list of EventList (i.e. all events that have happened on the graph) is encapsulated in another type AllEventList."
},

{
    "location": "techdoc/local/#EventList-1",
    "page": "Local sampler",
    "title": "EventList",
    "category": "section",
    "text": "The EventList type corresponds to what is stored by a single node of the factor graph. It contains the list of positions xs, the list of velocities vs and the list of times ts associated with that node.The function getevent, getlastevent, pushevent!, getlocalsegment, samplelocalpath, quadpathpoly and pathmean all work on an EventList object.In other words, an EventList is analogous to the Path object of the global sampler."
},

{
    "location": "techdoc/local/#AllEventList-1",
    "page": "Local sampler",
    "title": "AllEventList",
    "category": "section",
    "text": "This is just a vector of EventList. It also keeps track of the types associated with each EventList. Indeed, each node may correspond to a variable of different dimensionality so these types make initialisation procedures simpler."
},

{
    "location": "techdoc/local/#Auxiliary-functions-1",
    "page": "Local sampler",
    "title": "Auxiliary functions",
    "category": "section",
    "text": "getevent retrieve an event in an EventList\ngetlastevent retrieve the last event of an EventList\npushevent! add an event to an EventList\ngetlocalsegment get an event and the subsequent event\nsamplelocalpath sample the variable corresponding to a node by taking samples along the path described by the corresponding EventList\nquadpathpoly integrate a polynomial along the path described by an EventList"
},

{
    "location": "techdoc/local/#Factor-Graph-1",
    "page": "Local sampler",
    "title": "Factor Graph",
    "category": "section",
    "text": ""
},

{
    "location": "techdoc/local/#Hierarchy-of-types-2",
    "page": "Local sampler",
    "title": "Hierarchy of types",
    "category": "section",
    "text": "All types are immutables (define the graph).The base type is a Factor\nThe connection pattern is a FactorGraphStruct\nThe list of factors + structure forms a FactorGraph"
},

{
    "location": "techdoc/local/#Factor-1",
    "page": "Local sampler",
    "title": "Factor",
    "category": "section",
    "text": "A Factor encapsulatesnextevent a function which is able to produce a first arrival time from the IPP corresponding to that factor\ngll the gradient of the loglikelihood attached to that factor\nindex this is a dummy index to be able to refer to specific factors in the factor graph"
},

{
    "location": "techdoc/local/#FactorGraphStruct-1",
    "page": "Local sampler",
    "title": "FactorGraphStruct",
    "category": "section",
    "text": "A FactorGraphStruct encapsulatesflist a list of list, every entry corresponds to a factor and the list of variables that factor is connected to.implicitly it also encapsulatesvlist a list of list, every entry corresponds to a variable and the list of factors that variable is connected to.\nnfactors, nvars the number of factors and variablesThe function chainstruct defines a returns a FactorGraphStruct corresponding to a chain with a given number of nodes (variables)."
},

{
    "location": "techdoc/local/#FactorGraph-1",
    "page": "Local sampler",
    "title": "FactorGraph",
    "category": "section",
    "text": "A FactorGraph encapsulatesstructure a FactorGraphStruct object\nfactors a vector of Factor objects"
},

{
    "location": "techdoc/local/#Auxiliary-functions-2",
    "page": "Local sampler",
    "title": "Auxiliary functions",
    "category": "section",
    "text": "assocvariables and assocfactors return the indices of the associated variables to a factor (resp. factors to a variable)\nlinkedfactors for a given factor returns the list of factors which share a variable with it"
},

{
    "location": "techdoc/local/#Simulate-1",
    "page": "Local sampler",
    "title": "Simulate",
    "category": "section",
    "text": "That file has the same structure as that for the global sampler with one major LocalSimulation object encapsulating all the parameters of a given simulation.The main loop uses a number of helper functions ls_* in order to make the logic appear more clearly. Focusing on the main loop for now, it should be clear that is centered around a priority queue.(fidx, tbounce) = peek(pq)\n...\nif t < tref\n    ...\nelse\n    ...\nendSo the minimum time is recovered from the priority queue as well as the index of the corresponding factor. Then, there is a check to see whether we are in the bouncing scenario (first branch) or the refreshment scenario (second branch)."
},

{
    "location": "techdoc/local/#Helper-functions-1",
    "page": "Local sampler",
    "title": "Helper functions",
    "category": "section",
    "text": ""
},

{
    "location": "techdoc/local/#Initialisation-1",
    "page": "Local sampler",
    "title": "Initialisation",
    "category": "section",
    "text": "The function ls_init initialises an AllEventList object corresponding to the graph as well as a priority queue."
},

{
    "location": "techdoc/local/#Reshape,-Random-1",
    "page": "Local sampler",
    "title": "Reshape, Random",
    "category": "section",
    "text": "Once a factor is selected, the operations are very similar to the global BPS. But once an event is generated, it is necessary to slice it according to the different nodes so that they all store the relevant portion of information. The ls_reshape function reshapes a generated object into the appropriate format.The ls_random generates random numbers of the appropriate dimensions corresponding to an event list."
},

{
    "location": "techdoc/local/#Retrieve-1",
    "page": "Local sampler",
    "title": "Retrieve",
    "category": "section",
    "text": "The ls_retrieve function is called to access a specific factor. For that factor it retrieves:The positions xf, a list of positions for each nodes associated with the factor interpolated at a time t\nThe velocities vf, a list of velocities for each nodes associated with the factor\nThe gradient at xf (as seen from the factor)\nThe index of the variables associated with the factorThe interpolation is done following the method highlighted in the paper (recover the last event and follow the ray for required time)."
},

{
    "location": "techdoc/local/#Update-Priority-Queue-1",
    "page": "Local sampler",
    "title": "Update Priority Queue",
    "category": "section",
    "text": "For a given factor, the ls_updatepq! updates the current priority queue by generating an event (possibly with thinning) for the required factor and storing it in the priority queue then returning that priority queue.That function is usually called after a call of ls_retrieve: i.e. the interpolated position is recovered then correspondingly an event is generated and stored in the priority queue using ls_updatepq!."
},

{
    "location": "techdoc/local/#Save-update-1",
    "page": "Local sampler",
    "title": "Save update",
    "category": "section",
    "text": "Once a factor has been triggered and a new event computed, it is pushed in the relevant EventList objects using this ls_saveupdate! function which updates the all_eventlist object corresponding to the general simulation."
},

{
    "location": "techdoc/local/#Refreshment-1",
    "page": "Local sampler",
    "title": "Refreshment",
    "category": "section",
    "text": "The function ls_refreshment triggers a refreshment for the current factor and the corresponding refreshment of the priority queue."
},

{
    "location": "contributing/addingexample/#",
    "page": "New example",
    "title": "New example",
    "category": "page",
    "text": ""
},

{
    "location": "contributing/addingexample/#Adding-an-example-1",
    "page": "New example",
    "title": "Adding an example",
    "category": "section",
    "text": "Examples are a great way to showcase how to make use of a specific feature. We consider two types of examples:a simple example (running in < 10 seconds)\na complex example (the complement of the first category)The first category is great as they can be used as tests and as documentation.The process is somewhat automated here and essentially all you have to do is write the example in the test directory and comment it accordingly, we show this below."
},

{
    "location": "contributing/addingexample/#Syntax-for-the-example-1",
    "page": "New example",
    "title": "Syntax for the example",
    "category": "section",
    "text": "Let\'s say you have an example which can be run in a few seconds and uses a new feature. You can effectively use it as a unit test by itself. To respect conventions, please name your example ex_NAME.jl and put it in test/.Start your code byusing Base.TestThen a few markers should be considered:#@startexample NAME_OF_EXAMPLE indicates that you start the code of the example proper, everything between that mark and the end flag will appear in the doc.\nEncapsulates all the explanations you want to appear in markdown between #= and =#, all the other comments will be taken as part of the julia code and shown in code blocks.\n#@endexample to indicate that the example is finished\nwrite a few tests that check that the example produces the right answer (unit test)So it should look like (a full example can be seen here)using Base.Test\n#@startexample A simple example\n#=\nIn this example we will show how to find the maximum over a collection of\nrandom numbers in Julia for all the numbers that are *negative*.\n=#\na = randn(500)\n# we use a comprehension\nm = maximum(a[i] for i in 1:length(a) if a[i]<0)\n#=\nThat\'s it!\n=#\n#@endexample\n@test m < 0.0Make sure the tests pass! This will generate the following markdown (see next point for the command that generates it):# Name of the Test\n\nIn this example we will show how to find the maximum over a collection of\nrandom numbers in Julia for all the numbers that are negative.\n ```julia\na = randn(500)\n# we use a comprehension\nm = maximum(a[i] for i in 1:length(a) if a[i]<0)\n ```\nThat\'s it!Remark, the spaces in front of the triple backticks in the markdown snippet above are not actually generated when you use readexamples.jl. The spaces are used here in order to escape these triple backticks so that the snippet does not end up being unduly fragmented in three pieces."
},

{
    "location": "contributing/addingexample/#Declaring-your-example-1",
    "page": "New example",
    "title": "Declaring your example",
    "category": "section",
    "text": "You have to mention your example in a few spots:in test/runtests.jl, add a line at the bottom following the examples already present i.e. something like @testset \"ex_NAME\"    begin include(\"ex_NAME.jl\") end (make sure this passes!)\nin docs/src/make.jl, add a line under \"Examples\" following the syntax of examples already present so something like: \"Name of your expl\" => \"examples/ex_name_of_example.jl\"Finally, to generate the markdown run the following command (this will act for all the examples at once so it will also refresh any other modification you may have added to other examples):julia docs/readexamples.jl"
},

{
    "location": "contributing/addingfeature/#",
    "page": "New feature",
    "title": "New feature",
    "category": "page",
    "text": ""
},

{
    "location": "contributing/addingfeature/#Adding-a-feature-1",
    "page": "New feature",
    "title": "Adding a feature",
    "category": "section",
    "text": ""
},

{
    "location": "contributing/addingfeature/#Adding-a-new-feature-to-the-code-1",
    "page": "New feature",
    "title": "Adding a new feature to the code",
    "category": "section",
    "text": "If you wish to add a feature, please follow the following few steps:Keep it concise (so that the relevant PR is readable)\nWrite a test for it and make sure it passes\nDocument it at least briefly\nIdeally write an executable example for itPlease try to follow the conventions around the code to make code review simpler to manage."
},

{
    "location": "contributing/addingfeature/#Replacing-a-part-of-the-code-1",
    "page": "New feature",
    "title": "Replacing a part of the code",
    "category": "section",
    "text": "If you want to generalise / modify / fix a part of the code, please make sure you follow similar steps:Make sure your modifications pass the tests or modify the relevant tests, add tests if the rewrite is more general\nMake sure the fix is documented appropriately (both in )"
},

]}
