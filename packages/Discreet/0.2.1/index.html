<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · Discreet.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Discreet.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Estimating-entropy-1">Estimating entropy</a></li><li><a class="toctext" href="#Estimate-mutual-information-1">Estimate mutual information</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Discreet-1" href="#Discreet-1">Discreet</a></h1><p><a href="https://travis-ci.org/cynddl/Discreet.jl"><img src="https://travis-ci.org/cynddl/Discreet.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://coveralls.io/github/cynddl/Discreet.jl?branch=master"><img src="https://coveralls.io/repos/cynddl/Discreet.jl/badge.svg?branch=master&amp;service=github" alt="Coverage Status"/></a> <a href="http://codecov.io/github/cynddl/Discreet.jl?branch=master"><img src="http://codecov.io/github/cynddl/Discreet.jl/coverage.svg?branch=master" alt="codecov.io"/></a></p><p>Discreet is a small opinionated toolbox to estimate entropy and mutual information from discrete samples. It contains methods to adjust results and correct over- or under-estimations.</p><p>The code here should work on Julia 0.6. It has minimal unit tests and has received little testing in the wild.g</p><h2><a class="nav-anchor" id="Estimating-entropy-1" href="#Estimating-entropy-1">Estimating entropy</a></h2><p>Discreet uses StatsBase&#39;s FrequencyWeights and ProbabilityWeights types.</p><pre><code class="language-julia">using StatsBase: FrequencyWeights, ProbabilityWeights
using Discreet

dist = FrequencyWeights([1, 1, 1, 1, 1, 1])
entropy(dist)  # Naive method: log(6) ≈ 1.792

entropy(dist; method=:CS)  # Chao-Shen correction: ≈ 3.840

entropy(dist; method=:Shrink)  # Shrinkage correction: ≈ 1.792

dist = ProbabilityWeights([.5, .5])
entropy(dist)  # log(2) ≈ 0.693</code></pre><p>Discreet can also estimate the entropy of a sample:</p><pre><code class="language-julia">using Discreet

data = [&quot;tomato&quot;, &quot;apple&quot;, &quot;apple&quot;, &quot;banana&quot;, &quot;tomato&quot;]
estimate_entropy(data)  # == entropy(FrequencyWeights([2, 2, 1]))</code></pre><h2><a class="nav-anchor" id="Estimate-mutual-information-1" href="#Estimate-mutual-information-1">Estimate mutual information</a></h2><p>Discrete provides similar routines to estimate mutual information.</p><pre><code class="language-julia">using Discreet

labels_a = [1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]
labels_b = [1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 3, 1, 3, 3, 3, 2, 2]
mutual_information(labels_a, labels_b)  # Naive method: ≈ 0.410

mutual_information(labels_a, labels_b; method=:CS)  # Chao-Shen correction: ≈ 0.148

mutual_information(labels_a, labels_b; normalize=true)  # Normalized score (between 0 and 1): ≈ 0.382</code></pre><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
