<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · GLMNet.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>GLMNet.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Quick-start-1">Quick start</a></li><li><a class="toctext" href="#Fitting-models-1">Fitting models</a></li><li><a class="toctext" href="#See-also-1">See also</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="GLMNet-1" href="#GLMNet-1">GLMNet</a></h1><p><a href="https://travis-ci.org/JuliaStats/GLMNet.jl"><img src="https://travis-ci.org/JuliaStats/GLMNet.jl.svg?branch=v0.0.4" alt="Build Status"/></a> <a href="https://coveralls.io/github/JuliaStats/GLMNet.jl"><img src="https://coveralls.io/repos/github/JuliaStats/GLMNet.jl/badge.svg" alt="Coverage Status"/></a></p><p><a href="http://www.jstatsoft.org/v33/i01/">glmnet</a> is an R package by Jerome Friedman, Trevor Hastie, Rob Tibshirani that fits entire Lasso or ElasticNet regularization paths for linear, logistic, multinomial, and Cox models using cyclic coordinate descent. This Julia package wraps the Fortran code from glmnet.</p><h2><a class="nav-anchor" id="Quick-start-1" href="#Quick-start-1">Quick start</a></h2><p>To fit a basic model:</p><pre><code class="language-julia">julia&gt; using GLMNet

julia&gt; y = collect(1:100) + randn(100)*10;

julia&gt; X = [1:100 (1:100)+randn(100)*5 (1:100)+randn(100)*10 (1:100)+randn(100)*20];

julia&gt; path = glmnet(X, y)
Least Squares GLMNet Solution Path (55 solutions for 4 predictors in 163 passes):
55x3 DataFrame:
         df  pct_dev        λ
[1,]      0      0.0  27.1988
[2,]      1 0.154843  24.7825
[3,]      1 0.283396  22.5809
  :
[53,]     2 0.911956 0.215546
[54,]     2 0.911966 0.196397
[55,]     2 0.911974  0.17895</code></pre><p><code>path</code> represents the Lasso or ElasticNet fits for varying values of λ. The value of the intercept for each λ value are in <code>path.a0</code>. The coefficients for each fit are stored in compressed form in <code>path.betas</code>.</p><pre><code class="language-julia">julia&gt; path.betas
4x55 CompressedPredictorMatrix:
 0.0  0.083706  0.159976  0.22947  …  0.929157    0.929315
 0.0  0.0       0.0       0.0         0.00655753  0.00700862
 0.0  0.0       0.0       0.0         0.0         0.0
 0.0  0.0       0.0       0.0         0.0         0.0</code></pre><p>This CompressedPredictorMatrix can be indexed as any other AbstractMatrix, or converted to a Matrix using <code>convert(Matrix, path.betas)</code>.</p><p>To predict the output for each model along the path for a given set of predictors, use <code>predict</code>:</p><pre><code class="language-julia">julia&gt; predict(path, [22 22+randn()*5 22+randn()*10 22+randn()*20])
1x55 Array{Float64,2}:
 51.7098  49.3242  47.1505  45.1699  …  25.1036  25.0878  25.0736</code></pre><p>To find the best value of λ by cross-validation, use <code>glmnetcv</code>:</p><pre><code class="language-julia">julia&gt; cv = glmnetcv(X, y)
Least Squares GLMNet Cross Validation
55 models for 4 predictors in 10 folds
Best λ 0.343 (mean loss 76.946, std 12.546)

julia&gt; argmin(cv.meanloss)
48

julia&gt; cv.path.betas[:, 48]
4-element Array{Float64,1}:
 0.926911
 0.00366805
 0.0
 0.0</code></pre><h2><a class="nav-anchor" id="Fitting-models-1" href="#Fitting-models-1">Fitting models</a></h2><p><code>glmnet</code> has two required parameters: the m x n predictor matrix <code>X</code> and the dependent variable <code>y</code>. It additionally accepts an optional third argument, <code>family</code>, which can be used to specify a generalized linear model. Currently, only <code>Normal()</code> (least squares, default), <code>Binomial()</code> (logistic), and <code>Poisson()</code> are supported, although the glmnet Fortran code also implements a Cox model. For logistic models, <code>y</code> is a m x 2 matrix, where the first column is the count of negative responses for each row in <code>X</code> and the second column is the count of positive responses. For all other models, <code>y</code> is a vector.</p><p><code>glmnet</code> also accepts many optional parameters, described below:</p><ul><li><code>weights</code>: A vector of weights for each sample of the same size as <code>y</code>.</li><li><code>alpha</code>: The tradeoff between lasso and ridge regression. This defaults to <code>1.0</code>, which specifies a lasso model.</li><li><code>penalty_factor</code>: A vector of length n of penalties for each predictor in <code>X</code>. This defaults to all ones, which weights each predictor equally. To specify that a predictor should be unpenalized, set the corresponding entry to zero.</li><li><code>constraints</code>: An n x 2 matrix specifying lower bounds (first column) and upper bounds (second column) on each predictor. By default, this is <code>[-Inf Inf]</code> for each predictor in <code>X</code>.</li><li><code>dfmax</code>: The maximum number of predictors in the largest model.</li><li><code>pmax</code>: The maximum number of predictors in any model.</li><li><code>nlambda</code>: The number of values of λ along the path to consider.</li><li><code>lambda_min_ratio</code>: The smallest λ value to consider, as a ratio of the value of λ that gives the null model (i.e., the model with only an intercept). If the number of observations exceeds the number of variables, this defaults to <code>0.0001</code>, otherwise <code>0.01</code>.</li><li><code>lambda</code>: The λ values to consider. By default, this is determined from <code>nlambda</code> and <code>lambda_min_ratio</code>.</li><li><code>tol</code>: Convergence criterion. Defaults to <code>1e-7</code>.</li><li><code>standardize</code>: Whether to standardize predictors so that they are in the same units. Defaults to <code>true</code>. Beta values are always presented on the original scale.</li><li><code>intercept</code>: Whether to fit an intercept term. The intercept is always unpenalized. Defaults to <code>true</code>.</li><li><code>maxit</code>: The maximum number of iterations of the cyclic coordinate descent algorithm. If convergence is not achieved, a warning is returned.</li></ul><h2><a class="nav-anchor" id="See-also-1" href="#See-also-1">See also</a></h2><ul><li><a href="https://github.com/simonster/Lasso.jl">Lasso.jl</a>, a pure Julia implementation of the glmnet coordinate descent algorithm that often achieves better performance.</li><li><a href="https://github.com/simonster/LARS.jl">LARS.jl</a>, an implementation of least angle regression for fitting entire linear (but not generalized linear) Lasso and Elastic Net coordinate paths.</li></ul><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
