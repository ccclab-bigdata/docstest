<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · Spark</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Spark</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Introduction</a></li><li class="current"><a class="toctext" href>API Reference</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>API Reference</a></li></ul></nav><hr/><div id="topbar"><span>API Reference</span><a class="fa fa-bars" href="#"></a></div></header><ul><li><a href="#Spark.JavaPairRDD"><code>Spark.JavaPairRDD</code></a></li><li><a href="#Spark.JavaRDD"><code>Spark.JavaRDD</code></a></li><li><a href="#Spark.PipelinedPairRDD-Tuple{RDD,Function}"><code>Spark.PipelinedPairRDD</code></a></li><li><a href="#Spark.PipelinedPairRDD"><code>Spark.PipelinedPairRDD</code></a></li><li><a href="#Spark.PipelinedRDD"><code>Spark.PipelinedRDD</code></a></li><li><a href="#Spark.PipelinedRDD-Tuple{RDD,Function}"><code>Spark.PipelinedRDD</code></a></li><li><a href="#Spark.SparkContext-Tuple{}"><code>Spark.SparkContext</code></a></li><li><a href="#Spark.SparkContext"><code>Spark.SparkContext</code></a></li><li><a href="#Base.close-Tuple{SparkContext}"><code>Base.close</code></a></li><li><a href="#Base.collect-Tuple{Spark.PairRDD}"><code>Base.collect</code></a></li><li><a href="#Base.collect-Tuple{Spark.SingleRDD}"><code>Base.collect</code></a></li><li><a href="#Base.count-Tuple{RDD}"><code>Base.count</code></a></li><li><a href="#Base.map-Tuple{RDD,Function}"><code>Base.map</code></a></li><li><a href="#Base.reduce-Tuple{RDD,Function}"><code>Base.reduce</code></a></li><li><a href="#Spark.add_file-Tuple{SparkContext,AbstractString}"><code>Spark.add_file</code></a></li><li><a href="#Spark.add_jar-Tuple{SparkContext,AbstractString}"><code>Spark.add_jar</code></a></li><li><a href="#Spark.cache-Tuple{Spark.PairRDD}"><code>Spark.cache</code></a></li><li><a href="#Spark.cache-Tuple{Spark.SingleRDD}"><code>Spark.cache</code></a></li><li><a href="#Spark.cartesian-Tuple{Spark.SingleRDD,Spark.SingleRDD}"><code>Spark.cartesian</code></a></li><li><a href="#Spark.chain_function-Tuple{Any,Any}"><code>Spark.chain_function</code></a></li><li><a href="#Spark.coalesce-Union{Tuple{T}, Tuple{T,Integer}} where T&lt;:RDD"><code>Spark.coalesce</code></a></li><li><a href="#Spark.collect_internal-Tuple{RDD,Any,Any}"><code>Spark.collect_internal</code></a></li><li><a href="#Spark.collect_internal_itr-Tuple{RDD,Any,Any}"><code>Spark.collect_internal_itr</code></a></li><li><a href="#Spark.collect_itr-Tuple{Spark.SingleRDD}"><code>Spark.collect_itr</code></a></li><li><a href="#Spark.collect_itr-Tuple{Spark.PairRDD}"><code>Spark.collect_itr</code></a></li><li><a href="#Spark.context-Tuple{RDD}"><code>Spark.context</code></a></li><li><a href="#Spark.create_map_function-Tuple{Function}"><code>Spark.create_map_function</code></a></li><li><a href="#Spark.deserialized-Tuple{Array{UInt8,1}}"><code>Spark.deserialized</code></a></li><li><a href="#Spark.flat_map-Tuple{RDD,Function}"><code>Spark.flat_map</code></a></li><li><a href="#Spark.flat_map_pair-Tuple{RDD,Function}"><code>Spark.flat_map_pair</code></a></li><li><a href="#Spark.group_by_key-Tuple{Spark.PairRDD}"><code>Spark.group_by_key</code></a></li><li><a href="#Spark.id-Tuple{RDD}"><code>Spark.id</code></a></li><li><a href="#Spark.map_pair-Tuple{RDD,Function}"><code>Spark.map_pair</code></a></li><li><a href="#Spark.map_partitions-Tuple{RDD,Function}"><code>Spark.map_partitions</code></a></li><li><a href="#Spark.map_partitions_pair-Tuple{RDD,Function}"><code>Spark.map_partitions_pair</code></a></li><li><a href="#Spark.map_partitions_with_index-Tuple{RDD,Function}"><code>Spark.map_partitions_with_index</code></a></li><li><a href="#Spark.num_partitions-Tuple{Union{PipelinedPairRDD, PipelinedRDD}}"><code>Spark.num_partitions</code></a></li><li><a href="#Spark.pipe-Tuple{RDD,String}"><code>Spark.pipe</code></a></li><li><a href="#Spark.readobj-Tuple{IO}"><code>Spark.readobj</code></a></li><li><a href="#Spark.reduce_by_key-Tuple{Spark.PairRDD,Function}"><code>Spark.reduce_by_key</code></a></li><li><a href="#Spark.repartition-Union{Tuple{T}, Tuple{T,Integer}} where T&lt;:RDD"><code>Spark.repartition</code></a></li><li><a href="#Spark.serialized-Tuple{Any}"><code>Spark.serialized</code></a></li><li><a href="#Spark.share_variable-Tuple{SparkContext,Symbol,Any}"><code>Spark.share_variable</code></a></li><li><a href="#Spark.text_file-Tuple{SparkContext,AbstractString}"><code>Spark.text_file</code></a></li><li><a href="#Spark.writeobj-Tuple{IO,Any}"><code>Spark.writeobj</code></a></li></ul><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.JavaRDD" href="#Spark.JavaRDD"><code>Spark.JavaRDD</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pure wrapper around JavaRDD</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.SparkContext" href="#Spark.SparkContext"><code>Spark.SparkContext</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Wrapper around JavaSparkContext</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.SparkContext-Tuple{}" href="#Spark.SparkContext-Tuple{}"><code>Spark.SparkContext</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Params:</p><ul><li>master - address of application master. Currently only local and standalone modes          are supported. Default is &#39;local&#39;</li><li>appname - name of application</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.close-Tuple{SparkContext}" href="#Base.close-Tuple{SparkContext}"><code>Base.close</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Close SparkContext</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.collect-Tuple{Spark.PairRDD}" href="#Base.collect-Tuple{Spark.PairRDD}"><code>Base.collect</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Collect all elements of <code>rdd</code> on a driver machine</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.collect-Tuple{Spark.SingleRDD}" href="#Base.collect-Tuple{Spark.SingleRDD}"><code>Base.collect</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Collect all elements of <code>rdd</code> on a driver machine</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.count-Tuple{RDD}" href="#Base.count-Tuple{RDD}"><code>Base.count</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Count number of elements in this RDD</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.map-Tuple{RDD,Function}" href="#Base.map-Tuple{RDD,Function}"><code>Base.map</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Apply function <code>f</code> to each element of <code>rdd</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.reduce-Tuple{RDD,Function}" href="#Base.reduce-Tuple{RDD,Function}"><code>Base.reduce</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Reduce elements of <code>rdd</code> using specified function <code>f</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.cache-Tuple{Spark.PairRDD}" href="#Spark.cache-Tuple{Spark.PairRDD}"><code>Spark.cache</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Persist this RDD with the default storage level (MEMORY_ONLY)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.cache-Tuple{Spark.SingleRDD}" href="#Spark.cache-Tuple{Spark.SingleRDD}"><code>Spark.cache</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Persist this RDD with the default storage level (MEMORY_ONLY)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.cartesian-Tuple{Spark.SingleRDD,Spark.SingleRDD}" href="#Spark.cartesian-Tuple{Spark.SingleRDD,Spark.SingleRDD}"><code>Spark.cartesian</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Create a pair RDD with every combination of the values of rdd1 and rdd2</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.coalesce-Union{Tuple{T}, Tuple{T,Integer}} where T&lt;:RDD" href="#Spark.coalesce-Union{Tuple{T}, Tuple{T,Integer}} where T&lt;:RDD"><code>Spark.coalesce</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return a new RDD that is reduced into num_partitions partitions.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.flat_map-Tuple{RDD,Function}" href="#Spark.flat_map-Tuple{RDD,Function}"><code>Spark.flat_map</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Similar to <code>map</code>, but each input item can be mapped to 0 or more output items (so <code>f</code> should return an iterator rather than a single item)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.flat_map_pair-Tuple{RDD,Function}" href="#Spark.flat_map_pair-Tuple{RDD,Function}"><code>Spark.flat_map_pair</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Similar to <code>map</code>, but each input item can be mapped to 0 or more output items (so <code>f</code> should return an iterator of pairs rather than a single item)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.group_by_key-Tuple{Spark.PairRDD}" href="#Spark.group_by_key-Tuple{Spark.PairRDD}"><code>Spark.group_by_key</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>When called on a dataset of (K, V) pairs, returns a dataset of (K, [V]) pairs.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.id-Tuple{RDD}" href="#Spark.id-Tuple{RDD}"><code>Spark.id</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return the id of the rdd</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.map_pair-Tuple{RDD,Function}" href="#Spark.map_pair-Tuple{RDD,Function}"><code>Spark.map_pair</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Apply function <code>f</code> to each element of <code>rdd</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.map_partitions-Tuple{RDD,Function}" href="#Spark.map_partitions-Tuple{RDD,Function}"><code>Spark.map_partitions</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Apply function <code>f</code> to each partition of <code>rdd</code>. <code>f</code> should be of type <code>(iterator) -&gt; iterator</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.map_partitions_pair-Tuple{RDD,Function}" href="#Spark.map_partitions_pair-Tuple{RDD,Function}"><code>Spark.map_partitions_pair</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Apply function <code>f</code> to each partition of <code>rdd</code>. <code>f</code> should be of type <code>(iterator) -&gt; iterator</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.map_partitions_with_index-Tuple{RDD,Function}" href="#Spark.map_partitions_with_index-Tuple{RDD,Function}"><code>Spark.map_partitions_with_index</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Apply function <code>f</code> to each partition of <code>rdd</code>. <code>f</code> should be of type <code>(index, iterator) -&gt; iterator</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.num_partitions-Tuple{Union{PipelinedPairRDD, PipelinedRDD}}" href="#Spark.num_partitions-Tuple{Union{PipelinedPairRDD, PipelinedRDD}}"><code>Spark.num_partitions</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Returns the number of partitions of this RDD.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.pipe-Tuple{RDD,String}" href="#Spark.pipe-Tuple{RDD,String}"><code>Spark.pipe</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return an RDD created by piping elements to a forked external process.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.reduce_by_key-Tuple{Spark.PairRDD,Function}" href="#Spark.reduce_by_key-Tuple{Spark.PairRDD,Function}"><code>Spark.reduce_by_key</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>When called on a dataset of (K, V) pairs, returns a dataset of (K, V) pairs where the values for each key are aggregated using the given reduce function func, which must be of type (V,V) =&gt; V.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.repartition-Union{Tuple{T}, Tuple{T,Integer}} where T&lt;:RDD" href="#Spark.repartition-Union{Tuple{T}, Tuple{T,Integer}} where T&lt;:RDD"><code>Spark.repartition</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return a new RDD that has exactly num_partitions partitions.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.share_variable-Tuple{SparkContext,Symbol,Any}" href="#Spark.share_variable-Tuple{SparkContext,Symbol,Any}"><code>Spark.share_variable</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Makes the value of data available on workers as symbol name</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.text_file-Tuple{SparkContext,AbstractString}" href="#Spark.text_file-Tuple{SparkContext,AbstractString}"><code>Spark.text_file</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Create RDD from a text file</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.JavaPairRDD" href="#Spark.JavaPairRDD"><code>Spark.JavaPairRDD</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pure wrapper around JavaPairRDD</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.PipelinedPairRDD" href="#Spark.PipelinedPairRDD"><code>Spark.PipelinedPairRDD</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Julia type to handle Pair RDDs. Can handle pipelining of operations to reduce interprocess IO.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.PipelinedPairRDD-Tuple{RDD,Function}" href="#Spark.PipelinedPairRDD-Tuple{RDD,Function}"><code>Spark.PipelinedPairRDD</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Params:</p><ul><li>parentrdd - parent RDD</li><li>func - function of type <code>(index, iterator) -&gt; iterator</code> to apply to each partition</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.PipelinedRDD" href="#Spark.PipelinedRDD"><code>Spark.PipelinedRDD</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Julia type to handle RDDs. Can handle pipelining of operations to reduce interprocess IO.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.PipelinedRDD-Tuple{RDD,Function}" href="#Spark.PipelinedRDD-Tuple{RDD,Function}"><code>Spark.PipelinedRDD</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Params:</p><ul><li>parentrdd - parent RDD</li><li>func - function of type <code>(index, iterator) -&gt; iterator</code> to apply to each partition</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.add_file-Tuple{SparkContext,AbstractString}" href="#Spark.add_file-Tuple{SparkContext,AbstractString}"><code>Spark.add_file</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Add file to SparkContext. This file will be downloaded to each executor&#39;s work directory</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.add_jar-Tuple{SparkContext,AbstractString}" href="#Spark.add_jar-Tuple{SparkContext,AbstractString}"><code>Spark.add_jar</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Add JAR file to SparkContext. Classes from this JAR will then be available to all tasks</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.chain_function-Tuple{Any,Any}" href="#Spark.chain_function-Tuple{Any,Any}"><code>Spark.chain_function</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>chain 2 partion functions together </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.collect_internal-Tuple{RDD,Any,Any}" href="#Spark.collect_internal-Tuple{RDD,Any,Any}"><code>Spark.collect_internal</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Collects the RDD to the Julia process, by serialising all values via a byte array</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.collect_internal_itr-Tuple{RDD,Any,Any}" href="#Spark.collect_internal_itr-Tuple{RDD,Any,Any}"><code>Spark.collect_internal_itr</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Collects the RDD to the Julia process, via an Julia iterator that fetches each row at a time. This prevents creation of a byte array containing all rows at a time.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.collect_itr-Tuple{Spark.PairRDD}" href="#Spark.collect_itr-Tuple{Spark.PairRDD}"><code>Spark.collect_itr</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Collect all elements of <code>rdd</code> on a driver machine</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.collect_itr-Tuple{Spark.SingleRDD}" href="#Spark.collect_itr-Tuple{Spark.SingleRDD}"><code>Spark.collect_itr</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Collect all elements of <code>rdd</code> on a driver machine</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.context-Tuple{RDD}" href="#Spark.context-Tuple{RDD}"><code>Spark.context</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Get SparkContext of this RDD</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.create_map_function-Tuple{Function}" href="#Spark.create_map_function-Tuple{Function}"><code>Spark.create_map_function</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>creates a function that operates on a partition from an element by element map function</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.deserialized-Tuple{Array{UInt8,1}}" href="#Spark.deserialized-Tuple{Array{UInt8,1}}"><code>Spark.deserialized</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return object deserialized from array of bytes</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.readobj-Tuple{IO}" href="#Spark.readobj-Tuple{IO}"><code>Spark.readobj</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Read data object from a ioet. Returns code and byte array:</p><ul><li>if code is negative, it&#39;s considered as a special command code</li><li>if code is positive, it&#39;s considered as array length</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.serialized-Tuple{Any}" href="#Spark.serialized-Tuple{Any}"><code>Spark.serialized</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return serialized object as an array of bytes</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Spark.writeobj-Tuple{IO,Any}" href="#Spark.writeobj-Tuple{IO,Any}"><code>Spark.writeobj</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Write object to stream</p></div></div></section><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Introduction</span></a></footer></article></body></html>
