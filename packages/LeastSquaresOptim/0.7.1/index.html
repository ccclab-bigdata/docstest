<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · LeastSquaresOptim.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>LeastSquaresOptim.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Motivation-1">Motivation</a></li><li><a class="toctext" href="#Simple-Syntax-1">Simple Syntax</a></li><li><a class="toctext" href="#Choice-of-Optimizer-/-Least-Square-Solver-1">Choice of Optimizer / Least Square Solver</a></li><li><a class="toctext" href="#Alternative-in-place-Syntax-1">Alternative in-place Syntax</a></li><li><a class="toctext" href="#Related-packages-1">Related packages</a></li><li><a class="toctext" href="#References-1">References</a></li><li><a class="toctext" href="#Installation-1">Installation</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><p><a href="https://travis-ci.org/matthieugomez/LeastSquaresOptim.jl"><img src="https://travis-ci.org/matthieugomez/LeastSquaresOptim.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://coveralls.io/github/matthieugomez/LeastSquaresOptim.jl?branch=master"><img src="https://coveralls.io/repos/matthieugomez/LeastSquaresOptim.jl/badge.svg?branch=master&amp;service=github" alt="Coverage Status"/></a></p><h2><a class="nav-anchor" id="Motivation-1" href="#Motivation-1">Motivation</a></h2><p>This package solves non linear least squares optimization problems. The package is inspired by the <a href="http://ceres-solver.org/nnls_solving.html">Ceres library</a>.  This package is written with large scale problems in mind (in particular for sparse Jacobians). </p><h2><a class="nav-anchor" id="Simple-Syntax-1" href="#Simple-Syntax-1">Simple Syntax</a></h2><p>The symple syntax mirrors the <code>Optim.jl</code> syntax</p><pre><code class="language-julia">using LeastSquaresOptim
function rosenbrock(x)
	[1 - x[1], 100 * (x[2]-x[1]^2)]
end
x0 = zeros(2)
optimize(rosenbrock, x0, Dogleg())
optimize(rosenbrock, x0, LevenbergMarquardt())</code></pre><p>You can also add the options : <code>x_tol</code>, <code>f_tol</code>, <code>g_tol</code>, <code>iterations</code>, <code>Δ</code> (initial radius), <code>autodiff</code> (<code>:central</code> to use finite difference method or <code>:forward</code> to use ForwardDiff package) as well as <code>lower</code> / <code>upper</code> arguments to impose boundary constraints.</p><h2><a class="nav-anchor" id="Choice-of-Optimizer-/-Least-Square-Solver-1" href="#Choice-of-Optimizer-/-Least-Square-Solver-1">Choice of Optimizer / Least Square Solver</a></h2><ul><li>You can specify two least squares optimizers, <code>Dogleg()</code> and <code>LevenbergMarquardt()</code></li><li>You can specify three least squares solvers (used within the optimizer)</li></ul><pre><code class="language-none">- `LeastSquaresOptim.QR()` or  `LeastSquaresOptim.Cholesky()` for dense jacobians
- `LeastSquaresOptim.LSMR()`. A conjugate gradient method ([LSMR]([http://web.stanford.edu/group/SOL/software/lsmr/) with diagonal preconditioner). Beyond `Matrix` and `SparseMatrixCSC`, the jacobian can be any type that defines the following interface:

	- `mul!(y, A, x, α::Number, β::Number)` updates y to αAx + βy
	- `mul!(x, A&#39;, y, α::Number, β::Number)` updates x to αA&#39;y + βx
	- `colsumabs2!(x, A)` updates x to the sum of squared elements of each column
	- `size(A, d)` returns the nominal dimensions along the dth axis in the equivalent matrix representation of A.
	- `eltype(A)` returns the element type implicit in the equivalent matrix representation of A.

	Similarly, `x` or `f(x)` may be custom types. An example of the interface can be found in the package [SparseFactorModels.jl](https://github.com/matthieugomez/SparseFactorModels.jl).

	Moreover, you can optionally specifying a function `preconditioner!` and a matrix `P` such that `preconditioner!(P, x, J, λ)` updates `P` as a preconditioner for `J&#39;J + λ`. The preconditioner can be any type that supports `A_ldiv_B!(x, P, y)`. By default, the preconditioner is chosen as the diagonal of the matrix `J&#39;J + λ`.</code></pre><p>The optimizers and solvers are presented in more depth in the <a href="http://ceres-solver.org/nnls_solving.html">Ceres documentation</a>. For dense jacobians, the default option is <code>Doglel(QR())</code>. For sparse jacobians, the default option is  <code>LevenbergMarquardt(LSMR())</code></p><pre><code class="language-julia">optimize(rosenbrock, x0, Dogleg(LeastSquaresOptim.QR()))
optimize(rosenbrock, x0, LevenbergMarquardt(LeastSquaresOptim.LSMR()))</code></pre><h2><a class="nav-anchor" id="Alternative-in-place-Syntax-1" href="#Alternative-in-place-Syntax-1">Alternative in-place Syntax</a></h2><p>The alternative syntax is useful when specifying in-place functions or the jacobian. Pass <code>optimize</code> a <code>LeastSquaresProblem</code> object with:</p><ul><li><code>x</code> an initial set of parameters.</li><li><code>f!(out, x)</code> that writes <code>f(x)</code> in <code>out</code>.</li><li>the option <code>output_length</code> to specify the length of the output vector. </li><li>Optionally, <code>g!</code> a function such that <code>g!(out, x)</code> writes the jacobian at x in <code>out</code>. Otherwise, the jacobian will be computed following the <code>:autodiff</code> argument.</li></ul><pre><code class="language-julia">using LeastSquaresOptim
function rosenbrock_f!(out, x)
 out[1] = 1 - x[1]
 out[2] = 100 * (x[2]-x[1]^2)
end
optimize!(LeastSquaresProblem(x = zeros(2), f! = rosenbrock_f!, output_length = 2, autodiff = :central), Dogleg())

# if you want to use gradient
function rosenbrock_g!(J, x)
    J[1, 1] = -1
    J[1, 2] = 0
    J[2, 1] = -200 * x[1]
    J[2, 2] = 100
end
optimize!(LeastSquaresProblem(x = zeros(2), f! = rosenbrock_f!, g! = rosenbrock_g!, output_length = 2), Dogleg())</code></pre><h2><a class="nav-anchor" id="Related-packages-1" href="#Related-packages-1">Related packages</a></h2><p>Related:</p><ul><li><a href="https://github.com/JuliaOpt/LsqFit.jl">LSqfit.jl</a> fits curves (i.e. models of the form y = f(x, β))</li><li><a href="https://github.com/JuliaOpt/Optim.jl">Optim.jl</a> solves general optimization problems.</li><li><a href="https://github.com/EconForge/NLsolve.jl">NLSolve.jl</a> solves non linear equations by least squares minimization.</li></ul><h2><a class="nav-anchor" id="References-1" href="#References-1">References</a></h2><ul><li>Nocedal, Jorge and Stephen Wright <em>An Inexact Levenberg-Marquardt method for Large Sparse Nonlinear Least Squares</em>  (1985) The Journal of the Australian Mathematical Society</li><li>Fong, DC. and Michael Saunders. (2011) <em>LSMR: An Iterative Algorithm for Sparse Least-Squares Problems</em>.  SIAM Journal on Scientific Computing</li><li>Agarwal, Sameer, Keir Mierle and Others. (2010) <em>Ceres Solver</em></li></ul><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><p>To install the package,</p><pre><code class="language-julia">using Pkg
Pkg.add(&quot;LeastSquaresOptim&quot;)</code></pre><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
