<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · EntropicCone</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>EntropicCone</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="index.html">Index</a></li><li class="current"><a class="toctext" href="intro.html">Introduction</a><ul class="internal"><li><a class="toctext" href="#The-definition-of-entropy-1">The definition of entropy</a></li><li><a class="toctext" href="#The-entropic-cone-1">The entropic cone</a></li></ul></li><li><a class="toctext" href="vector.html">Entropic Vector</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="intro.html">Introduction</a></li></ul></nav><hr/><div id="topbar"><span>Introduction</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Introduction-1" href="#Introduction-1">Introduction</a></h1><h2><a class="nav-anchor" id="The-definition-of-entropy-1" href="#The-definition-of-entropy-1">The definition of entropy</a></h2><p>In 1948, Shannon published &quot;A Mathematical Theory of Communication&quot; [Sha48]. In this paper, Shannon introduces the entropy of a random variable. Suppose we have a random variable <span>$X$</span> of alphabet <span>$\mathcal{X}$</span>, he defines the entropy of <span>$X$</span> as</p><div>\[H_b(X) = \sum_{x \in \mathcal{X}} \Pr[X = x] \log_b \frac{1}{\Pr[X = x]}\]</div><p>where the basis <span>$b$</span> is positive. If <span>$b$</span> is 2 (resp. <span>$e$</span>), the unit is the bits (resp. nats). Note that <span>$H_b(X) = H_a(X) \log_b(a)$</span> so the entropies using different basis are equivalent up to a positive constant factor.</p><p>The entropy of several random variables in simply the entropy of their cartesian product:</p><div>\[\begin{align*}
  H_b(\{X_1, \ldots, X_n\})
  &amp; = \sum_{(x_1,\ldots,x_n) \in \mathcal{X}_1 \times \cdots \times \mathcal{X}_n} \Pr[(X_1, \ldots, X_n) = (x_1,\ldots,x_n)] \log_b \frac{1}{\Pr[(X_1, \ldots, X_n) = (x_1,\ldots,x_n)]}.
\end{align*}\]</div><p>By convention, we say that the entropy of an empty set of random variables is 0.</p><p>Given a <span>$n$</span> random variables, we can compute the entropy of any of the <span>$2^n$</span> subset of those <span>$n$</span> variables. The entropic vector of a set of <span>$n$</span> random variables is a vector <span>$h$</span>, indexed by the subsets of <span>$[n] = \{1, \ldots, n\}$</span>, such that <span>$h_S = H_b(\{\, X_i \mid i \in S\,\})$</span>.</p><h2><a class="nav-anchor" id="The-entropic-cone-1" href="#The-entropic-cone-1">The entropic cone</a></h2><p>The <em>entropic cone</em> of <span>$n$</span> variables is the set of vectors of <span>$\mathbb{R}^{2^n-1}$</span> that are entropic:</p><div>\[\mathcal{H}_n = \{\, h \in \mathbb{R}^{2^n-1} \mid \exists X_1, \ldots, X_n, \forall \emptyset \neq S \subseteq [n], h_S = H_b(\{\, X_i \mid i \in S\,\}) \,\}.\]</div><p>We do not include the dimension corresponding to the entropy of the empty set as it is zero to make the cone <span>$\mathcal{H}_n$</span> solid, i.e. full-dimensional.</p><p>[Sha48] Claude Elwood Shannon. <em>A mathematical theory of communication</em>. Bell System Technical Journal, 27:379–423 and 623–656, July and October 1948.</p><footer><hr/><a class="previous" href="index.html"><span class="direction">Previous</span><span class="title">Index</span></a><a class="next" href="vector.html"><span class="direction">Next</span><span class="title">Entropic Vector</span></a></footer></article></body></html>
