<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme Â· TensorCast.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>TensorCast.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#Examples-1">Examples</a></li><li><a class="toctext" href="#Inside-1">Inside</a></li><li><a class="toctext" href="#Checking-1">Checking</a></li><li><a class="toctext" href="#Options-1">Options</a></li><li><a class="toctext" href="#Wishlist-1">Wishlist</a></li><li><a class="toctext" href="#About-1">About</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="TensorCast.jl-1" href="#TensorCast.jl-1">TensorCast.jl</a></h1><p><a href="https://travis-ci.org/mcabbott/TensorCast.jl"><img src="https://travis-ci.org/mcabbott/TensorCast.jl.svg?branch=master" alt="Build Status"/></a> &lt;!â€“ &lt;a href=&quot;https://travis-ci.org/mcabbott/TensorCast.jl&quot;&gt;&lt;img src=&quot;https://travis-ci.org/mcabbott/TensorCast.jl.svg?branch=master&quot; align=&quot;right&quot; alt=&quot;Build Status&quot; padding=&quot;20&quot;&gt;&lt;/a&gt;â€“&gt;</p><p>This package lets you write many expressions involving N-dimensional arrays in index notation, which is often the least confusing way.  It defines a pair of macros: <code>@cast</code> deals both with &quot;casting&quot; into new shapes (including going  to and from an array-of-arrays) and with broadcasting:</p><pre><code class="language-julia">@cast A[row][col] := B[row, col]            # slice a matrix into its rows

@cast C[(i,j), (k,â„“)] := D[i,j,k,â„“]         # reshape a 4-tensor to give a matrix

@cast E[x,y] = F[x]^2 * log(G[y])           # broadcast E .= F.^2 .* log.(G&#39;) into existing E</code></pre><p>And <code>@reduce</code> takes sums (or other reductions) over some directions,  but otherwise understands all the same things: </p><pre><code class="language-julia">@reduce H[a] := sum(b,c) L[a,b,c]                # sum over dims=(2,3), and dropdims

@reduce S[i] = sum(n) -P[i,n] * log(P[i,n]/Q[n]) # sum!(S, @. -P*log(P/Q&#39;)) into exising S

@reduce W[Î¼,Î½,J] := prod(i:2) V[(i,J)][Î¼,Î½]      # products of pairs of matrices, stacked</code></pre><p>These are intended to complement the macro from <a href="https://github.com/Jutho/TensorOperations.jl">TensorOperations.jl</a>, which instead performs Einstein-convention contractions and traces, in a very similar notation.  Here it is implicit that repeated indices are summed over: </p><pre><code class="language-julia">@tensor A[i,k] := B[i,j] * C[j,k]           # matrix multiplication, A = B * C
@tensor D[i] := E[i] + F[i,k,k]             # partial trace of F only, Dáµ¢ = Eáµ¢ + Î£â±¼ Fáµ¢â±¼â±¼</code></pre><p>Similar notation is also used by the macro from <a href="https://github.com/ahwillia/Einsum.jl">Einsum.jl</a>, where again it is implicit that all indices appearing only on the right are summed over.  This allows arbitrary (element-wise) functions:</p><pre><code class="language-julia">@einsum S[i] := -P[i,n] * log(P[i,n]/Q[n])  # sum over n, for each i (also with @reduce above)
@einsum G[i] := E[i] + F[i,k,k]             # the sum includes everyting:  Gáµ¢ = Î£â±¼ (Eáµ¢ + Fáµ¢â±¼â±¼)</code></pre><p>There is some overlap of operations which can be done with two (or all three) of these packages.  However they produce very different code for actually doing what you request.  The original <code>@einsum</code> simply writes the necessary set of nested loops.  Instead <code>@tensor</code> works out a sequence of contraction and trace operations, calling optimised BLAS routines where possible.  &lt;!â€“ (And <a href="https://github.com/shashi/ArrayMeta.jl">ArrayMeta.jl</a> aimed to do a wide variety of operations efficiently, but seems to be abandonned.) â€“&gt;</p><p>The  macros from this package aim to produce simple Julia commands:  often just a string of <code>reshape</code> and <code>permutedims</code> and <code>eachslice</code> and so on, plus a native <a href="https://julialang.org/blog/2017/01/moredots">broadcasting expression</a> if needed,  and <code>sum</code> or  <code>sum!</code>. This means that they are very generic, and will (mostly) work well on  <a href="https://github.com/FluxML/Flux.jl">Flux</a>&#39;s TrackedArrays, on the GPU via  <a href="https://github.com/JuliaGPU/CuArrays.jl">CuArrays</a>, and on almost any other kind of N-dimensional array.</p><p>For those who speak Python, <code>@cast</code> and <code>@reduce</code> allow similar operations to  <a href="https://github.com/arogozhnikov/einops"><code>einops</code></a> (minus the cool video, but plus broadcasting) while Einsum / TensorOperations map very roughly to <a href="http://numpy-discussion.10968.n7.nabble.com/einsum-td11810.html"><code>einsum</code></a>  / <a href="https://github.com/dgasmith/opt_einsum"><code>opt_einsum</code></a>. The function of <code>@check!</code> (see <a href="#checking">below</a>) is similar to <a href="https://github.com/ofnote/tsalib"><code>tsalib</code></a>&#39;s shape annotations.</p><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><p>You need <a href="https://julialang.org/downloads/">Julia</a> 1.0. This package is now registered, install it like this: </p><pre><code class="language-julia">pkg&gt; add TensorCast  # press ] for pkg, backspace to leave

pkg&gt; add StaticArrays Strided  TensorOperations Einsum  # optional extras, see below
pkg&gt; add Flux ImageView FileIO                          # for image examples

julia&gt; using TensorCast

help?&gt; @cast  # press ? for help</code></pre><p>From a Jupyter notebook, write instead <code>using Pkg; pkg&quot;add TensorCast&quot;</code>. If you downloaded this under its former name, you should <code>rm TensorSlice</code>.  </p><h2><a class="nav-anchor" id="Examples-1" href="#Examples-1">Examples</a></h2><p>This simply slices a matrix into its rows, then re-glues and re-slices to obtain the columns instead:</p><pre><code class="language-julia">mat = (1:4)&#39; .+ rand(2,4)

@cast rows[r][c] := mat[r,c]
@cast cols[â™œ][ðŸš£] := rows[ðŸš£][â™œ]

@reduce sum_r[c] := sum(r) mat[r,c]  

size(sum_r) == (4,) # @reduce gives a vector, not a 1Ã—4 matrix
sum_r == sum(rows)  # true</code></pre><p>Notice that the same indices must always appear both on the right and on the left (unless they are explicitly reduced over). Indices may not be repeated. </p><p>This reshapes a matrix into a 3-tensor. The ranges of <code>i</code> and <code>k</code> would be ambiguous unless you specify  (at least) one of them. Such ranges are written <code>i:2</code>, and appear as part of a tuple of options after the expression:</p><pre><code class="language-julia">M = randn(Float16, 2*5, 3)

@cast A[i,j,k] := M[(i,k),j]  i:2, k:5

size(A) == (2,3,5) # true

@cast A[i,j,k] = M[(i,k),j]; # writing into existing A, it knows size(A)</code></pre><p>This glues and reshapes a list of images into one large image:</p><p>&lt;img src=&quot;test/famous-digits.png?raw=true&quot; width=&quot;336&quot; height=&quot;168&quot; align=&quot;right&quot; alt=&quot;MNIST&quot; padding=&quot;20&quot;&gt;</p><pre><code class="language-julia">using Flux, ImageView, FileIO
imgs = Flux.Data.MNIST.images()[1:32] # vector of matrices

@cast G[(i,I), (j,J)] := imgs[(I,J)][i,j] J:8
@cast G[ i\I,   j\J ] := imgs[ I\J ][i,j] J:8 # identical

imshow(G) # grid with eight columns, 1 â‰¤ J â‰¤ 8

save(&quot;famous-digits.png&quot;, G)</code></pre><p>Note that the order here <code>(i,I) = (pixel, grid)</code> is a choice made by this package, such that <code>A[(i,j),k]</code> and <code>B[i,j,k]</code> have the same linear order <code>A[:] == B[:]</code>. And entries <code>i</code> and <code>i+1</code> are neighbours because Julia <code>Array</code>s are column-major  (the opposite of C, and hence of NumPy). The alternative notation <code>(i,I) == i\I</code> used here  is meant to help me remember which is the large-grid index. (The vector of matrices <code>C[k]{i,j}</code> also has the same order, if the slices are StaticArrays, below.)</p><p>This defines a function which extends <a href="https://docs.julialang.org/en/latest/stdlib/LinearAlgebra/#Base.kron"><code>kron(A,B)</code></a> one step beyond vectors &amp; matrices: </p><pre><code class="language-julia">function Base.kron(A::Array{T,3}, B::Array{T,3}) where {T}
    @cast D[i\I, j\J, k\K] := A[I,J,K] * B[i,j,k]
end

A = rand(-20:20, 2,3,1)   # test with 3rd index trivial
B = ones(Int, 5,7,1);

D = kron(A, B)            # calls this new method
size(D) == (2*5, 3*7, 1*1)

kron(A[:,:,1], B[:,:,1])  # calls built-in method, same numbers</code></pre><p>While <em>tensor</em> is often just a fancy word for <em>N-dimensional array</em>, it has more specific meanings,  and one of them is that the the tensor product of two vector spaces <code>V âŠ— V</code> is the one with the product of  their dimensions (as opposed to <code>V Ã— V</code> which has the sum). The Kronecker product  <code>kron</code> maps to such a tensor product space (as <code>vcat</code> maps into <code>V Ã— V</code>).  We can always think of these combined indices <code>(i,I) = i\I</code> in this way, and now you may write <code>iâŠ—I</code> too. </p><p>This does max-pooling on the above image grid <code>G</code>: </p><p>&lt;img src=&quot;test/famous-digits-2.png?raw=true&quot; width=&quot;224&quot; height=&quot;112&quot; align=&quot;right&quot; alt=&quot;MNIST&quot; padding=&quot;20&quot;&gt;</p><pre><code class="language-julia">@reduce H[a, b] := maximum(Î±:2,Î²:2)  G[Î±\a, Î²\b]  

size(G) == 2 .* size(H) # true
imshow(H)</code></pre><p>In words: take a horizontal line of pixels in <code>G</code> and re-arrange them into two rows,  so that each column contains two formerly-neighbouring pixes. The horizontal position is now <code>a</code>,  vertical is <code>Î± âˆˆ 1:2</code>. Take the maximum along these new columns, giving us one line again (half as long).  Do this to every line, and also to every vertical line, to obtain <code>H</code>. </p><p>Notice also that ranges <code>Î±:2, Î²:2</code> can be specified inside the reduction function, instead of at the end. </p><p>Finally, this takes a 2D slice <code>W[2,:,4,:]</code> of a 4D array, transposes it, and then forms it into a 4D array with two trivial dimensions â€“ such output can be useful for interacting with broadcasting:</p><pre><code class="language-julia">W = randn(2,3,5,7);

@cast Z[_,i,_,k] := W[2,k,4,i]  # equivalent to Z[1,i,1,k] on left

size(Z) == (1,7,1,3)</code></pre><h2><a class="nav-anchor" id="Inside-1" href="#Inside-1">Inside</a></h2><p>To inspect what this package produces, there is another macro <code>@pretty</code> which works like this:</p><pre><code class="language-julia">@pretty @cast A[(i,j)] = B[i,j]
# copyto!(A, B)

@pretty @cast A[k][i,j] := B[i,(j,k)]  k:length(C)
# begin
#     local caterpillar = (size(B, 1), :, length(C))  # your animal may vary
#     A = sliceview(reshape(B, (caterpillar...,)), (:, :, *))
# end</code></pre><p>Here <code>TensorCast.sliceview(D, (:,:,*)) = collect(eachslice(D, dims=3))</code> using the new <a href="https://github.com/JuliaLang/julia/blob/master/HISTORY.md#new-library-functions">eachcol &amp; eachrow</a> functions, but allowing more general <code>sliceview(D, (:,*,:,*) â‰ˆ eachslice(D, dims=(2,4))</code>.  (In notation borrowed from <a href="https://github.com/bramtayl/JuliennedArrays.jl">JuliennedArrays.jl</a>, see below.)</p><p>Adding <code>assert</code> or just <code>!</code> inserts explicit size checks:</p><pre><code class="language-julia">@pretty @reduce H[a, b] := maximum(Î±:2,Î²:2) G[Î±\a, Î²\b] !
# begin
#     @assert rem(size(G, 1), 2) == 0 
#     @assert rem(size(G, 2), 2) == 0
#     local fox = (2, 2, size(G, 1) Ã· 2, size(G, 2) Ã· 2)
#     H = dropdims(maximum(
#         permutedims(reshape(G, (fox[1], fox[3], fox[2], fox[4])), (1, 3, 2, 4)), 
#             dims=(3, 4)), dims=(3, 4))
# end</code></pre><p>This <code>@pretty</code> is really just a variant of the built-in <code>@macroexpand1</code>, with animal names from <a href="https://github.com/MikeInnes/MacroTools.jl">MacroTools.jl</a> in place of generated symbols,  and some tidying up.</p><h2><a class="nav-anchor" id="Checking-1" href="#Checking-1">Checking</a></h2><p>When writing complicated index expressions by hand, it is conventional to use different groups of letters  for indices which mean different things. If <code>a,b,c...</code> label some objects, while <code>Î¼,Î½,...</code> are components  of their positions (in units of meters) then any expression which mixes these up is probably a mistake.  This package also can automate checks for such mistakes: </p><pre><code class="language-julia">@reduce!  A[Î±] := sum(k) B[Î±,k]     # memorises that A takes Î±, etc.
@cast!  C[Î±,Î²] := A[Î±] * A[Î²]       # no problem: Î² is close to Î±
@cast! D[n][Î²] := C[n,Î²]            # warning! C does not accept n</code></pre><p>There are also macros <code>@tensor!</code> and <code>@einsum!</code> which perform the same checks,  before calling the usual <code>@tensor</code> / <code>@einsum</code>. </p><p>If you need to leave index notation and return, you can insert <code>@check!</code> to confirm.  (The <code>!</code> is because it alters a dictionary, off-stage somewhere.)</p><pre><code class="language-julia">@cast! D[Î±,_,Î²,_] := C[Î±,Î²]         # reshape to size(D,2) == size(D,4) == 1
E = calculate(D)
@check! E[n,Î±]                      # just the check, with no calculation</code></pre><p>These macros are (by definition) run when your code is loaded, not during the calculation,  and thus such checks have zero speed penalty. But you can turn on explicit run-time size checks too  (and, if you wish, an error not a warning) by passing these options:</p><pre><code class="language-julia">@check!  size=true  throw=true</code></pre><p>After this, <code>@check!(A[Î±])</code> will insert the function <code>check!(A, ...)</code> which (when run) saves the range  of every distinct index name, and gives an error if it is subsequently used to indicate a dimension of different size. This is based on the complete name, thus <code>Î±</code> and <code>Î±2</code> may have distinct ranges,  while the above slot-checking is based on the first letter.  </p><p>(For now there is one global list of settings, index names, and run-time sizes.)</p><h2><a class="nav-anchor" id="Options-1" href="#Options-1">Options</a></h2><p>As mentioned above, expressions with <code>=</code> write into an existing array,  while those with <code>:=</code> do not. This is the same notation as  <a href="https://github.com/Jutho/TensorOperations.jl">TensorOperations.jl</a> and <a href="https://github.com/ahwillia/Einsum.jl">Einsum.jl</a>.  But unlike those packages, sometimes the result of <code>@cast</code> is a view of the original, for instance  <code>@cast A[i,j] := B[j,i]</code> gives <code>A = transpose(B)</code>. You can forbid this, and insist on a copy,  by writing <code>|=</code> instead. And conversely, if you expect a view, writing <code>==</code> will give an error if not.</p><h3><a class="nav-anchor" id="Ways-of-slicing-1" href="#Ways-of-slicing-1">Ways of slicing</a></h3><p>The default way of slicing creates an array of views,  but if you use <code>|=</code> instead then you get copies: </p><pre><code class="language-julia">M = rand(1:99, 3,4)

@cast S[k][i] := M[i,k]             # collect(eachcol(M)) â‰ˆ [ view(M,:,k) for k=1:4 ]
@cast S[k][i] |= M[i,k]             # [ M[:,k] for k=1:4 ]; using |= demands a copy</code></pre><p>The default way of un-slicing is <code>reduce(cat, ...)</code>, which creates a new array.  But there are other options, controlled by keywords after the expression:</p><pre><code class="language-julia">@cast A[i,k] := S[k][i]             # A = reduce(hcat, B)
@cast A[i,k] := S[k][i]  cat        # A = hcat(B...)
@cast A[i,k] := S[k][i]  lazy       # A = VectorOfArrays(B)

size(A) == (3, 4) # true</code></pre><p>The option <code>lazy</code> uses <a href="https://github.com/JuliaDiffEq/RecursiveArrayTools.jl">RecursiveArrayTools.jl</a> to create a view of the original vectors. This would also be possible with  <a href="https://github.com/bramtayl/JuliennedArrays.jl">JuliennedArrays.jl</a>, I may change what gets used later. </p><p>Combining with <code>cat</code> is often much slower, but more generic. For example it will work with  <a href="https://github.com/FluxML/Flux.jl">Flux</a>&#39;s TrackedArrays.</p><p>Another kind of slices are provided by <a href="https://github.com/JuliaArrays/StaticArrays.jl">StaticArrays.jl</a>, in which a Vector of SVectors is just a different interpretation of the same memory as a Matrix.  By another slight abuse of notation, such slices are written here as curly brackets:</p><pre><code class="language-julia">using StaticArrays

@cast S[k]{i} == M[i,k]  i:3        # S = reinterpret(SVector{3,Int}, vec(M)) 

@cast R[k,i] == S[k]{i}             # such slices can be reinterpreted back again

M[1,2]=42; R[2,1]==42               # all views of the original data</code></pre><p>When creating such slices, their size ought to be provided, either as a literal integer or  through the types. Note that you may also write <code>S[k]{i:3}</code>.  For example, this function is about 100x slower if not given the <a href="https://docs.julialang.org/en/latest/manual/types/index.html#&quot;Value-types&quot;-1">value type</a> <code>Val(3)</code>, as the size of the SVector is then not known to the compiler:</p><pre><code class="language-julia">cols_slow(M::Matrix) = @cast A[j]{i} == M[i,j]  i:size(M,1)

cols_fast(M::Matrix, ::Val{N}) where N = @cast A[j]{i:N} == M[i,j]

@code_warntype cols_slow(M) # with complaints ::Any in red
@code_warntype cols_fast(M, Val(3))</code></pre><p>Another potential issue is that, if you create such slices after transposing (or some other lazy transformation),  then accessing them tends to be slower. Making a copy with <code>|=</code> such as <code>@cast T[i]{k:4} |= M[i,k]</code> will  avoid this.</p><h3><a class="nav-anchor" id="Better-broadcasting-1" href="#Better-broadcasting-1">Better broadcasting</a></h3><p>When broadcasting and then summing over some directions, it can be faster to avoid creating the  entire array, then throwing it away. This can be done with the package  <a href="https://github.com/JuliaArrays/LazyArrays.jl">LazyArrays.jl</a> which has a lazy <code>BroadcastArray</code>.  In the following example, the product <code>V .* V&#39; .* V3</code> contains about 1GB of data,  the writing of which is avoided by giving the option <code>lazy</code>: </p><pre><code class="language-julia">using LazyArrays
V = rand(500);
V3 = reshape(V, 1,1,:);

@time sum(V .* V&#39; .* V3; dims=(2,3));                 # 0.6 seconds, 950 MB
@time @reduce W[i] := sum(j,k) V[i] * V[j] * V[k];    # about the same

@time sum(BroadcastArray(*, V, V&#39;, V3); dims=(2,3));  # 0.025 s, 5 KB
@time @reduce W[i] := sum(j,k) V[i]*V[j]*V[k]  lazy;  # about the same </code></pre><p>Finally, the package <a href="https://github.com/Jutho/Strided.jl">Strided.jl</a> can apply multi-threading to  broadcasting, and some other magic. You can enable it with the option <code>strided</code>, like this: </p><pre><code class="language-julia">using Strided # and export JULIA_NUM_THREADS = 4 before starting
A = randn(4000,4000); 
B = similar(A);
Threads.nthreads() == 4 # true

@time B .= (A .+ A&#39;) ./ 2;                            # 0.12 seconds
@time @cast B[i,j] = (A[i,j] + A[j,i])/2;             # the same 

@time @strided B .= (A .+ A&#39;) ./ 2;                   # 0.025 seconds
@time @cast B[i,j] = (A[i,j] + A[j,i])/2 strided;     # the same</code></pre><p>&lt;!â€“</p><h2><a class="nav-anchor" id="Wishlist-1" href="#Wishlist-1">Wishlist</a></h2><ul><li><p>More torture-tests. This is very new, and probably has many bugs.</p></li><li><p>Better writing into sliced arrays? Right now <code>@cast A[i]{j} = B[i,j] j:3</code> is allowed,  but <code>A[i][j]</code> with ordinary sub-arrays is not.</p></li><li><p>More compact notation? This gets messy with many indices, perahps something closer to <a href="https://github.com/arogozhnikov/einops"><code>einops</code></a>&#39;s notation could be used without having to parse strings (try this with <code>macro arrow(exs...) @show(exs); nothing end</code>):</p></li></ul><pre><code class="language-julia">Y = @arrow [X]  i j k l -n  =&gt;  (i,k) (j,l) n   [i:2, j:3]

Z = @arrow [Y / sum, i:2, j:3]  i\k  j\l n  =&gt;  k l n</code></pre><ul><li><p>Support for mutating operators <code>+=</code> and <code>*=</code> etc. like <a href="https://github.com/ahwillia/Einsum.jl">@einsum</a> does. </p></li><li><p>Ability to write shifts in this notation:</p></li></ul><pre><code class="language-julia">@cast A[i,j] = B[i+1,j+3]     # circshift!(A, B, (1,3)) or perhaps (-1,-3)</code></pre><ul><li>A mullet as awesome as <a href="https://www.youtube.com/watch?v=Ohidv69WfNQ">Rich DuLaney</a> had.</li></ul><p>â€“&gt;</p><h2><a class="nav-anchor" id="About-1" href="#About-1">About</a></h2><p>First uploaded January 2019 as <code>TensorSlice.jl</code> with only the <code>@shape</code> macro, and later <code>@reduce</code>. </p><p>Then I understood how to implement arbitrary broadcasting in <code>@cast</code>,  and this replaced the earlier implementation. </p><p>&lt;!â€“</p><h3><a class="nav-anchor" id="See-also-1" href="#See-also-1">See also</a></h3><ul><li><p><a href="https://github.com/Jutho/TensorOperations.jl">TensorOperations.jl</a> and <a href="https://github.com/ahwillia/Einsum.jl">Einsum.jl</a> </p></li><li></li></ul><p>â€“&gt; &lt;!â€“ <a href="https://travis-ci.org/mcabbott/TensorCast.jl"><img src="https://travis-ci.org/mcabbott/TensorCast.jl.svg?branch=master" alt="Build Status"/></a></p><p>&lt;img src=&quot;https://raw.githubusercontent.com/mcabbott/TensorCast.jl/master/as-seen-on-TV.png&quot; width=&quot;50&quot; height=&quot;40&quot; align=&quot;right&quot;&gt;&lt;img src = &quot;https://camo.githubusercontent.com/890acbdcb87868b382af9a4b1fac507b9659d9bf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667&quot; align=&quot;right&quot;&gt; â€“&gt;</p><p>&lt;!â€“ pandoc -s -o README.html  README.md â€“&gt;</p><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
