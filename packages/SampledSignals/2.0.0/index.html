<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · SampledSignals.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>SampledSignals.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Types-1">Types</a></li><li><a class="toctext" href="#Stream-Read/Write-Semantics-1">Stream Read/Write Semantics</a></li><li><a class="toctext" href="#Plotting-Support-1">Plotting Support</a></li><li><a class="toctext" href="#REPL-Display-1">REPL Display</a></li><li><a class="toctext" href="#Jupyter-Notebook-Display-1">Jupyter Notebook Display</a></li><li><a class="toctext" href="#Defining-Custom-Sink/Source-types-1">Defining Custom Sink/Source types</a></li><li><a class="toctext" href="#Connecting-Streams-1">Connecting Streams</a></li><li><a class="toctext" href="#Conversions-1">Conversions</a></li><li><a class="toctext" href="#Sticky-Design-Issues-1">Sticky Design Issues</a></li><li><a class="toctext" href="#AbstractTrees-troubleshooting-1">AbstractTrees troubleshooting</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="SampledSignals-1" href="#SampledSignals-1">SampledSignals</a></h1><p><a href="https://travis-ci.org/JuliaAudio/SampledSignals.jl"><img src="https://travis-ci.org/JuliaAudio/SampledSignals.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://ci.appveyor.com/project/ssfrr/sampledsignals-jl/branch/master"><img src="https://ci.appveyor.com/api/projects/status/qioy8vjpwg51s77p/branch/master?svg=true" alt="Build status"/></a> <a href="http://codecov.io/github/JuliaAudio/SampledSignals.jl?branch=master"><img src="http://codecov.io/github/JuliaAudio/SampledSignals.jl/coverage.svg?branch=master" alt="codecov.io"/></a></p><p><strong>Dev Note: Currently the master branch of SampledSignals requires the master branch of LibSndFile for its tests.</strong></p><p>SampledSignals is a collection of types intended to be used on multichannel sampled signals like audio or radio data, EEG signals, etc., to provide better interoperability between packages that read data from files or streams, DSP packages, and output and display packages.</p><p>SampledSignals provides several types to stream and store sampled data: <code>SampleBuf</code>, <code>SpectrumBuf</code>, <code>SampleSource</code>, <code>SampleSink</code> which make use of <a href="https://github.com/JuliaMath/IntervalSets.jl">IntervalSets</a> that can be used to represent contiguous ranges using a convenient <code>a..b</code> syntax, this feature is copied mostly from the <a href="https://github.com/mbauman/AxisArrays.jl">AxisArrays</a> package, which also inspired much of the implementation of this package.</p><p>We also use the <a href="https://github.com/ajkeller34/Unitful.jl">Unitful</a> package to enable indexing using real-world units like seconds or hertz. <code>SampledSignals</code> re-exports the relevant <code>Unitful</code> units (<code>ns</code>, <code>ms</code>, <code>µs</code>, <code>s</code>, <code>Hz</code>, <code>kHz</code>, <code>MHz</code>, <code>GHz</code>, <code>THz</code>, and <code>dB</code>) so you don&#39;t need to import <code>Unitful</code> explicitly.</p><p>Because these buffer and stream types are sample-rate and channel-count aware, this package can automatically handle situations like writing a mono source into a stereo buffer, or resampling to match sample rates. This greatly simplifies the process of writing new streaming sample back-ends, because you only need to implement a small number of fundamental read/write operations, and SampledSignals will handle the plumbing.</p><h2><a class="nav-anchor" id="Types-1" href="#Types-1">Types</a></h2><h3><a class="nav-anchor" id="SampleBuf/SpectrumBuf-1" href="#SampleBuf/SpectrumBuf-1">SampleBuf/SpectrumBuf</a></h3><p><code>SampleBuf</code>s and <code>SpectrumBuf</code>s represent multichannel, regularly-sampled data, providing handy indexing operations. The only difference between them is that <code>SampleBuf</code>s are time-domain and <code>SpectrumBuf</code>s are frequency-domain, which affects how they can be indexed and how they are displayed. They subtypes AbstractArray and should be drop-in compatible with raw arrays, with the exception that indexing a row (a single frame of multiple channels) will result in a 1xN result (a 1-frame multichannel buffer) instead of a 1D Vector, which is the Array behavior as of 0.5. The two main advantages of these types are they are sample-rate aware and that they support indexing with real-world units like seconds or hertz (depending on the domain). When defining methods on these types you can use the <code>AbstractSampleBuf</code> type to refer to both of them collectively.</p><h4><a class="nav-anchor" id="Methods-1" href="#Methods-1">Methods</a></h4><ul><li><code>samplerate</code></li><li><code>samplerate!</code></li><li><code>nchannels</code></li><li><code>nframes</code></li><li><code>domain</code></li><li><code>channelptr</code></li></ul><h3><a class="nav-anchor" id="SampleSource-1" href="#SampleSource-1">SampleSource</a></h3><p><code>SampleSource</code> is an abstract type representing a source of samples, which might for instance represent a microphone input. The <code>read</code> method just gives you a single frame (an 1xN N-channel <code>SampleBuf</code>), but you can also read an integer number of samples or an amount of time given in seconds. This package includes the <code>SampleBufSource</code> type that is a useful example and also can be used to test your implementations of the stream interface.</p><h4><a class="nav-anchor" id="Methods-2" href="#Methods-2">Methods</a></h4><ul><li><code>samplerate</code></li><li><code>nchannels</code></li><li><code>blocksize</code></li></ul><h3><a class="nav-anchor" id="SampleSink-1" href="#SampleSink-1">SampleSink</a></h3><p><code>SampleSink</code> is an abstract type representing a sink for samples to be written to, for instance representing your laptop speakers. The main method used here is <code>write</code> which writes a <code>SampleBuf</code> to a <code>SampleSink</code>. This package includes the <code>SampleBufSink</code> type that is a useful example and also can be used to test your implementations of the stream interface.</p><h4><a class="nav-anchor" id="Methods-3" href="#Methods-3">Methods</a></h4><ul><li><code>samplerate</code></li><li><code>nchannels</code></li><li><code>blocksize</code></li></ul><h2><a class="nav-anchor" id="Stream-Read/Write-Semantics-1" href="#Stream-Read/Write-Semantics-1">Stream Read/Write Semantics</a></h2><p>SampledSignals tries to keep the semantics of reading and writing simple and consistent. If a read or write is attempted and there&#39;s not enough space or samples available (but the stream is still open), the operation will block the task until it can proceed. If the stream is closed, you can always check the return value of the operation for a partially-completed read or write.</p><p>Rather than specifying read and write durations in terms of frames, you can also specify in seconds. In this case <code>read!</code> and <code>write</code> will return seconds as well. If the operation completes fully, the returned duration will exactly match the given duration, so you can still check for equality.</p><p><code>read!(source, buf)</code> reads from <code>source</code> and places the data in <code>buf</code>. It returns the number of frames that were read. If the number returned is less than the length of <code>buf</code>, you know that <code>source</code> was closed before the read was complete.</p><p><code>read(source, n)</code> reads <code>n</code> frames from the source and returns a new buffer filled with their contents. If the length of the returned buffer is shorter than <code>n</code> then you know that <code>source</code> was closed before the read was complete.</p><p><code>write(sink, buf)</code> writes the contents of <code>buf</code> into <code>sink</code>, and returns the number of frames that were written. If fewer frames were written than the length of <code>buf</code>, you know that <code>sink</code> was closed before the write was complete.</p><p><code>write(sink, source)</code> reads from <code>source</code> and writes to <code>sink</code> a block at a time, and returns the number of frames written to <code>sink</code>.</p><p><code>write(sink, source, n)</code> reads from <code>source</code> and writes to <code>sink</code> a block at a time, and returns the number of frames written to <code>sink</code>. If both the streams stay open it will return after writing <code>n</code> frames.</p><p><code>read!(source, sink)</code> reads from <code>source</code> and writes to <code>sink</code> a block at a time, and returns the number of frames read from <code>source</code>. This method is not currently implemented.</p><p>Note that when connecting <code>source</code>s to <code>sink</code>s, the only difference between <code>read!</code> and <code>write</code> is the return value. If the sampling rates match then the value returned should be the same in both cases, but will be different in the case of a samplerate conversion.</p><h2><a class="nav-anchor" id="Plotting-Support-1" href="#Plotting-Support-1">Plotting Support</a></h2><p>SampledSignals adds the <code>domain</code> function for <code>SampleBuf</code>s, which gives you the domain in real-world units at the buffer&#39;s sampling rate. This is especially useful for plotting because you can simply run <code>plot(domain(buf), buf)</code> and see your x axis in seconds. This also works for frequency-domain buffers, so you can do:</p><pre><code class="language-julia">spec = fft(buf)
plot(domain(spec), abs(spec))</code></pre><p>and see the magnitude spectrum plotted against actual frequencies.</p><h2><a class="nav-anchor" id="REPL-Display-1" href="#REPL-Display-1">REPL Display</a></h2><p>When displaying a buffer at the REPL, SampledSignals shows the length, channel count, sample rate, and duration. It also shows a coarse audio waveform, which shows the signal amplitude in dB.</p><pre><code class="language-julia">julia&gt; [buf[1:44100] buf[44100:88199]]
44100-frame, 2-channel SampleBuf{PCM16Sample, 2}
1.0s sampled at 44100Hz
▁▁▁▁▁▁▁▁▂▁▁▁▃▂▅▅▅▅▅▅▅▅▆▅▅▅▄▃▃▄▅▅▄▄▄▃▄▃▂▅▅▅▄▃▁▂▄▄▄▄▄▄▄▄▅▅▅▅▅▄▃▂▄▅▅▅▅▅▅▅▅▅▅▅▅▄▃▂▄▄
▃▃▄▄▄▃▂▂▂▂▄▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▄▂▂▁▁▅▃▃▂▄▂▄▃▃▄▃▄▂▁▃▂▂▃▃▃▃▃▃▃▃▃▃▃▄▄▄▅▅▄▄▄▆▆▄▃▅▄▂▁▁▂▁</code></pre><h2><a class="nav-anchor" id="Jupyter-Notebook-Display-1" href="#Jupyter-Notebook-Display-1">Jupyter Notebook Display</a></h2><p>When working in a Jupyter notebook (which can display rich HTML representations), <code>SampleBuf</code>s will show a waveform display and allow you to listen to the buffer using your browser&#39;s WebAudio support.</p><p><img src="http://juliaaudio.github.io/SampledSignals.jl/samplebuf_html_disp.png" alt="Example of SampleBuf display in a Jupyter Notebook"/></p><h2><a class="nav-anchor" id="Defining-Custom-Sink/Source-types-1" href="#Defining-Custom-Sink/Source-types-1">Defining Custom Sink/Source types</a></h2><p>Say you have a library that moves audio over a network, or interfaces with some software-defined radio hardware. You should be able to easily tap into the SampledSignals infrastructure by doing the following:</p><ol><li>Subtype <code>SampleSink</code> or <code>SampleSource</code></li><li>Implement <code>SampledSignals.unsafe_read!(source::YourSource, buf::Array, frameoffset, framecount)</code> (for sources) or <code>SampledSignals.unsafe_write(sink::YourSink, buf::Array, frameoffset, framecount)</code> (for sinks), which can assume that the channel count, sample rate, and type match between your stream type and the buffer type. The methods listed above in the &quot;Stream Read/Write Semantics&quot; section are implemented in terms of these base <code>unsafe_read!</code> and <code>unsafe_write</code> calls. SampledSignals will call these methods with a 1D or 2D (nframes x nchannels) <code>Array</code>, with each channel in its own column. Note that these <code>unsafe_*</code> methods might be called many times for a given high-level <code>read</code> or <code>write</code>, so you&#39;ll want to avoid allocating buffers within them, and instead store any temporary buffers you need inside of your stream type, so they&#39;re only created once.</li><li>Implement <code>SampledSignals.samplerate</code>, <code>SampledSignals.nchannels</code>, and <code>Base.eltype</code> for your type. SampledSignals uses your stream&#39;s reported properties through these methods to decide what conversions it needs to do when plugging together streams, so for instance if your stream type only supports writing 16-bit integer data, you might just have <code>SampledSignals.eltype(sink::MySink) = PCM16Sample</code>, and then SampledSignals will make sure that by the time it calls your <code>unsafe_write</code> method it will have converted things to the right datatype.</li><li>If your type has a preferred blocksize, implement <code>SampledSignals.blocksize</code>. Otherwise the fallback implementation will return <code>0</code>, meaning there&#39;s no preferred blocksize.</li></ol><p>For example, to define a <code>MySource</code> type, you would implement:</p><pre><code class="language-julia">Base.read!(src::MySource, buf::Array)
Base.eltype(source::MySource)
SampledSignals.samplerate(source::MySource)
SampledSignals.nchannels(source::MySource)</code></pre><p>Other methods, such as the non-modifying <code>read</code>, sample-rate converting versions, and time-based indexing are all handled by SampledSignals. You can see the implementation of <code>DummySampleSink</code> and <code>DummySampleSource</code> in <a href="src/DummySampleStream.jl">DummySampleStream.jl</a>, or the <a href="https://github.com/JuliaAudio/JACKAudio.jl">JACKAudio.jl</a> or <a href="https://github.com/JuliaAudio/PortAudio.jl">PortAudio.jl</a> packages for more complete examples.</p><h2><a class="nav-anchor" id="Connecting-Streams-1" href="#Connecting-Streams-1">Connecting Streams</a></h2><p>In addition to reading and writing buffers to streams, you can also set up direct stream-to-stream connections using the <code>write</code> function. For instance, if you have a sink <code>in</code> and a source <code>out</code>, you can connect them with <code>write(out, in)</code>. This will block the current task until the <code>in</code> stream ends, but you can give an optional third argument in samples or seconds to write a limited amount. The implementation just reads a block at a time from <code>in</code> and writes the received data to <code>out</code>. You can set the blocksize with a keyword argument, e.g. <code>write(out, in, blocksize=1024)</code> will read blocks of 1024 frames at a time. The default blocksize is 4096 frames.</p><h2><a class="nav-anchor" id="Conversions-1" href="#Conversions-1">Conversions</a></h2><p>Sometimes you have a source of data (a <code>SampleBuf</code> or <code>SampleSource</code>) that is not in the same format as the stream you want to write to. For instance, you may have a audio file recorded at 44.1kHz and want to play to your soundcard configured for 48kHz (samplerate conversion). Or you want to play a mono microphone signal through your stereo soundcard (channel conversion). Or you generated a buffer of floating point values that you want to write to a 16-bit integer WAVE file (format conversion). SampledSignals handles these conversions transparently.</p><p>SampledSignals uses several wrapper types to implement this conversion. Normally these wrappers are created automatically when you attempt an operation that needs conversion, but you can also create them explictly. For instance, if you have a sink <code>sink</code> that is operating at 48kHz (say a soundcard output), and a source <code>source</code> at 44.1kHz, the code <code>write(sink, source)</code> is equivalent to:</p><pre><code class="language-julia">wrapper = ResampleSink(sink, 44.1kHz)
write(wrapper, source)</code></pre><h3><a class="nav-anchor" id="Samplerate-Conversion-1" href="#Samplerate-Conversion-1">Samplerate Conversion</a></h3><p>The <code>ResampleSink</code> wrapper type wraps around a sink. Writing to this wrapper sink will resample the given data and pass it to the original sink. It maintains state between writes so that the interpolation is correct across the boundaries of multiple writes.</p><p><code>ResampleSink</code> handles resampling with polyphase FIR resampling filter.</p><h3><a class="nav-anchor" id="Channel-Conversion-1" href="#Channel-Conversion-1">Channel Conversion</a></h3><p>The <code>UpMixSink</code> and <code>DownMixSink</code> types wrap around a multi-channel or single-channel sink, respectively, so that you can write a mono signal to a stereo or multichannel output and it will be written to all channels, or you can write a multi-channel signal into a mono sink and it will be down-mixed.</p><h3><a class="nav-anchor" id="Format-Conversion-1" href="#Format-Conversion-1">Format Conversion</a></h3><p>Format conversion is handled automatically by Julia when we write data from one buffer type to another. There are several potential gotchas to consider. When dealing with integer samples, it&#39;s better to represent them with <code>Fixed</code> from <a href="https://github.com/JeffBezanson/FixedPointNumbers.jl">FixedPointNumbers.jl</a>. For example, 16-bit integer samples can be represented by <code>Fixed{Int16, 15}</code>. In fact SampledSignals provides some handy aliases for signed fixed-point samples: <code>PCM8Sample</code>, <code>PCM16Sample</code>, <code>PCM24Sample</code>, and <code>PCM32Sample</code>. This way julia knows how to convert properly between fixed and floating-point values. One problem with this is that 16-bit fixed-point data can only represent values in the interval [-1.0, 0.99997], so if you have full-scale [-1.0, 1.0] floating point data, you will run into problems converting to fixed point values. One solution would be to first multiply your signal by <code>typemax(PCM16Sample)</code> before converting.</p><h2><a class="nav-anchor" id="Sticky-Design-Issues-1" href="#Sticky-Design-Issues-1">Sticky Design Issues</a></h2><p>There are a number of issues that I&#39;m still in the process of figuring out:</p><h3><a class="nav-anchor" id="Interpolation-1" href="#Interpolation-1">Interpolation</a></h3><p>Currently for real-valued indices like time we are just rounding to the nearest sample index, but often you&#39;ll want an interpolated value. How does the user specify what type of interpolation they want? One idea would be to allow an interpolation type symbol in the indexing, like <code>x[1.25s, :cubic]</code>, but that seems a little weird. Another option would be to have LinearInterpolator{T}, CubicInterpolator{T}, etc. wrappers that determine interpolation behavior.</p><h3><a class="nav-anchor" id="Relative-vs.-Absolute-indexing-1" href="#Relative-vs.-Absolute-indexing-1">Relative vs. Absolute indexing</a></h3><p>When we take a slice of a SampleBuf (e.g. take the span from 1s to 3s of a 10s audio buffer), what is the indexing domain of the result? Specifically, is it 1s-3s, or is it 0s-2s? For time-domain signals I can see wanting indexing relative to the beginning of the buffer, but in frequency-domain buffers it seems you usually want to keep the frequency information. Keeping track of the time information could also be useful if you split out a signal for processing and then want to re-combine things at the end.</p><h2><a class="nav-anchor" id="AbstractTrees-troubleshooting-1" href="#AbstractTrees-troubleshooting-1">AbstractTrees troubleshooting</a></h2><p>To run the SampledSignals tests you need Gumbo, but installing both Gumbo and Juno causes issues that prevent you from running the tests on 0.6. Here are the details:</p><ul><li>AbstractTrees &lt; v0.1.0 is not compatible with Julia v0.6</li><li>Gumbo 0.3.0 (latest) requires AbstractTrees &gt;= v0.0.4</li><li>ASTInterpreter requires AbstractTrees between v0.0.4 and v0.1.0<ul><li>this limitation isn&#39;t in the REQUIRE in the repo, but was added to METADATA</li></ul></li><li>ASTInterpreter is required by Atom and Gallium</li></ul><h3><a class="nav-anchor" id="Solution:-1" href="#Solution:-1">Solution:</a></h3><p>Run <code>Pkg.checkout(&quot;ASTInterpreter&quot;)</code> and <code>Pkg.resolve()</code> until a new version is tagged. The ASTInterpreter tests don&#39;t pass, but it gets things working enough to get AbstractTrees back to 0.1.0 and the SampledSignals tests runnable.</p><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
