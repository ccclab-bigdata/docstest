<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · ReinforcementLearning.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ReinforcementLearning.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Introduction</a><ul class="internal"><li class="toplevel"><a class="toctext" href="#What-is-reinforcement-learning?-1">What is reinforcement learning?</a></li><li class="toplevel"><a class="toctext" href="#Features-1">Features</a></li><li><a class="toctext" href="#Learning-methods-1">Learning methods</a></li><li><a class="toctext" href="#Environments-1">Environments</a></li><li><a class="toctext" href="#Preprocessors-1">Preprocessors</a></li><li><a class="toctext" href="#Helper-Functions-1">Helper Functions</a></li><li class="toplevel"><a class="toctext" href="#Installation-1">Installation</a></li><li class="toplevel"><a class="toctext" href="#Credits-1">Credits</a></li><li class="toplevel"><a class="toctext" href="#Contribute-1">Contribute</a></li></ul></li><li><a class="toctext" href="usage/">Usage</a></li><li><a class="toctext" href="tutorial/">Tutorial</a></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="comparison/">Comparison</a></li><li><a class="toctext" href="learning/">Learning</a></li><li><a class="toctext" href="learners/">Learners</a></li><li><a class="toctext" href="buffers/">Buffers</a></li><li><a class="toctext" href="environments/">Environments</a></li><li><a class="toctext" href="stop/">Stopping Criteria</a></li><li><a class="toctext" href="preprocessors/">Preprocessors</a></li><li><a class="toctext" href="policies/">Policies</a></li><li><a class="toctext" href="callbacks/">Callbacks</a></li><li><a class="toctext" href="metrics/">Evaluation Metrics</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Introduction</a></li></ul></nav><hr/><div id="topbar"><span>Introduction</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="ReinforcementLearning-1" href="#ReinforcementLearning-1">ReinforcementLearning</a></h1><p><a href="https://JuliaReinforcementLearning.github.io/ReinforcementLearning.jl/latest"><img src="https://img.shields.io/badge/docs-latest-blue.svg" alt="Documentation"/></a> <a href="https://travis-ci.com/JuliaReinforcementLearning/ReinforcementLearning.jl"><img src="https://travis-ci.com/JuliaReinforcementLearning/ReinforcementLearning.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://codecov.io/gh/JuliaReinforcementLearning/ReinforcementLearning.jl"><img src="https://codecov.io/gh/JuliaReinforcementLearning/ReinforcementLearning.jl/branch/master/graph/badge.svg" alt="codecov"/></a></p><p>A reinforcement learning package for <a href="https://julialang.org/">Julia</a>.</p><h1><a class="nav-anchor" id="What-is-reinforcement-learning?-1" href="#What-is-reinforcement-learning?-1">What is reinforcement learning?</a></h1><ul><li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Wikipedia</a></li><li><a href="http://incompleteideas.net/book/the-book-2nd.html">New Sutton &amp; Barto book</a></li></ul><h1><a class="nav-anchor" id="Features-1" href="#Features-1">Features</a></h1><h2><a class="nav-anchor" id="Learning-methods-1" href="#Learning-methods-1">Learning methods</a></h2><table><tr><th>name</th><th>discrete states</th><th>linear approximation</th><th>non-linear approximation</th></tr><tr><td>Q-learning/SARSA(λ)</td><td>✓</td><td>✓</td><td></td></tr><tr><td>n-step Q-learning/SARSA</td><td>✓</td><td>✓</td><td></td></tr><tr><td>Online Policy Gradient</td><td>✓</td><td>✓</td><td></td></tr><tr><td>Episodic Reinforce</td><td>✓</td><td>✓</td><td></td></tr><tr><td>n-step Actor-Critic Policy-Gradient</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Monte Carlo Control</td><td>✓</td><td></td><td></td></tr><tr><td>Prioritized Sweeping</td><td>✓</td><td></td><td></td></tr><tr><td>(double) DQN</td><td></td><td>✓</td><td>✓</td></tr></table><h2><a class="nav-anchor" id="Environments-1" href="#Environments-1">Environments</a></h2><table><tr><th>name</th><th>state space</th><th>action space</th></tr><tr><td><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentClassicControl.jl">Cartpole</a></td><td>4D</td><td>discrete</td></tr><tr><td><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentClassicControl.jl">Mountain Car</a></td><td>2D</td><td>discrete</td></tr><tr><td><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentClassicControl.jl">Pendulum</a></td><td>3D</td><td>1D</td></tr><tr><td><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentAtari.jl">Atari</a></td><td>pixel images</td><td>discrete</td></tr><tr><td><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentVizDoom.jl">VizDoom</a></td><td>pixel images</td><td>discrete</td></tr><tr><td><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentDiscrete.jl">POMDPs</a>, MDPs, <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentDiscrete.jl">Mazes</a>, <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentDiscrete.jl">Cliffwalking</a></td><td>discrete</td><td>discrete</td></tr><tr><td><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironmentGym.jl">OpenAi Gym</a> (using PyCall)</td><td>see <a href="https://github.com/openai/gym">here</a></td><td>see <a href="https://github.com/openai/gym">here</a></td></tr></table><h2><a class="nav-anchor" id="Preprocessors-1" href="#Preprocessors-1">Preprocessors</a></h2><ul><li>State Aggregation</li><li>Tile Coding</li><li>Random Projections</li><li>Radial Basis Functions</li></ul><h2><a class="nav-anchor" id="Helper-Functions-1" href="#Helper-Functions-1">Helper Functions</a></h2><ul><li>comparison of different methods</li><li>callbacks to track performance, change exploration policy, save models during learning etc.</li></ul><h1><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h1><pre><code class="language-julia">(v1.0) pkg&gt; add ReinforcementLearning</code></pre><p>or in julia v0.6</p><pre><code class="language-julia">Pkg.add(&quot;ReinforcementLearning&quot;)</code></pre><h1><a class="nav-anchor" id="Credits-1" href="#Credits-1">Credits</a></h1><ul><li>Main author: Johanni Brea</li><li>Contributions: Marco Lehmann, Raphaël Nunes</li></ul><h1><a class="nav-anchor" id="Contribute-1" href="#Contribute-1">Contribute</a></h1><p>Contributions are highly welcome. Please have a look at the issues.</p><footer><hr/><a class="next" href="usage/"><span class="direction">Next</span><span class="title">Usage</span></a></footer></article></body></html>
