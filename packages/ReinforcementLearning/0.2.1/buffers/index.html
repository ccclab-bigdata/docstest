<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Buffers · ReinforcementLearning.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ReinforcementLearning.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Introduction</a></li><li><a class="toctext" href="../usage/">Usage</a></li><li><a class="toctext" href="../tutorial/">Tutorial</a></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../comparison/">Comparison</a></li><li><a class="toctext" href="../learning/">Learning</a></li><li><a class="toctext" href="../learners/">Learners</a></li><li class="current"><a class="toctext" href>Buffers</a><ul class="internal"></ul></li><li><a class="toctext" href="../environments/">Environments</a></li><li><a class="toctext" href="../stop/">Stopping Criteria</a></li><li><a class="toctext" href="../preprocessors/">Preprocessors</a></li><li><a class="toctext" href="../policies/">Policies</a></li><li><a class="toctext" href="../callbacks/">Callbacks</a></li><li><a class="toctext" href="../metrics/">Evaluation Metrics</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Reference</li><li><a href>Buffers</a></li></ul></nav><hr/><div id="topbar"><span>Buffers</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="buffers-1" href="#buffers-1">Buffers</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ArrayCircularBuffer" href="#ReinforcementLearning.ArrayCircularBuffer"><code>ReinforcementLearning.ArrayCircularBuffer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">mutable struct ArrayCircularBuffer{T}
    data::T
    capacity::Int64
    start::Int64
    counter::Int64
    full::Bool</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ArrayCircularBuffer-NTuple{4,Any}" href="#ReinforcementLearning.ArrayCircularBuffer-NTuple{4,Any}"><code>ReinforcementLearning.ArrayCircularBuffer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ArrayCircularBuffer(arraytype, datatype, elemshape, capacity)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ArrayStateBuffer" href="#ReinforcementLearning.ArrayStateBuffer"><code>ReinforcementLearning.ArrayStateBuffer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">struct ArrayStateBuffer{Ts, Ta}
    states::ArrayCircularBuffer{Ts}
    actions::CircularBuffer{Ta}
    rewards::CircularBuffer{Float64}
    done::CircularBuffer{Bool}</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.ArrayStateBuffer-Tuple{}" href="#ReinforcementLearning.ArrayStateBuffer-Tuple{}"><code>ReinforcementLearning.ArrayStateBuffer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ArrayStateBuffer(; arraytype = Array, datatype = Float64, 
                   elemshape = (1), actiontype = Int64, 
                   capacity = 2, capacitystates = capacity,
                   capacityrewards = capacity - 1)</code></pre><p>An <code>ArrayStateBuffer</code> is similar to a <a href="#ReinforcementLearning.Buffer"><code>Buffer</code></a> but the states are stored in a prealocated array of size <code>(elemshape..., capacity)</code>. <code>K</code> consecutive states at position <code>i</code> in the state buffer can can efficiently be retrieved with <code>nmarkovview(buffer.states, i, K)</code> or <code>nmarkovgetindex(buffer.states, i, K)</code>. See the implementation of DQN for an example. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.Buffer" href="#ReinforcementLearning.Buffer"><code>ReinforcementLearning.Buffer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">struct Buffer{Ts, Ta}
    states::CircularBuffer{Ts}
    actions::CircularBuffer{Ta}
    rewards::CircularBuffer{Float64}
    done::CircularBuffer{Bool}</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.Buffer-Tuple{}" href="#ReinforcementLearning.Buffer-Tuple{}"><code>ReinforcementLearning.Buffer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">Buffer(; statetype = Int64, actiontype = Int64, 
         capacity = 2, capacitystates = capacity,
         capacityrewards = capacity - 1)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.EpisodeBuffer" href="#ReinforcementLearning.EpisodeBuffer"><code>ReinforcementLearning.EpisodeBuffer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">struct EpisodeBuffer{Ts, Ta}
    states::Array{Ts, 1}
    actions::Array{Ta, 1}
    rewards::Array{Float64, 1}
    done::Array{Bool, 1}</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="ReinforcementLearning.EpisodeBuffer-Tuple{}" href="#ReinforcementLearning.EpisodeBuffer-Tuple{}"><code>ReinforcementLearning.EpisodeBuffer</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">EpisodeBuffer(; statetype = Int64, actiontype = Int64) = 
    EpisodeBuffer(statetype[], actiontype[], Float64[], Bool[])</code></pre></div></div></section><footer><hr/><a class="previous" href="../learners/"><span class="direction">Previous</span><span class="title">Learners</span></a><a class="next" href="../environments/"><span class="direction">Next</span><span class="title">Environments</span></a></footer></article></body></html>
