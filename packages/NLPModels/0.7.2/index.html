<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · NLPModels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>NLPModels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Optimization-Problems-1">Optimization Problems</a></li><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#External-models-1">External models</a></li><li><a class="toctext" href="#Main-Methods-1">Main Methods</a></li><li><a class="toctext" href="#Attributes-1">Attributes</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="NLPModels-1" href="#NLPModels-1">NLPModels</a></h1><p>This package provides general guidelines to represent optimization problems in Julia and a standardized API to evaluate the functions and their derivatives. The main objective is to be able to rely on that API when designing optimization solvers in Julia.</p><p>Cite as</p><pre><code class="language-none">Abel Soares Siqueira, &amp; Dominique Orban. (2019, February 6). NLPModels.jl. Zenodo.
http://doi.org/10.5281/zenodo.2558627</code></pre><p><a href="https://doi.org/10.5281/zenodo.2558627"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.2558627.svg" alt="DOI"/></a></p><h3><a class="nav-anchor" id="Stable-release-[![GitHub-release](https://img.shields.io/github/release/JuliaSmoothOptimizers/NLPModels.jl.svg)](https://github.com/JuliaSmoothOptimizers/NLPModels.jl/releases/latest)-1" href="#Stable-release-[![GitHub-release](https://img.shields.io/github/release/JuliaSmoothOptimizers/NLPModels.jl.svg)](https://github.com/JuliaSmoothOptimizers/NLPModels.jl/releases/latest)-1">Stable release <a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/releases/latest"><img src="https://img.shields.io/github/release/JuliaSmoothOptimizers/NLPModels.jl.svg" alt="GitHub release"/></a></a></h3><ul><li>Documentation:</li></ul><p><a href="https://JuliaSmoothOptimizers.github.io/NLPModels.jl/stable"><img src="https://img.shields.io/badge/docs-stable-3f51b5.svg" alt/></a></p><ul><li>Package Evaluator:</li></ul><p><a href="http://pkg.julialang.org/?pkg=NLPModels"><img src="http://pkg.julialang.org/badges/NLPModels_0.5.svg" alt="NLPModels"/></a> <a href="http://pkg.julialang.org/?pkg=NLPModels"><img src="http://pkg.julialang.org/badges/NLPModels_0.6.svg" alt="NLPModels"/></a></p><ul><li>Chat: <a href="https://gitter.im/JuliaSmoothOptimizers/JuliaSmoothOptimizers"><img src="https://img.shields.io/gitter/room/JuliaSmoothOptimizers/JuliaSmoothOptimizers.svg" alt="Gitter"/></a></li></ul><h3><a class="nav-anchor" id="Development-version-1" href="#Development-version-1">Development version</a></h3><ul><li>Documentation:</li></ul><p><a href="https://JuliaSmoothOptimizers.github.io/NLPModels.jl/latest"><img src="https://img.shields.io/badge/docs-latest-3f51b5.svg" alt/></a></p><ul><li>Tests:</li></ul><p><a href="https://travis-ci.org/JuliaSmoothOptimizers/NLPModels.jl"><img src="https://travis-ci.org/JuliaSmoothOptimizers/NLPModels.jl.svg" alt="Master Build Status"/></a> <a href="https://ci.appveyor.com/project/dpo/nlpmodels-jl/branch/master"><img src="https://ci.appveyor.com/api/projects/status/l1rs9ajxkyc0cer9/branch/master?svg=true" alt="Master Build status"/></a> <a href="https://coveralls.io/github/JuliaSmoothOptimizers/NLPModels.jl?branch=master"><img src="https://coveralls.io/repos/JuliaSmoothOptimizers/NLPModels.jl/badge.svg?branch=master&amp;service=github" alt="Master Coverage Status"/></a></p><h2><a class="nav-anchor" id="Optimization-Problems-1" href="#Optimization-Problems-1">Optimization Problems</a></h2><p>Optimization problems are represented by an instance of (a subtype of) <code>AbstractNLPModel</code>. Such instances are composed of</p><ul><li>an instance of <code>NLPModelMeta</code>, which provides information about the problem, including the number of variables, constraints, bounds on the variables, etc.</li><li>other data specific to the provenance of the problem.</li></ul><p>See the <a href="https://JuliaSmoothOptimizers.github.io/NLPModels.jl/latest">documentation</a> for details on the models, a tutorial and the API.</p><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><pre><code class="language-julia">Pkg.add(&quot;NLPModels&quot;)</code></pre><h2><a class="nav-anchor" id="External-models-1" href="#External-models-1">External models</a></h2><p>In addition to the models available in this package, there are some external models for specific needs:</p><ul><li><a href="https://github.com/JuliaSmoothOptimizers/AmplNLReader.jl">AmplNLReader.jl</a>: Interface for <a href="http://www.ampl.com/">AMPL</a>;</li><li><a href="https://github.com/JuliaSmoothOptimizers/CUTEst.jl">CUTEst.jl</a>: Interface for CUTEst problems;</li><li><a href="https://github.com/JuliaSmoothOptimizers/NLPJuMPModels.jl">NLPJuMPModels.jl</a>: Converts MathProgBase/JuMP models to and from NLPModels.</li></ul><h2><a class="nav-anchor" id="Main-Methods-1" href="#Main-Methods-1">Main Methods</a></h2><p>If <code>model</code> is an instance of an appropriate subtype of <code>AbstractNLPModel</code>, the following methods are normally defined:</p><ul><li><code>obj(model, x)</code>: evaluate <em>f(x)</em>, the objective at <code>x</code></li><li><code>cons(model x)</code>: evaluate <em>c(x)</em>, the vector of general constraints at <code>x</code></li></ul><p>The following methods are defined if first-order derivatives are available:</p><ul><li><code>grad(model, x)</code>: evaluate <em>∇f(x)</em>, the objective gradient at <code>x</code></li><li><code>jac(model, x)</code>: evaluate <em>J(x)</em>, the Jacobian of <em>c</em> at <code>x</code> as a sparse matrix</li></ul><p>If Jacobian-vector products can be computed more efficiently than by evaluating the Jacobian explicitly, the following methods may be implemented:</p><ul><li><code>jprod(model, x, v)</code>: evaluate the result of the matrix-vector product <em>J(x)⋅v</em></li><li><code>jtprod(model, x, u)</code>: evaluate the result of the matrix-vector product <em>J(x)ᵀ⋅u</em></li></ul><p>The following method is defined if second-order derivatives are available:</p><ul><li><code>hess(model, x, y)</code>: evaluate <em>∇²L(x,y)</em>, the Hessian of the Lagrangian at <code>x</code> and <code>y</code></li></ul><p>If Hessian-vector products can be computed more efficiently than by evaluating the Hessian explicitly, the following method may be implemented:</p><ul><li><code>hprod(model, x, v, y)</code>: evaluate the result of the matrix-vector product <em>∇²L(x,y)⋅v</em></li></ul><p>Several in-place variants of the methods above may also be implemented.</p><p>The complete list of methods that an interface may implement is as follows:</p><ul><li><code>reset!()</code>,</li><li><code>write_sol()</code>,</li><li><code>varscale()</code>,</li><li><code>lagscale()</code>,</li><li><code>conscale()</code>,</li><li><code>obj()</code>,</li><li><code>grad()</code>,</li><li><code>grad!()</code>,</li><li><code>cons()</code>,</li><li><code>cons!()</code>,</li><li><code>jth_con()</code>,</li><li><code>jth_congrad()</code>,</li><li><code>jth_congrad!()</code>,</li><li><code>jth_sparse_congrad()</code>,</li><li><code>jac_coord()</code>,</li><li><code>jac()</code>,</li><li><code>jac_op()</code>,</li><li><code>jth_hprod()</code>,</li><li><code>jth_hprod!()</code>,</li><li><code>ghjvprod()</code>,</li><li><code>ghjvprod!()</code>,</li><li><code>hess_coord()</code>,</li><li><code>hess()</code>,</li><li><code>hess_op()</code></li><li><code>hprod()</code>,</li><li><code>hprod!</code></li></ul><h2><a class="nav-anchor" id="Attributes-1" href="#Attributes-1">Attributes</a></h2><p><code>NLPModelMeta</code> objects have the following attributes:</p><table><tr><th>Attribute</th><th>Type</th><th>Notes</th></tr><tr><td><code>nvar</code></td><td><code>Int</code></td><td>number of variables</td></tr><tr><td><code>x0</code></td><td><code>Array{Float64,1}</code></td><td>initial guess</td></tr><tr><td><code>lvar</code></td><td><code>Array{Float64,1}</code></td><td>vector of lower bounds</td></tr><tr><td><code>uvar</code></td><td><code>Array{Float64,1}</code></td><td>vector of upper bounds</td></tr><tr><td><code>ifix</code></td><td><code>Array{Int64,1}</code></td><td>indices of fixed variables</td></tr><tr><td><code>ilow</code></td><td><code>Array{Int64,1}</code></td><td>indices of variables with lower bound only</td></tr><tr><td><code>iupp</code></td><td><code>Array{Int64,1}</code></td><td>indices of variables with upper bound only</td></tr><tr><td><code>irng</code></td><td><code>Array{Int64,1}</code></td><td>indices of variables with lower and upper bound (range)</td></tr><tr><td><code>ifree</code></td><td><code>Array{Int64,1}</code></td><td>indices of free variables</td></tr><tr><td><code>iinf</code></td><td><code>Array{Int64,1}</code></td><td>indices of visibly infeasible bounds</td></tr><tr><td><code>ncon</code></td><td><code>Int</code></td><td>total number of general constraints</td></tr><tr><td><code>nlin</code></td><td><code>Int</code></td><td>number of linear constraints</td></tr><tr><td><code>nnln</code></td><td><code>Int</code></td><td>number of nonlinear general constraints</td></tr><tr><td><code>nnet</code></td><td><code>Int</code></td><td>number of nonlinear network constraints</td></tr><tr><td><code>y0</code></td><td><code>Array{Float64,1}</code></td><td>initial Lagrange multipliers</td></tr><tr><td><code>lcon</code></td><td><code>Array{Float64,1}</code></td><td>vector of constraint lower bounds</td></tr><tr><td><code>ucon</code></td><td><code>Array{Float64,1}</code></td><td>vector of constraint upper bounds</td></tr><tr><td><code>lin</code></td><td><code>Range1{Int64}</code></td><td>indices of linear constraints</td></tr><tr><td><code>nln</code></td><td><code>Range1{Int64}</code></td><td>indices of nonlinear constraints (not network)</td></tr><tr><td><code>nnet</code></td><td><code>Range1{Int64}</code></td><td>indices of nonlinear network constraints</td></tr><tr><td><code>jfix</code></td><td><code>Array{Int64,1}</code></td><td>indices of equality constraints</td></tr><tr><td><code>jlow</code></td><td><code>Array{Int64,1}</code></td><td>indices of constraints of the form c(x) ≥ cl</td></tr><tr><td><code>jupp</code></td><td><code>Array{Int64,1}</code></td><td>indices of constraints of the form c(x) ≤ cu</td></tr><tr><td><code>jrng</code></td><td><code>Array{Int64,1}</code></td><td>indices of constraints of the form cl ≤ c(x) ≤ cu</td></tr><tr><td><code>jfree</code></td><td><code>Array{Int64,1}</code></td><td>indices of &quot;free&quot; constraints (there shouldn&#39;t be any)</td></tr><tr><td><code>jinf</code></td><td><code>Array{Int64,1}</code></td><td>indices of the visibly infeasible constraints</td></tr><tr><td><code>nnzj</code></td><td><code>Int</code></td><td>number of nonzeros in the sparse Jacobian</td></tr><tr><td><code>nnzh</code></td><td><code>Int</code></td><td>number of nonzeros in the sparse Hessian</td></tr><tr><td><code>minimize</code></td><td><code>Bool</code></td><td>true if <code>optimize == minimize</code></td></tr><tr><td><code>islp</code></td><td><code>Bool</code></td><td>true if the problem is a linear program</td></tr><tr><td><code>name</code></td><td><code>ASCIIString</code></td><td>problem name</td></tr></table><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
