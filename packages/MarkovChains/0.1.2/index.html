<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme Â· MarkovChains.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MarkovChains.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li class="toplevel"><a class="toctext" href="#Tutorial-1">Tutorial</a></li><li class="toplevel"><a class="toctext" href="#Example-1">Example</a></li><li><a class="toctext" href="#A-birth-death-chain-1">A birth-death chain</a></li><li><a class="toctext" href="#A-chain-with-absorbing-states-1">A chain with absorbing states</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="MarkovChains.jl-1" href="#MarkovChains.jl-1">MarkovChains.jl</a></h1><p><a href="https://travis-ci.org/wangnangg/MarkovChains.jl"><img src="https://travis-ci.org/wangnangg/MarkovChains.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://coveralls.io/github/wangnangg/MarkovChains.jl?branch=master"><img src="https://coveralls.io/repos/github/wangnangg/MarkovChains.jl/badge.svg?branch=master" alt="Coverage Status"/></a></p><p>This pacakge provides functions to solve continuous time Markov chains for state probablities or accumulated sojourn times at a certain time point, including time infinity.</p><h1><a class="nav-anchor" id="Tutorial-1" href="#Tutorial-1">Tutorial</a></h1><p>Here&#39;s a detailed <a href="docs/tutorial.ipynb">tutorial</a> on how to use this package.</p><h1><a class="nav-anchor" id="Example-1" href="#Example-1">Example</a></h1><h2><a class="nav-anchor" id="A-birth-death-chain-1" href="#A-birth-death-chain-1">A birth-death chain</a></h2><p>The following example is about solving a 4 states birth-death chain at time 0.1, 1.0, and infinity.</p><pre><code class="language-julia">using MarkovChains
chain = ContMarkovChain()
n0 = add_state!(chain)
n1 = add_state!(chain)
n2 = add_state!(chain)
n3 = add_state!(chain)
add_transition!(chain, n0, n1, 1.0) #transition from n0 to n1 with rate = 1.0
add_transition!(chain, n1, n2, 1.0)
add_transition!(chain, n2, n3, 1.0)
add_transition!(chain, n3, n2, 3.0)
add_transition!(chain, n2, n1, 2.0)
add_transition!(chain, n1, n0, 1.0)
init_prob = sparsevec([1], [1.0])

sol = solve(chain, init_prob, 0.1) #solve at time 0.1
@show state_prob(sol, n1) #probablity of being at state n1 at time 0.1
# state_prob(sol, n1) = 0.08652421409974947

sol = solve(chain, init_prob, 1) 
@show state_prob(sol, n1)
# state_prob(sol, n1) = 0.375

sol = solve(chain, init_prob, Inf)
@show state_prob(sol, n1)
# state_prob(sol, n1) = 0.375</code></pre><h2><a class="nav-anchor" id="A-chain-with-absorbing-states-1" href="#A-chain-with-absorbing-states-1">A chain with absorbing states</a></h2><p>The following example is about solving a 3 states chain with absorbing states.</p><pre><code class="language-julia">chain = ContMarkovChain()
n1 = add_state!(chain)
n2 = add_state!(chain)
n3 = add_state!(chain)
add_transition!(chain, n1, n2, 2.0)
add_transition!(chain, n2, n3, 4.0)
init_prob = sparsevec([1], [1.0])

sol = solve(chain, init_prob, 0.5)

@show state_prob(sol, n2)
# state_prob(sol, n2) = 0.23254415793482963

@show state_cumtime(sol, n2) #cumulative time spent in state n2
# state_cumtime(sol, n2) = 0.09989410022321275

@show mean_time_to_absorption(chain, init_prob) #you may be interested in MTTA for a chain with absorbing states
# mean_time_to_absorption(chain, init_prob) = 0.75</code></pre><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
