<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · NetworkLearning.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>NetworkLearning.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><pre><code class="language-none">NetworkLearning.@print_verbose</code></pre><pre><code class="language-none">NetworkLearning.AbstractAdjacency</code></pre><pre><code class="language-none">NetworkLearning.AbstractCollectiveInferer</code></pre><pre><code class="language-none">NetworkLearning.AbstractNetworkLearner</code></pre><pre><code class="language-none">NetworkLearning.AbstractRelationalLearner</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.BayesRN" href="#NetworkLearning.BayesRN"><code>NetworkLearning.BayesRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Naive-Bayes relational neighbour learner (trainable).  Calculates neighbourhood likelihoods (i.e. given a vertex&#39;s class,  the class distribution in its neighbourhood) and uses the resulting information to compute class estimates for each vertex using a Bayesian approach.</p></div></div></section><pre><code class="language-none">NetworkLearning.BayesRNColumnMajor</code></pre><pre><code class="language-none">NetworkLearning.BayesRNRowMajor</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.ClassDistributionRN" href="#NetworkLearning.ClassDistributionRN"><code>NetworkLearning.ClassDistributionRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Class-distribution relational neighbour (trainable). Claculates a reference vector (RV) for each class (using the vertex neighbourhood information) and compares vertices to the reference vectors corresponding to each class using a similarity measure.</p></div></div></section><pre><code class="language-none">NetworkLearning.ClassDistributionRNColumnMajor</code></pre><pre><code class="language-none">NetworkLearning.ClassDistributionRNRowMajor</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.ComputableAdjacency" href="#NetworkLearning.ComputableAdjacency"><code>NetworkLearning.ComputableAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by a . function <code>f</code> and <code>data</code> on which the function can be applied. The result of <code>f(data)</code> has to be either a matrix or a graph.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.EmptyAdjacency" href="#NetworkLearning.EmptyAdjacency"><code>NetworkLearning.EmptyAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type indicating the lack of any adjacency information.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.GibbsSamplingInferer" href="#NetworkLearning.GibbsSamplingInferer"><code>NetworkLearning.GibbsSamplingInferer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Gibbs sapmpling object. Stores the parameters necessary for the algorithm.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.GraphAdjacency" href="#NetworkLearning.GraphAdjacency"><code>NetworkLearning.GraphAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by an <code>AbstractGraph</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.IterativeClassificationInferer" href="#NetworkLearning.IterativeClassificationInferer"><code>NetworkLearning.IterativeClassificationInferer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Iterative classification object. Stores the parameters necessary for the algorithm.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.MatrixAdjacency" href="#NetworkLearning.MatrixAdjacency"><code>NetworkLearning.MatrixAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by an <code>AbstractMatrix</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.NetworkLearnerEnt" href="#NetworkLearning.NetworkLearnerEnt"><code>NetworkLearning.NetworkLearnerEnt</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Entity-based network learning model type.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.NetworkLearnerObs" href="#NetworkLearning.NetworkLearnerObs"><code>NetworkLearning.NetworkLearnerObs</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Observation-based network learning model type.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.NetworkLearnerState" href="#NetworkLearning.NetworkLearnerState"><code>NetworkLearning.NetworkLearnerState</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Entity-based network learning model state. It consists of an <code>Array</code> with estimates and a an update mask in the form of a <code>BitVector</code> indicating which observation estimates are to be updated (the ones that are not updated are considered training/stable observations).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.NetworkLearning" href="#NetworkLearning.NetworkLearning"><code>NetworkLearning.NetworkLearning</code></a> — <span class="docstring-category">Module</span>.</div><div><div><p>NetworkLearning implements a generic framework for network classification. It could in theory be used for other functionality such as regression and density estimation, provided that appropriate methods for relational learning (i.e. relational variable generation) and collective inference are added. The framework is designed to make as little assumptions as possible on the elements involved in the process.  </p><p><strong>References</strong></p><p>[1] S.A. Macskassy, F. Provost &quot;Classification in networked data: A toolkit and a univariate case study&quot;, Journal of Machine learning Research 8, 2007, 935-983</p><p>[2] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Gallagher, T. Eliassi-Rad &quot;Collective classification in network data&quot;, AI Magazine 29(3), 2008</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.PartialAdjacency" href="#NetworkLearning.PartialAdjacency"><code>NetworkLearning.PartialAdjacency</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adjacency type where the adjacency information is represented by a function <code>f</code> which can be used to calculate an adjacency matrix or graph,  given proper data.&quot;</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.RelaxationLabelingInferer" href="#NetworkLearning.RelaxationLabelingInferer"><code>NetworkLearning.RelaxationLabelingInferer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Relaxation labeling object. Stores the parameters necessary for the algorithm.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.SimpleRN" href="#NetworkLearning.SimpleRN"><code>NetworkLearning.SimpleRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Simple relational neighbour learner. Counts for  each vertex how many neighbours from each class are in its neighbourhood.</p></div></div></section><pre><code class="language-none">NetworkLearning.SimpleRNColumnMajor</code></pre><pre><code class="language-none">NetworkLearning.SimpleRNRowMajor</code></pre><pre><code class="language-none">NetworkLearning.VERBOSE</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.WeightedRN" href="#NetworkLearning.WeightedRN"><code>NetworkLearning.WeightedRN</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Weighted relational neighbour learner. For each vertex, it sums up the estimates from neighboring vertices. </p></div></div></section><pre><code class="language-none">NetworkLearning.WeightedRNColumnMajor</code></pre><pre><code class="language-none">NetworkLearning.WeightedRNRowMajor</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.add_adjacency!" href="#NetworkLearning.add_adjacency!"><code>NetworkLearning.add_adjacency!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">add_adjacency!(model, Av)</code></pre><p>Function that adds or, creates and then adds, adjacency objects contained in a vector <code>Av</code> to a network  learning <code>model</code>. The method is used in &#39;ouf-of-graph&#39; learning i.e. the training data is not used in  the predictions for new samples. In such circumstances, the adjacency structures - graphs, matrices etc.  pertinent to the new observations have to be created either using the same functions used in training or,  separately supplied, so that relational variables can be created.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency" href="#NetworkLearning.adjacency"><code>NetworkLearning.adjacency</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjacency([a,data])</code></pre><p>Constructs an adjacency object. If <code>a</code> is a <code>AbstractMatrix</code>, <code>AbstractGraph</code> or  <code>Tuple</code>, it will return usable adjacencies. If <code>a</code> is a <code>Function</code> or <code>PartialAdjacency</code>, <code>data</code> has to be present. If both arguments are missing,  the function returns an <code>EmptyAdjacency</code>.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; using NetworkLearning, LightGraphs

julia&gt; A = [0 1 0; 1 0 0; 0 0 0];

julia&gt; Am = adjacency(A)
Matrix adjacency, 3 obs

julia&gt; Ag = adjacency(Graph(A))
Graph adjacency, 3 obs

julia&gt; Ac = adjacency(x-&gt;x,A)
Computable adjacency</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency_graph" href="#NetworkLearning.adjacency_graph"><code>NetworkLearning.adjacency_graph</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjacency_graph(a)</code></pre><p>Returns an adjacency graph computed from the adjacency information of <code>a</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency_matrix" href="#NetworkLearning.adjacency_matrix"><code>NetworkLearning.adjacency_matrix</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjacency_matrix(a)</code></pre><p>Returns an adjacency matrix computed from the adjacency information of <code>a</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.adjacency_obs" href="#NetworkLearning.adjacency_obs"><code>NetworkLearning.adjacency_obs</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">adjacency_obs(A, r, obsdim)</code></pre><p>Selects a range <code>r::UnitRange</code> of observations from the matrix <code>A</code>, along the dimension <code>obsdim::LearnBase.ObsDimension</code>.</p></div></div></section><pre><code class="language-none">NetworkLearning.encode_targets</code></pre><pre><code class="language-none">NetworkLearning.eval</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.fit" href="#NetworkLearning.fit"><code>NetworkLearning.fit</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">fit(::Type{NetworkLearnerObs}, X, y, Adj, fl_train, fl_exec, fr_train, fr_exec [;kwargs])</code></pre><p>Training method for the observation-based network learning framework.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix</code> training data (used by <code>fl_train</code>, <code>fl_exec</code>; if <code>use_local_data==true</code>, it is also used by <code>fr_train</code>)</li><li><code>Y::AbstractAray</code> data targets (used by <code>fl_train</code>, <code>fr_train</code>)</li><li><code>Adj::Vector{AbstractAdjacency}</code> a vector containing the observation relational structures (adjacency objects)</li><li><code>fl_train</code> local model training &#39;function&#39;; can be anything that supports the call <code>fl_train((X,y))</code></li><li><code>fl_exec</code> local model prediction &#39;function&#39;; can be anything that supports the call <code>fl_exec(Ml,X)</code> where <code>Ml = fl_train((X,y))</code></li><li><code>fr_train</code> relational model training <code>function</code>; can be anything that suports the call <code>fr_train((Xr,y))</code> </li><li><code>fr_exec</code> relational model prediction <code>function</code>; can be anything that suports the call <code>fr_exec(Mr,Xr)</code> where <code>Mr = fr_train((Xr,y))</code></li></ul><p>and <code>Xr</code> is a dataset of relational variables generated by the relational learner using the results of the local model prediction   function and adjacency structures.</p><p><strong>Keyword arguments</strong></p><ul><li><code>priors::Vector{Float64}</code> class priors (if applicable)</li><li><code>learner::Symbol</code> relational learner (i.e. variable generator); available options <code>:rn</code>, <code>:wrn</code>, <code>:bayesrn</code> and <code>:cdrn</code> (default <code>:wrn</code>)</li><li><code>inference::Symbol</code> collective inference method; available options <code>:rl</code>, <code>:ic</code> and <code>:gs</code> (default <code>:rl</code>)</li><li><code>normalize::Bool</code> whether to normalize the relational variables per-observation to the L1 norm (default <code>true</code>)</li><li><code>use_local_data::Bool</code> whether the relational model should use the local data provided (i.e. in <code>X</code>) (default <code>true</code>)</li><li><code>f_targets::Function</code> function that extracts targets from estimates generated by the local/relational models </li></ul><p>(default <code>f_targets = x-&gt;MLDataPattern.targets(indmax,x)</code>)</p><ul><li><code>obsdim::Int</code> observation dimension (default <code>2</code>)</li><li><code>tol::Float64</code> maximum admissible mean estimate error for collective inference convergence (default <code>1e-6</code>)</li><li><code>κ::Float64</code> relaxation labeling starting constant, used if <code>learner == :rl</code> (default <code>1.0</code>)</li><li><code>α::Float64</code> relaxation labeling decay constant, used if <code>learner == :rl</code> (default <code>0.99</code>)</li><li><code>maxiter::Int</code> maximum number of iterations for collective inference (default <code>100</code>)</li><li><code>bratio::Float64</code> percentage of iterations i.e. <code>maxiter</code> used for Gibbs sampling burn-in (default <code>0.1</code>)</li></ul></div></div><div><div><p>Training method for the network learning framework. This method should not be called directly.</p></div></div><div><div><pre><code class="language-none">fit(::Type{NetworkLearnerEnt}, X, update, Adj, fl_train, fl_exec, fr_train, fr_exec [;kwargs])</code></pre><p>Training method for the entity-based network learning framework.</p><p><strong>Arguments</strong></p><ul><li><code>Xo::AbstractMatrix</code> initial estimates for the entities</li><li><code>update::BitVector</code> mask that indicates wether estimates can be updated (<code>true</code> value) or not (<code>false</code> value); false values </li></ul><p>generally can be associated with estimates of training samples</p><ul><li><code>Adj::Vector{AbstractAdjacency}</code> a vector containing the entity relational structures (adjacency objects)</li><li><code>fr_train</code> relational model training <code>function</code>; can be anything that suports the call <code>fr_train((Xr,y))</code> where <code>y = f_targets(Xo)</code> </li><li><code>fr_exec</code> relational model prediction <code>function</code>; can be anything that suports the call <code>fr_exec(Mr,Xr)</code> where <code>Mr = fr_train((Xr,y))</code></li></ul><p>and <code>Xr</code> is a dataset of relational variables generated by the relational learner using the estimates <code>Xo</code> and the  adjacency structures.</p><p><strong>Keyword arguments</strong></p><ul><li><code>priors::Vector{Float64}</code> class priors (if applicable)</li><li><code>learner::Symbol</code> relational learner (i.e. variable generator); available options <code>:rn</code>, <code>:wrn</code>, <code>:bayesrn</code> and <code>:cdrn</code> (default <code>:wrn</code>)</li><li><code>inference::Symbol</code> collective inference method; available options <code>:rl</code>, <code>:ic</code> and <code>:gs</code> (default <code>:rl</code>)</li><li><code>normalize::Bool</code> whether to normalize the relational variables per-entity to the L1 norm (default <code>true</code>)</li><li><code>f_targets::Function</code> function that extracts targets from estimates generated by the local/relational models </li></ul><p>(default <code>f_targets = x-&gt;MLDataPattern.targets(indmax,x)</code>)</p><ul><li><code>obsdim::Int</code> observation dimension (default <code>2</code>)</li><li><code>tol::Float64</code> maximum admissible mean estimate error for collective inference convergence (default <code>1e-6</code>)</li><li><code>κ::Float64</code> relaxation labeling starting constant, used if <code>learner == :rl</code> (default <code>1.0</code>)</li><li><code>α::Float64</code> relaxation labeling decay constant, used if <code>learner == :rl</code> (default <code>0.99</code>)</li><li><code>maxiter::Int</code> maximum number of iterations for collective inference (default <code>100</code>)</li><li><code>bratio::Float64</code> percentage of iterations i.e. <code>maxiter</code> used for Gibbs sampling burn-in (default <code>0.1</code>)</li></ul></div></div><div><div><p>Training method for the network learning framework. This method should not be called directly.</p></div></div></section><pre><code class="language-none">NetworkLearning.generate_partial_adjacency</code></pre><pre><code class="language-none">NetworkLearning.get_size_out</code></pre><pre><code class="language-none">NetworkLearning.getpriors</code></pre><pre><code class="language-none">NetworkLearning.grab_cora_data</code></pre><pre><code class="language-none">NetworkLearning.include</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.infer!" href="#NetworkLearning.infer!"><code>NetworkLearning.infer!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Function that calls collective inference using the information in contained in the entity-based network learner</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.intdim" href="#NetworkLearning.intdim"><code>NetworkLearning.intdim</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">intdim(::LearnBase.ObsDimension)</code></pre><p>Returns the integer associated to a dimension object  i.e. <code>intdim(ObsDim.Constant{3})</code>  returns <code>3</code>.  The function is designed to work on matices so  <code>intdim(::ObsDim.Last)</code> will return <code>2</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.matrix_prealloc" href="#NetworkLearning.matrix_prealloc"><code>NetworkLearning.matrix_prealloc</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">matrix_prealloc(no, nv, obsdim, val)</code></pre><p>Returns a <code>Matrix{T}</code> filled with values equal to <code>val::T</code>, having the size <code>no</code> (number of observations) on dimension <code>obsdim</code> and  <code>nv</code> (number of variables) in the other dimension.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.nvars" href="#NetworkLearning.nvars"><code>NetworkLearning.nvars</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Returns the number of variables given a data object which  supports the <code>nobs</code> function. The data object must ideally  present two dimensions i.e. matrix.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.oppdim" href="#NetworkLearning.oppdim"><code>NetworkLearning.oppdim</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">oppdim(::LearnBase.ObsDimension)</code></pre><p>Returns the other dimension for a matrix i.e. if provided <code>ObsDim.Constant{1}</code>  returns <code>ObsDim.Constant{2}</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.predict" href="#NetworkLearning.predict"><code>NetworkLearning.predict</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Prediction method for the network learning framework.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.predict!" href="#NetworkLearning.predict!"><code>NetworkLearning.predict!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>In-place prediction method for the network learning framework.</p></div></div></section><pre><code class="language-none">NetworkLearning.read_citation_data</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.strip_adjacency" href="#NetworkLearning.strip_adjacency"><code>NetworkLearning.strip_adjacency</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">strip_adjacency(a)</code></pre><p>Function that removes adjancency information (i.e. matrix, graph or other data) from adjacency objects and returns a <code>PartialAdjacency</code> that can be used in conjunction with the <code>adjacency</code> function to build a new adjacency object.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; using NetworkLearning, LightGraphs

julia&gt; A = [0 1 0; 1 0 0; 0 0 0];

julia&gt; Am = adjacency(A)
Matrix adjacency, 3 obs

julia&gt; Ac = adjacency(x-&gt;x,A)
Computable adjacency

julia&gt; Sm = strip_adjacency(Am)
Partial adjacency, not computable

julia&gt; adjacency(Sm, A) # Sm has to be used with a matrix
Matrix adjacency, 3 obs

julia&gt; Sc = strip_adjacency(Ac)
Partial adjacency, not computable

julia&gt; adjacency(Sc, A) # Sc can be use with any data; calls f(A) where f = x-&gt;x
Matrix adjacency, 3 obs</code></pre></div></div></section><pre><code class="language-none">NetworkLearning.transform</code></pre><pre><code class="language-none">NetworkLearning.transform!</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NetworkLearning.update_adjacency!" href="#NetworkLearning.update_adjacency!"><code>NetworkLearning.update_adjacency!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">update_adjacency!(a,f_update)</code></pre><p>Function that updates the data of an adjacency object. <code>a</code> has to be a <code>MatrixAdjacency</code> or  <code>GraphAdjacency</code> while <code>f_update</code> has to of the form <code>f_update = x-&gt;update_function!(x)</code>.</p><p><strong>Examples</strong></p><p>julia&gt; using NetworkLearning, LightGraphs</p><p>julia&gt; A = [0 1 0; 1 0 0; 0 0 0];</p><p>julia&gt; Am = adjacency(A) Matrix adjacency, 3 obs</p><p>julia&gt; update<em>function!(X,x,y) = begin          X[x,y] += 1          X[y,x] += 1          return X        end update</em>function! (generic function with 2 methods)</p><p>julia&gt; f<em>update(x,y) = X-&gt;update</em>function!(X,x,y) f_update (generic function with 1 method)</p><p>julia&gt; for i in 1:3          update<em>adjacency!(Am, f</em>update(1,3)) # call function three times        end</p><p>julia&gt; adjacency_matrix(Am) 3×3 Array{Int64,2}:  0  1  3  1  0  0  3  0  0</p></div></div></section><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>
