<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Model Transformations · POMDPModelTools.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>POMDPModelTools.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../convenience/">Convenience</a></li><li><a class="toctext" href="../distributions/">Distributions</a></li><li><a class="toctext" href="../">About</a></li><li><a class="toctext" href="../interface_extensions/">Interface Extensions</a></li><li class="current"><a class="toctext" href>Model Transformations</a><ul class="internal"><li><a class="toctext" href="#Fully-Observable-POMDP-1">Fully Observable POMDP</a></li><li><a class="toctext" href="#Generative-Belief-MDP-1">Generative Belief MDP</a></li><li><a class="toctext" href="#Underlying-MDP-1">Underlying MDP</a></li></ul></li><li><a class="toctext" href="../utility_types/">Utility Types</a></li><li><a class="toctext" href="../visualization/">Visualization</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Model Transformations</a></li></ul></nav><hr/><div id="topbar"><span>Model Transformations</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Model-Transformations-1" href="#Model-Transformations-1">Model Transformations</a></h1><p>POMDPModelTools contains several tools for transforming problems into other classes so that they can be used by different solvers.</p><h2><a class="nav-anchor" id="Fully-Observable-POMDP-1" href="#Fully-Observable-POMDP-1">Fully Observable POMDP</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="POMDPModelTools.FullyObservablePOMDP" href="#POMDPModelTools.FullyObservablePOMDP"><code>POMDPModelTools.FullyObservablePOMDP</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">FullyObservablePOMDP(mdp)</code></pre><p>Turn <code>MDP</code> <code>mdp</code> into a <code>POMDP</code> where the observations are the states of the MDP.</p></div></div></section><h2><a class="nav-anchor" id="Generative-Belief-MDP-1" href="#Generative-Belief-MDP-1">Generative Belief MDP</a></h2><p>Every POMDP is an MDP on the belief space <code>GenerativeBeliefMDP</code> creates a generative model for that MDP.</p><p>&lt;aside class=&quot;warning&quot;&gt; WARNING: The reward generated by the <code>GenerativeBeliefMDP</code> is the reward for a <em>single state sampled from the belief</em>; it is not the expected reward for that belief transition (though, in expectation, they are equivalent of course). Implementing the model with the expected reward requires a custom implementation because belief updaters do not typically deal with reward. &lt;/aside&gt;</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="POMDPModelTools.GenerativeBeliefMDP" href="#POMDPModelTools.GenerativeBeliefMDP"><code>POMDPModelTools.GenerativeBeliefMDP</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">GenerativeBeliefMDP(pomdp, updater)</code></pre><p>Create a generative model of the belief MDP corresponding to POMDP <code>pomdp</code> with belief updates performed by <code>updater</code>.</p></div></div></section><h3><a class="nav-anchor" id="Example-1" href="#Example-1">Example</a></h3><pre><code class="language-julia">using POMDPModels
using POMDPModelTools
using BeliefUpdaters

pomdp = BabyPOMDP()
updater = DiscreteUpdater(pomdp)

belief_mdp = GenerativeBeliefMDP(pomdp, updater)
@show statetype(belief_mdp) # POMDPModels.BoolDistribution

for (a, r, sp) in stepthrough(belief_mdp, RandomPolicy(belief_mdp), &quot;a,r,sp&quot;, max_steps=5)
    @show a, r, sp
end</code></pre><h2><a class="nav-anchor" id="Underlying-MDP-1" href="#Underlying-MDP-1">Underlying MDP</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="POMDPModelTools.UnderlyingMDP" href="#POMDPModelTools.UnderlyingMDP"><code>POMDPModelTools.UnderlyingMDP</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">UnderlyingMDP(pomdp)</code></pre><p>Transform <code>POMDP</code> <code>pomdp</code> into an <code>MDP</code> where the states are fully observed.</p></div></div></section><footer><hr/><a class="previous" href="../interface_extensions/"><span class="direction">Previous</span><span class="title">Interface Extensions</span></a><a class="next" href="../utility_types/"><span class="direction">Next</span><span class="title">Utility Types</span></a></footer></article></body></html>
