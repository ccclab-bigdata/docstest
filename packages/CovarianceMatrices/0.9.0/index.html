<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · CovarianceMatrices.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>CovarianceMatrices.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#Introduction-1">Introduction</a></li><li class="toplevel"><a class="toctext" href="#Quick-tour-1">Quick tour</a></li><li><a class="toctext" href="#HAC-(Heteroskedasticity-and-Autocorrelation-Consistent)-1">HAC (Heteroskedasticity and Autocorrelation Consistent)</a></li><li><a class="toctext" href="#HC-(Heteroskedastic-consistent)-1">HC (Heteroskedastic consistent)</a></li><li><a class="toctext" href="#CRHC-(Cluster-robust-heteroskedasticty-consistent)-1">CRHC (Cluster robust heteroskedasticty consistent)</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="CovarianceMatrices.jl-1" href="#CovarianceMatrices.jl-1">CovarianceMatrices.jl</a></h1><p><a href="https://travis-ci.org/gragusa/CovarianceMatrices.jl"><img src="https://travis-ci.org/gragusa/CovarianceMatrices.jl.svg?branch=master" alt="Build Status"/></a> <a href="http://pkg.julialang.org/detail/CovarianceMatrices&amp;ver=0.6"><img src="http://pkg.julialang.org/badges/CovarianceMatrices_0.6.svg" alt="CovarianceMatrices"/></a> <a href="https://coveralls.io/github/gragusa/CovarianceMatrices.jl?branch=master"><img src="https://coveralls.io/repos/gragusa/CovarianceMatrices.jl/badge.svg?branch=master&amp;service=github" alt="Coverage Status"/></a> <a href="http://codecov.io/github/gragusa/CovarianceMatrices.jl?branch=master"><img src="http://codecov.io/github/gragusa/CovarianceMatrices.jl/coverage.svg?branch=master" alt="codecov.io"/></a></p><p>Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation for Julia.</p><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><p>The package is registered on <a href="http::/github.com/JuliaLang/METADATA.jl">METADATA</a>, so to install</p><pre><code class="language-julia">Pkg.add(&quot;CovarianceMatrices&quot;)</code></pre><hr/><h2><a class="nav-anchor" id="Introduction-1" href="#Introduction-1">Introduction</a></h2><p>This package provides types and methods useful to obtain consistent estimates of the long run covariance matrix of a random process.</p><p>Three classes of estimators are considered:</p><ol><li><strong>HAC</strong> - heteroskedasticity and autocorrelation consistent (Andrews, 1996; Newey and West, 1994)</li><li><strong>HC</strong>  - hetheroskedasticity (White, 1982)</li><li><strong>CRVE</strong> - cluster robust (Arellano, 1986)</li></ol><p>The typical application of these estimators is to conduct robust inference about parameters of a model. This is accomplished by extending methods defined in <a href="http://github.com/JuliaStat/StatsBase.jl">StatsBase.jl</a> and <a href="http://github.com/JuliaStat/GLM.jl">GLM.jl</a>.</p><h1><a class="nav-anchor" id="Quick-tour-1" href="#Quick-tour-1">Quick tour</a></h1><h2><a class="nav-anchor" id="HAC-(Heteroskedasticity-and-Autocorrelation-Consistent)-1" href="#HAC-(Heteroskedasticity-and-Autocorrelation-Consistent)-1">HAC (Heteroskedasticity and Autocorrelation Consistent)</a></h2><p>Available kernel types are:</p><ul><li><code>TruncatedKernel</code></li><li><code>BartlettKernel</code></li><li><code>ParzenKernel</code></li><li><code>TukeyHanningKernel</code></li><li><code>QuadraticSpectralKernel</code></li></ul><p>For example, <code>ParzenKernel(NeweyWest)</code> return an instance of <code>TruncatedKernel</code> parametrized by <code>NeweyWest</code>, the type that corresponds to the optimal bandwidth calculated following Newey and West (1994).  Similarly, <code>ParzenKernel(Andrews)</code> corresponds to the optimal bandwidth obtained in Andrews (1991). If the bandwidth is known, it can be directly passed, i.e. <code>TruncatedKernel(2)</code>.</p><p>The examples below clarify the API, that is however relatively easy to use.</p><h3><a class="nav-anchor" id="Long-run-variance-of-the-regression-coefficient-1" href="#Long-run-variance-of-the-regression-coefficient-1">Long run variance of the regression coefficient</a></h3><p>In the regression context, the function <code>vcov</code> does all the work:</p><pre><code class="language-julia">vcov(::DataFrameRegressionModel, ::HAC; prewhite = true)</code></pre><p>Consider the following artificial data (a regression with autoregressive error component):</p><pre><code class="language-julia">using CovarianceMatrices
using DataFrames
Random.seed!(1)
n = 500
x = randn(n,5)
u = Array{Float64}(2*n)
u[1] = rand()
for j in 2:2*n
    u[j] = 0.78*u[j-1] + randn()
end
u = u[n+1:2*n]    
y = 0.1 + x*[0.2, 0.3, 0.0, 0.0, 0.5] + u            

df = DataFrame()
df[:y] = y
for j in enumerate([:x1, :x2, :x3, :x4, :x5])
    df[j[2]] = x[:,j[1]]
end</code></pre><p>Using the data in <code>df</code>, the coefficient of the regression can be estimated using <code>GLM</code></p><pre><code class="language-julia">lm1 = glm(y~x1+x2+x3+x4+x5, df, Normal(), IdentityLink())</code></pre><p>To get a consistent estimate of the long run variance of the estimated coefficients using a Quadratic Spectral kernel with automatic bandwidth selection  <em>à la</em> Andrews</p><pre><code class="language-julia">vcov(lm1, QuadraticSpectralKernel(Andrews), prewhite = false)</code></pre><p>If one wants to estimate the long-time variance using the same kernel, but with a bandwidth selected <em>à la</em> Newey-West</p><pre><code class="language-julia">vcov(lm1, QuadraticSpectralKernel(NeweyWest), prewhite = false)</code></pre><p>The standard errors can be obtained by the <code>stderror</code> method</p><pre><code class="language-julia">stderror(::DataFrameRegressionModel, ::HAC; prewhite::Bool)</code></pre><p>Sometime is useful to access the bandwidth selected by the automatic procedures. This can be done using the <code>optimalbw</code> method</p><pre><code class="language-julia">optimalbw(NeweyWest, QuadraticSpectralKernel, lm1; prewhite = false)
optimalbw(Andrews, QuadraticSpectralKernel, lm1; prewhite = false)</code></pre><h3><a class="nav-anchor" id="Long-run-variance-of-the-average-of-the-process-1" href="#Long-run-variance-of-the-average-of-the-process-1">Long run variance of the average of the process</a></h3><p>Sometime interest lies in estimating the long-run variance of the average of the process. At the moment this can be done by carrying out a regression on a constant (the sample mean of the realization of the process) and using <code>vcov</code> or <code>stderror</code> to obtain a consistent variance estimate (or its diagonal elements).</p><pre><code class="language-julia">lm2 = glm(u~1, df, Normal(), IdentityLink())
vcov(lm1, ParzenKernel(NeweyWest), prewhite = false)
stderr(lm1, ParzenKernel(NeweyWest), prewhite = false)</code></pre><h2><a class="nav-anchor" id="HC-(Heteroskedastic-consistent)-1" href="#HC-(Heteroskedastic-consistent)-1">HC (Heteroskedastic consistent)</a></h2><p>As in the HAC case, <code>vcov</code> and <code>stderr</code> are the main functions. They know get as argument the type of robust variance being sought</p><pre><code class="language-julia">vcov(::DataFrameRegressionModel, ::HC)</code></pre><p>Where HC is an abstract type with the following concrete types:</p><ul><li><code>HC0</code></li><li><code>HC1</code> (this is <code>HC0</code> with the degree of freedom adjustment)</li><li><code>HC2</code></li><li><code>HC3</code></li><li><code>HC4</code></li><li><code>HC4m</code></li><li><code>HC5</code></li></ul><pre><code class="language-none">using CovarianceMatrices
using DataFrames
using GLM

# A Gamma example, from McCullagh &amp; Nelder (1989, pp. 300-2)
# The weights are added just to test the interface and are not part
# of the original data
clotting = DataFrame(
    u    = log([5,10,15,20,30,40,60,80,100]),
    lot1 = [118,58,42,35,27,25,21,19,18],
    lot2 = [69,35,26,21,18,16,13,12,12],
    w    = 9*[1/8, 1/9, 1/25, 1/6, 1/14, 1/25, 1/15, 1/13, 0.3022039]
)
wOLS = fit(GeneralizedLinearModel, lot1~u, clotting, Normal(), wts = array(clotting[:w]))

vcov(wOLS, HC0
vcov(wOLS, HC1)
vcov(wOLS, HC2)
vcov(wOLS, HC3)
vcov(wOLS, HC4)
vcov(wOLS, HC4m)
vcov(wOLS, HC5)</code></pre><h2><a class="nav-anchor" id="CRHC-(Cluster-robust-heteroskedasticty-consistent)-1" href="#CRHC-(Cluster-robust-heteroskedasticty-consistent)-1">CRHC (Cluster robust heteroskedasticty consistent)</a></h2><p>The API of this class of variance estimators is subject to change, so please use with care. The difficulty is that <code>CRHC</code> type needs to have access to the variable along which dimension the clustering mast take place. For the moment, the following approach works –- as long as no missing values are present in the original dataframe.</p><pre><code class="language-julia">using RDatasets
df = dataset(&quot;plm&quot;, &quot;Grunfeld&quot;)
lm = glm(Inv~Value+Capital, df, Normal(), IdentityLink())
vcov(lm, CRHC1(convert(Array, df[:Firm])))
stderr(lm, CRHC1(convert(Array, df[:Firm])))</code></pre><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
