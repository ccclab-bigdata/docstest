<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · DataStreams.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DataStreams.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"><li><a class="toctext" href="#Data.Source-Interface-1"><code>Data.Source</code> Interface</a></li><li><a class="toctext" href="#Data.Sink-Interface-1"><code>Data.Sink</code> Interface</a></li><li><a class="toctext" href="#Data.stream!-1"><code>Data.stream!</code></a></li><li><a class="toctext" href="#Data.Schema-1"><code>Data.Schema</code></a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="DataStreams.jl-1" href="#DataStreams.jl-1">DataStreams.jl</a></h1><p>The <code>DataStreams.jl</code> package aims to define a generic and performant framework for the transfer of &quot;table-like&quot; data. (i.e. data that can, at least in some sense, be described by rows and columns).</p><p>The framework achieves this by defining interfaces (i.e. a group of methods) for <code>Data.Source</code> types and methods to describe how they &quot;provide&quot; data; as well as <code>Data.Sink</code> types and methods around how they &quot;receive&quot; data. This allows <code>Data.Source</code>s and <code>Data.Sink</code>s to implement their interfaces separately, without needing to be aware of each other. The end result is an ecosystem of packages that &quot;automatically&quot; talk with each other, with adding an additional package not requiring changes to existing packages.</p><p>Packages can have a single julia type implement both the <code>Data.Source</code> and <code>Data.Sink</code> interfaces, or two separate types can implement them separately. </p><h2><a class="nav-anchor" id="Data.Source-Interface-1" href="#Data.Source-Interface-1"><code>Data.Source</code> Interface</a></h2><p>The <code>Data.Source</code> interface includes the following definitions:</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.schema" href="#DataStreams.Data.schema"><code>DataStreams.Data.schema</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.schema(s::Source) =&gt; Data.Schema</code></p><p>Return the <code>Data.Schema</code> of a source, which describes the # of rows &amp; columns, as well as the column types of a dataset. Some sources like <code>CSV.Source</code> or <code>SQLite.Source</code> store the <code>Data.Schema</code> directly in the type, whereas others like <code>DataFrame</code> compute the schema on the fly.</p><p>The <code>Data.Schema</code> of a source is used in various ways during the streaming process:</p><ul><li>The # of rows and if they are known are used to generate the inner streaming loop</li><li>The # of columns determine if the innermost streaming loop can be unrolled automatically or not</li><li>The types of the columns are used in loop unrolling to generate efficient and type-stable streaming</li></ul><p>See <code>?Data.Schema</code> for more details on how to work with the type.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.isdone" href="#DataStreams.Data.isdone"><code>DataStreams.Data.isdone</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.isdone(source, row, col) =&gt; Bool</code></p><p>Checks whether a source can stream additional fields/columns for a desired <code>row</code> and <code>col</code> intersection. Used during the streaming process, especially for sources that have an unknown # of rows, to detect when a source has been exhausted of data.</p><p>Data.Source types must at least implement:</p><p><code>Data.isdone(source::S, row::Int, col::Int)</code></p><p>If more convenient/performant, they can also implement:</p><p><code>Data.isdone(source::S, row::Int, col::Int, rows::Union{Int, Missing}, cols::Int)</code></p><p>where <code>rows</code> and <code>cols</code> are the size of the <code>source</code>&#39;s schema when streaming.</p><p>A simple example of how a DataFrame implements this is:</p><pre><code class="language-julia">Data.isdone(df::DataFrame, row, col, rows, cols) = row &gt; rows || col &gt; cols</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.streamtype" href="#DataStreams.Data.streamtype"><code>DataStreams.Data.streamtype</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.streamtype{T&lt;:Data.Source, S&lt;:Data.StreamType}(::Type{T}, ::Type{S}) =&gt; Bool</code></p><p>Indicates whether the source <code>T</code> supports streaming of type <code>S</code>. To be overloaded by individual sources according to supported <code>Data.StreamType</code>s. This is used in the streaming process to determine the compatability of streaming from a specific source to a specific sink. It also helps in determining the preferred streaming method, when matched up with the results of <code>Data.streamtypes(s::Sink)</code>.</p><p>For example, if <code>MyPkg.Source</code> supported <code>Data.Field</code> streaming, I would define:</p><pre><code class="language-julia">Data.streamtype(::Type{MyPkg.Source}, ::Type{Data.Field}) = true</code></pre><p>and/or for <code>Data.Column</code> streaming:</p><pre><code class="language-julia">Data.streamtype(::Type{MyPkg.Source}, ::Type{Data.Column}) = true</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.reset!" href="#DataStreams.Data.reset!"><code>DataStreams.Data.reset!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.reset!(source)</code></p><p>Resets a source into a state that allows streaming its data again. For example, for <code>CSV.Source</code>, the internal buffer is &quot;seek&quot;ed back to the start position of the csv data (after the column name headers). For <code>SQLite.Source</code>, the source SQL query is re-executed.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.streamfrom" href="#DataStreams.Data.streamfrom"><code>DataStreams.Data.streamfrom</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Data.Source types must implement one of the following:</p><p><code>Data.streamfrom(source, ::Type{Data.Field}, ::Type{T}, row::Int, col::Int) where {T}</code></p><p><code>Data.streamfrom(source, ::Type{Data.Column}, ::Type{T}, col::Int) where {T}</code></p><p>Performs the actually streaming of data &quot;out&quot; of a data source. For <code>Data.Field</code> streaming, the single field value of type <code>T</code> at the intersection of <code>row</code> and <code>col</code> is returned. For <code>Data.Column</code> streaming, the column # <code>col</code> with element type <code>T</code> is returned.</p><p>For <code>Data.Column</code>, a source can also implement:</p><pre><code class="language-julia">Data.streamfrom(source, ::Type{Data.Field}, ::Type{T}, row::Int, col::Int) where {T}</code></pre><p>where <code>row</code> indicates the # of rows that have already been streamed from the source.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.accesspattern" href="#DataStreams.Data.accesspattern"><code>DataStreams.Data.accesspattern</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.accesspattern(source) =&gt; Data.RandomAccess | Data.Sequential</code></p><p>returns the data access pattern for a Data.Source.</p><p><code>RandomAccess</code> indicates that a source supports streaming data (via calls to <code>Data.streamfrom</code>) with arbitrary row/column values in any particular order.</p><p><code>Sequential</code> indicates that the source only supports streaming data sequentially, starting w/ row 1, then accessing each column from 1:N, then row 2, and each column from 1:N again, etc.</p><p>For example, a <code>DataFrame</code> holds all data in-memory, and thus supports easy random access in any order. A <code>CSV.Source</code> however, is streaming the contents of a file, where rows must be read sequentially, and each column sequentially within each rows.</p><p>By default, sources are assumed to have a <code>Sequential</code> access pattern.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.reference" href="#DataStreams.Data.reference"><code>DataStreams.Data.reference</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Data.Source types can optionally implement</p><p><code>Data.reference(x::Source) =&gt; Vector{UInt8}</code></p><p>where the type retruns a <code>Vector{UInt8}</code> that represents a memory block that should be kept in reference for WeakRefStringArrays.</p><p>In many streaming situations, the minimizing of data copying/movement is ideal. Some sources can provide in-memory access to their data in the form of a <code>Vector{UInt8}</code>, i.e. a single byte vector, that sinks can &quot;point to&quot; when streaming, instead of needing to always copy all the data. In particular, the <code>WeakRefStrings</code> package provides utilities for creating &quot;string types&quot; that don&#39;t actually hold their own data, but instead just &quot;point&quot; to data that lives elsewhere. As Strings can be some of the most expensive data structures to copy and move around, this provides excellent performance gains in some cases when the sink is able to leverage this alternative structure.</p></div></div></section><h2><a class="nav-anchor" id="Data.Sink-Interface-1" href="#Data.Sink-Interface-1"><code>Data.Sink</code> Interface</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.Sink" href="#DataStreams.Data.Sink"><code>DataStreams.Data.Sink</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Represents a type that can have data streamed to it from <code>Data.Source</code>s.</p><p>To satisfy the <code>Data.Sink</code> interface, it must provide two constructors with the following signatures:</p><pre><code class="language-none">[Sink](sch::Data.Schema, S::Type{StreamType}, append::Bool, args...; reference::Vector{UInt8}=UInt8[], kwargs...) =&gt; [Sink]
[Sink](sink, sch::Data.Schema, S::Type{StreamType}, append::Bool; reference::Vector{UInt8}=UInt8[]) =&gt; [Sink]</code></pre><p>Let&#39;s break these down, piece by piece:</p><ul><li><code>[Sink]</code>: this is your sink type, i.e. <code>CSV.Sink</code>, <code>DataFrame</code>, etc. You&#39;re defining a constructor for your sink type.</li><li><code>sch::Data.Schema</code>: in the streaming process, the schema of a <code>Data.Source</code> is provided to the sink in order to allow the sink to &quot;initialize&quot; properly in order to receive data according to the format in <code>sch</code>. This might mean pre-allocating space according to the # of rows/columns in the source, managing the sink&#39;s own schema to match <code>sch</code>, etc.</li><li><code>S::Type{StreamType}</code>: <code>S</code> represents the type of streaming that will occur from the <code>Data.Source</code>, either <code>Data.Field</code> or <code>Data.Column</code></li><li><code>append::Bool</code>: a boolean flag indicating whether the data should be appended to a sink&#39;s existing data store, or, if <code>false</code>, if the sink&#39;s data should be fully replaced by the incoming <code>Data.Source</code>&#39;s data</li><li><code>args...</code>: In the 1st constructor form, <code>args...</code> represents a catchall for any additional arguments your sink may need to construct. For example, <code>SQLite.jl</code> defines <code>Sink(sch, S, append, db, table_name)</code>, meaning that the <code>db</code> and <code>table_name</code> are additional required arguments in order to properly create an <code>SQLite.Sink</code>.</li><li><code>reference::Vector{UInt8}</code>: if your sink defined <code>Data.weakrefstrings(sink::MySink) = true</code>, then it also needs to be able to accept the <code>reference</code> keyword argument, where a source&#39;s memory block will be passed, to be held onto appropriately by the sink when streaming WeakRefStrings. If a sink does not support streaming WeakRefStrings (the default), the sink constructor doesn&#39;t need to support any keyword arguments.</li><li><code>kwargs...</code>: Similar to <code>args...</code>, <code>kwargs...</code> is a catchall for any additional keyword arguments you&#39;d like to expose for your sink constructor, typically matching supported keyword arguments that are provided through the normal sink constructor</li><li><code>sink</code>: in the 2nd form, an already-constructed sink is passed in as the 1st argument. This allows efficient sink re-use. This constructor needs to ensure the existing sink is modified (enlarged, shrunk, schema changes, etc) to be ready to accept the incoming source data as described by <code>sch</code>.</li></ul><p>Now let&#39;s look at an example implementation from CSV.jl:</p><pre><code class="language-julia">function CSV.Sink(fullpath::AbstractString; append::Bool=false, headers::Bool=true, colnames::Vector{String}=String[], kwargs...)
    io = IOBuffer()
    options = CSV.Options(kwargs...)
    !append &amp;&amp; header &amp;&amp; !isempty(colnames) &amp;&amp; writeheaders(io, colnames, options)
    return CSV.Sink(options, io, fullpath, position(io), !append &amp;&amp; header &amp;&amp; !isempty(colnames), colnames, length(colnames), append)
end

function CSV.Sink(sch::Data.Schema, T, append, file::AbstractString; reference::Vector{UInt8}=UInt8[], kwargs...)
    sink = CSV.Sink(file; append=append, colnames=Data.header(sch), kwargs...)
    return sink
end

function CSV.Sink(sink, sch::Data.Schema, T, append; reference::Vector{UInt8}=UInt8[])
    sink.append = append
    sink.cols = size(sch, 2)
    !sink.header &amp;&amp; !append &amp;&amp; writeheaders(sink.io, Data.header(sch), sink.options, sink.quotefields)
    return sink
end</code></pre><p>In this case, CSV.jl defined an initial constructor that just takes the filename with a few keyword arguments. The two required Data.Sink constructors are then defined. The first constructs a new Sink, requiring a <code>file::AbstractString</code> argument. We also see that <code>CSV.Sink</code> supports WeakRefString streaming by accepting a <code>reference</code> keyword argument (which is trivially implemented for CSV, since all data is simply written out to disk as text).</p><p>For the 2nd (last) constructor in the definitions above, we see the case where an existing <code>sink</code> is passed to <code>CSV.Sink</code>. The sink updates a few of its fields (<code>sink.append = append</code>), and some logic is computed to determine if the column headers should be written.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.streamtypes" href="#DataStreams.Data.streamtypes"><code>DataStreams.Data.streamtypes</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.streamtypes(::Type{[Sink]}) =&gt; Vector{StreamType}</code></p><p>Returns a vector of <code>Data.StreamType</code>s that the sink is able to receive; the order of elements indicates the sink&#39;s streaming preference</p><p>For example, if my sink only supports <code>Data.Field</code> streaming, I would simply define:</p><pre><code class="language-julia">Data.streamtypes(::Type{MyPkg.Sink}) = [Data.Field]</code></pre><p>If, on the other hand, my sink also supported <code>Data.Column</code> streaming, and <code>Data.Column</code> streaming happend to be more efficient, I could define:</p><pre><code class="language-julia">Data.streamtypes(::Type{MyPkg.Sink}) = [Data.Column, Data.Field] # put Data.Column first to indicate preference</code></pre><p>A third option is a sink that operates on entire rows at a time, in which case I could define:</p><pre><code class="language-julia">Data.streamtypes(::Type{MyPkg.Sink}) = [Data.Row]</code></pre><p>The subsequent <code>Data.streamto!</code> method would then require the signature <code>Data.streamto!(sink::MyPkg.Sink, ::Type{Data.Row}, vals::NamedTuple, row, col, knownrows</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.streamto!" href="#DataStreams.Data.streamto!"><code>DataStreams.Data.streamto!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.streamto!(sink, S::Type{StreamType}, val, row, col)</code></p><p><code>Data.streamto!(sink, S::Type{StreamType}, val, row, col, knownrows)</code></p><p>Streams data to a sink. <code>S</code> is the type of streaming (<code>Data.Field</code>, <code>Data.Row</code>, or <code>Data.Column</code>). <code>val</code> is the value or values (single field, row as a NamedTuple, or column, respectively) to be streamed to the sink. <code>row</code> and <code>col</code> indicate where the data should be streamed/stored.</p><p>A sink may optionally define the method that also accepts the <code>knownrows</code> argument, which will be <code>Val{true}</code> or <code>Val{false}</code>, indicating whether the source streaming has a known # of rows or not. This can be useful for sinks that may know how to pre-allocate space in the cases where the source can tell the # of rows, or in the case of unknown # of rows, may need to stream the data in differently.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.cleanup!" href="#DataStreams.Data.cleanup!"><code>DataStreams.Data.cleanup!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.cleanup!(sink)</code></p><p>Sometimes errors occur during the streaming of data from source to sink. Some sinks may be left in an undesired state if an error were to occur mid-streaming. <code>Data.cleanup!</code> allows a sink to &quot;clean up&quot; any necessary resources in the case of a streaming error. <code>SQLite.jl</code>, for example, defines:</p><pre><code class="language-julia">function Data.cleanup!(sink::SQLite.Sink)
    rollback(sink.db, sink.transaction)
    return
end</code></pre><p>Since a database transaction is initiated at the start of streaming, it must be rolled back in the case of streaming error.</p><p>The default definition is: <code>Data.cleanup!(sink) = nothing</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.close!" href="#DataStreams.Data.close!"><code>DataStreams.Data.close!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.close!(sink) =&gt; sink</code></p><p>A function to &quot;close&quot; a sink to streaming. Some sinks require a definitive time where data can be &quot;committed&quot;, <code>Data.close!</code> allows a sink to perform any necessary resource management or commits to ensure all data that has been streamed is stored appropriately. For example, the <code>SQLite</code> package defines:</p><pre><code class="language-julia">function Data.close!(sink::SQLite.Sink)
    commit(sink.db, sink.transaction)
    return sink
end</code></pre><p>Which commits a database transaction that was started when the sink was initially &quot;opened&quot;.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.weakrefstrings" href="#DataStreams.Data.weakrefstrings"><code>DataStreams.Data.weakrefstrings</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.weakrefstrings(sink) =&gt; Bool</code></p><p>If a sink is able to appropriately handle <code>WeakRefString</code> objects, it can define:</p><pre><code class="language-julia">Data.weakrefstrings(::Type{[Sink]}) = true</code></pre><p>to indicate that a source may stream those kinds of values to it. By default, sinks do not support WeakRefString streaming. Supporting WeakRefStrings corresponds to accepting the <code>reference</code> keyword argument in the required sink constructor method, see <code>?Data.Sink</code>.</p></div></div></section><h2><a class="nav-anchor" id="Data.stream!-1" href="#Data.stream!-1"><code>Data.stream!</code></a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.stream!" href="#DataStreams.Data.stream!"><code>DataStreams.Data.stream!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>Data.stream!(source, sink; append::Bool=false, transforms=Dict())</code></p><p><code>Data.stream!(source, ::Type{Sink}, args...; append::Bool=false, transforms=Dict(), kwargs...)</code></p><p>Stream data from source to sink. The 1st definition assumes already constructed source &amp; sink and takes two optional keyword arguments:</p><ul><li><code>append::Bool=false</code>: whether the data from <code>source</code> should be appended to <code>sink</code></li><li><code>transforms::Dict</code>: A dict with mappings between column # or name (Int or String) to a &quot;transform&quot; function. For <code>Data.Field</code> streaming, the transform function should be of the form <code>f(x::T) =&gt; y::S</code>, i.e. takes a single input of type <code>T</code> and returns a single value of type <code>S</code>. For <code>Data.Column</code> streaming, it should be of the form <code>f(x::AbstractVector{T}) =&gt; y::AbstractVector{S}</code>, i.e. take an AbstractVector with eltype <code>T</code> and return another AbstractVector with eltype <code>S</code>.</li></ul><p>For the 2nd definition, the Sink type itself is passed as the 2nd argument (<code>::Type{Sink}</code>) and is constructed &quot;on-the-fly&quot;, being passed <code>args...</code> and <code>kwargs...</code> like <code>Sink(args...; kwargs...)</code>.</p><p>While users are free to call <code>Data.stream!</code> themselves, oftentimes, packages want to provide even higher-level convenience functions.</p><p>An example of of these higher-level convenience functions are from CSV.jl:</p><pre><code class="language-julia">function CSV.read(fullpath::Union{AbstractString,IO}, sink::Type=DataFrame, args...; append::Bool=false, transforms::Dict=Dict{Int,Function}(), kwargs...)
    source = CSV.Source(fullpath; kwargs...)
    sink = Data.stream!(source, sink, args...; append=append, transforms=transforms, kwargs...)
    return Data.close!(sink)
end

function CSV.read(fullpath::Union{AbstractString,IO}, sink::T; append::Bool=false, transforms::Dict=Dict{Int,Function}(), kwargs...) where T
    source = CSV.Source(fullpath; kwargs...)
    sink = Data.stream!(source, sink; append=append, transforms=transforms)
    return Data.close!(sink)
end</code></pre><p>In this example, CSV.jl defines it&#39;s own high-level function for reading from a <code>CSV.Source</code>. In these examples, a <code>CSV.Source</code> is constructed using the <code>fullpath</code> argument, along w/ any extra <code>kwargs...</code>. The sink can be provided as a type with <code>args...</code> and <code>kwargs...</code> that will be passed to its DataStreams constructor, like <code>Sink(sch, streamtype, append, args...; kwargs...)</code>; otherwise, an already-constructed Sink can be provided directly (2nd example).</p><p>Once the <code>source</code> is constructed, the data is streamed via the call to <code>Data.stream(source, sink; append=append, transforms=transforms)</code>, with the sink being returned.</p><p>And finally, to &quot;finish&quot; the streaming process, <code>Data.close!(sink)</code> is closed, which returns the finalized sink. Note that <code>Data.stream!(source, sink)</code> could be called multiple times with different sources and the same sink, most likely with <code>append=true</code> being passed, to enable the accumulation of several sources into a single sink. A single <code>Data.close!(sink)</code> method should be called to officially close or commit the final sink.</p><p>Two &quot;builtin&quot; Source/Sink types that are included with the DataStreams package are the <code>Data.Table</code> and <code>Data.RowTable</code> types. <code>Data.Table</code> is a NamedTuple of AbstractVectors, with column names as NamedTuple fieldnames. This type supports both <code>Data.Field</code> and <code>Data.Column</code> streaming. <code>Data.RowTable</code> is just a Vector of NamedTuples, and as such, only supports <code>Data.Field</code> streaming.</p><p>In addition, any <code>Data.Source</code> can be iterated via the <code>Data.rows(source)</code> function, which returns a NamedTuple-iterator over the rows of a source.</p></div></div></section><h2><a class="nav-anchor" id="Data.Schema-1" href="#Data.Schema-1"><code>Data.Schema</code></a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="DataStreams.Data.Schema" href="#DataStreams.Data.Schema"><code>DataStreams.Data.Schema</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A <code>Data.Schema</code> describes a tabular dataset, i.e. a set of named, typed columns with records as rows</p><p><code>Data.Schema</code> allow <code>Data.Source</code> and <code>Data.Sink</code> to talk to each other and prepare to provide/receive data through streaming. <code>Data.Schema</code> provides the following accessible properties:</p><ul><li><code>Data.header(schema)</code> to return the header/column names in a <code>Data.Schema</code></li><li><code>Data.types(schema)</code> to return the column types in a <code>Data.Schema</code>; <code>Union{T, Missing}</code> indicates columns that may contain missing data (<code>missing</code> values)</li><li><code>Data.size(schema)</code> to return the (# of rows, # of columns) in a <code>Data.Schema</code>; note that # of rows may be <code>missing</code>, meaning unknown</li></ul><p><code>Data.Schema</code> has the following constructors:</p><ul><li><code>Data.Schema()</code>: create an &quot;empty&quot; schema with no rows, no columns, and no column names</li><li><code>Data.Schema(types[, header, rows, meta::Dict])</code>: column element types are provided as a tuple or vector; column names provided as an iterable; # of rows can be an Int or <code>missing</code> to indicate unknown # of rows</li></ul><p><code>Data.Schema</code> are indexable via column names to get the number of that column in the <code>Data.Schema</code></p><pre><code class="language-julia">julia&gt; sch = Data.Schema([Int], [&quot;column1&quot;], 10)
Data.Schema:
rows: 10	cols: 1
Columns:
 &quot;column1&quot;  Int64

julia&gt; sch[&quot;column1&quot;]
1</code></pre><p><strong>Developer note</strong>: the full type definition is <code>Data.Schema{R, T}</code> where the <code>R</code> type parameter will be <code>true</code> or <code>false</code>, indicating whether the # of rows are known (i.e not <code>missing</code>), respectively. The <code>T</code> type parameter is a <code>Tuple{A, B, ...}</code> representing the column element types in the <code>Data.Schema</code>. Both of these type parameters provide valuable information that may be useful when constructing <code>Sink</code>s or streaming data.</p></div></div></section><p>The reference DataStreams interface implementation lives in the <a href="https://github.com/JuliaData/DataStreams.jl/blob/master/src/DataStreams.jl#L370">DataStreams.jl package itself</a>, implemented for a NamedTuple with AbstractVector elements.</p><p>For examples of additional interface implementations, see some of the packages below:</p><p><code>Data.Source</code> implementations:</p><ul><li><a href="https://github.com/JuliaData/CSV.jl/blob/master/src/Source.jl"><code>CSV.Source</code></a></li><li><a href="https://github.com/JuliaDB/SQLite.jl/blob/master/src/Source.jl"><code>SQLite.Source</code></a></li><li><a href="https://github.com/JuliaDB/ODBC.jl/blob/master/src/Source.jl"><code>ODBC.Source</code></a></li></ul><p><code>Data.Sink</code> implementations:</p><ul><li><a href="https://github.com/JuliaData/CSV.jl/blob/master/src/Sink.jl"><code>CSV.Sink</code></a></li><li><a href="https://github.com/JuliaDB/SQLite.jl/blob/master/src/Sink.jl"><code>SQLite.Sink</code></a></li><li><a href="https://github.com/JuliaDB/ODBC.jl/blob/master/src/Sink.jl"><code>ODBC.Sink</code></a></li></ul><footer><hr/></footer></article></body></html>
