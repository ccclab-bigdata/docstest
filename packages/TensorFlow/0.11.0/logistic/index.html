<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Logistic regression Â· TensorFlow.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-1123761-11', 'auto');
ga('send', 'pageview');
</script><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../index.html"><img class="logo" src="../assets/logo.png" alt="TensorFlow.jl logo"/></a><h1>TensorFlow.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../tutorial/">MNIST tutorial</a></li><li><a class="toctext" href="../visualization/">Visualizing with Tensorboard</a></li><li><a class="toctext" href="../io/">Using queues for loading your data</a></li><li><a class="toctext" href="../shape_inference/">Shape inference</a></li><li><a class="toctext" href="../saving/">Saving and restoring</a></li></ul></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../core/">Core functions</a></li><li><a class="toctext" href="../ops/">Operations</a></li><li><a class="toctext" href="../io_ref/">IO pipelines with queues</a></li><li><a class="toctext" href="../summary_ref/">Summaries</a></li></ul></li><li><span class="toctext">Examples</span><ul><li><a class="toctext" href="../basic_usage/">Basic usage</a></li><li class="current"><a class="toctext" href>Logistic regression</a><ul class="internal"></ul></li></ul></li><li><span class="toctext">Advanced</span><ul><li><a class="toctext" href="../build_from_source/">Build TensorFlow from source</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Examples</li><li><a href>Logistic regression</a></li></ul></nav><hr/><div id="topbar"><span>Logistic regression</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Logistic-regression-1" href="#Logistic-regression-1">Logistic regression</a></h1><pre><code class="language-julia">using Distributions, TensorFlow, Printf

# Generate some synthetic data
x = randn(100, 50)
w = randn(50, 10)
y_prob = exp.(x*w)
y_prob ./= sum(y_prob, dims=2)

function draw(probs)
    y = zeros(size(probs))
    for i in 1:size(probs, 1)
        idx = rand(Categorical(probs[i, :]))
        y[i, idx] = 1
    end
    return y
end

y = draw(y_prob)

# Build the model
sess = Session(Graph())
X = placeholder(Float64)
Y_obs = placeholder(Float64)

variable_scope(&quot;logisitic_model&quot;, initializer=Normal(0, .001)) do
    global W = get_variable(&quot;weights&quot;, [50, 10], Float64)
    global B = get_variable(&quot;bias&quot;, [10], Float64)
end

Y=nn.softmax(X*W + B)
Loss = -reduce_sum(log(Y).*Y_obs)
optimizer = train.AdamOptimizer()
minimize_op = train.minimize(optimizer, Loss)
saver = train.Saver()
# Run training
run(sess, global_variables_initializer())
checkpoint_path = mktempdir()
@info(&quot;Checkpoint files saved in $checkpoint_path&quot;)
for epoch in 1:100
    cur_loss, _ = run(sess, (Loss, minimize_op), Dict(X=&gt;x, Y_obs=&gt;y))
    println(Printf.@sprintf(&quot;Current loss is %.2f.&quot;, cur_loss))
    train.save(saver, sess, joinpath(checkpoint_path, &quot;logistic&quot;), global_step=epoch)
end
</code></pre><footer><hr/><a class="previous" href="../basic_usage/"><span class="direction">Previous</span><span class="title">Basic usage</span></a><a class="next" href="../build_from_source/"><span class="direction">Next</span><span class="title">Build TensorFlow from source</span></a></footer></article></body></html>
