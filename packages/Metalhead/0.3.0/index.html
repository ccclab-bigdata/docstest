<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme · Metalhead.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Metalhead.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li class="toplevel"><a class="toctext" href="#Working-with-common-datasets-1">Working with common datasets</a></li><li class="toplevel"><a class="toctext" href="#Inline-Images-at-the-REPL-1">Inline Images at the REPL</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Metalhead-1" href="#Metalhead-1">Metalhead</a></h1><p><a href="https://travis-ci.org/FluxML/Metalhead.jl"><img src="https://travis-ci.org/FluxML/Metalhead.jl.svg?branch=master" alt="Build Status"/></a></p><pre><code class="language-julia">Pkg.add(&quot;Metalhead&quot;)</code></pre><p>This package provides computer vision models that run on top of the <a href="http://fluxml.github.io/">Flux</a> machine learning library.</p><p><img src="https://i.imgur.com/spBsaz7.png" alt="IJulia Screenshot"/></p><p>Each model (like <code>VGG19</code>) is a Flux layer, so you can do anything you would normally do with a model; like moving it to the GPU, training or freezing components, and extending it to carry out other tasks (such as neural style transfer).</p><pre><code class="language-julia"># Run with dummy image data
julia&gt; x = rand(Float32, 224, 224, 3, 1)
224×224×3×1 Array{Float32,4}:
[:, :, 1, 1] =
 0.353337   0.252493    0.444695   0.767193    …  0.107599   0.424298   0.218889    0.377959
 0.247294   0.039822    0.829367   0.832303       0.582103   0.359319   0.259342    0.12293
  ⋮

julia&gt; vgg(x)
1000×1 Array{Float32,2}:
 0.000851723
 0.00079913
  ⋮

# See the underlying model structure
julia&gt; vgg.layers
Chain(Conv2D((3, 3), 3=&gt;64, NNlib.relu), Conv2D((3, 3), 64=&gt;64, NNlib.relu), Metalhead.#3, Conv2D((3, 3), 64=&gt;128, NNlib.relu), Conv2D((3, 3), 128=&gt;128, NNlib.relu), Metalhead.#4, Conv2D((3, 3), 128=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Conv2D((3, 3), 256=&gt;256, NNlib.relu), Metalhead.#5, Conv2D((3, 3), 256=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Metalhead.#6, Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Conv2D((3, 3), 512=&gt;512, NNlib.relu), Metalhead.#7, Metalhead.#8, Dense(25088, 4096, NNlib.relu), Flux.Dropout{Float32}(0.5f0, false), Dense(4096, 4096, NNlib.relu), Flux.Dropout{Float32}(0.5f0, false), Dense(4096, 1000), NNlib.softmax)

# Run the model up to the last convolution/pooling layer
julia&gt; vgg.layers[1:21](x)
7×7×512×1 Array{Float32,4}:
[:, :, 1, 1] =
 0.657502  0.598338  0.594517  0.594425  0.594522  0.597183  0.59534
 0.663341  0.600874  0.596379  0.596292  0.596385  0.598204  0.590494
  ⋮</code></pre><h1><a class="nav-anchor" id="Working-with-common-datasets-1" href="#Working-with-common-datasets-1">Working with common datasets</a></h1><p>Metalhead includes support for wokring with several common object recognition datasets. The <code>datasets()</code> function will attempt to auto-detect any common dataset placed in the <code>datasets/</code>. The <code>Metalhead.download</code> function can be used to download these datasets (where such automatic download is possible - for other data sets, see <code>datasets/README.md</code>), e.g.:</p><pre><code class="language-none">MetalHead.download(CIFAR10)</code></pre><p>Once a dataset is load, it&#39;s training, validation, and test images are available using the <code>trainimgs</code>, <code>valimgs</code>, and <code>testimgs</code> functions. E.g.</p><pre><code class="language-none">julia&gt; valimgs(dataset(ImageNet))[rand(1:50000, 10)]</code></pre><p>will fetch 10 random validation images from the ImageNet data set.</p><h1><a class="nav-anchor" id="Inline-Images-at-the-REPL-1" href="#Inline-Images-at-the-REPL-1">Inline Images at the REPL</a></h1><p>If you are using OS X, it is recommended that you use iTerm2 and install the <code>TerminalExtensions.jl</code> package. This will allow you to see inference results as well as the corresponding images directly in your terminal:</p><p><img src="https://i.imgur.com/hy7LXS5.png" alt="REPL Screenshot"/></p><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
