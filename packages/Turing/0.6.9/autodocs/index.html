<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · Turing.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Turing.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><pre><code class="language-none">Turing.+</code></pre><pre><code class="language-none">Turing.-</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Core.@VarName" href="#Turing.Core.@VarName"><code>Turing.Core.@VarName</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><p>Usage: @VarName x[1,2][1+5][45][3]   return: (:x,[1,2],6,45,3)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Core.@model" href="#Turing.Core.@model"><code>Turing.Core.@model</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><pre><code class="language-none">@model(body)</code></pre><p>Macro to specify a probabilistic model.</p><p>Example:</p><p>Model definition:</p><pre><code class="language-julia">@model model_generator(x = default_x, y) = begin
    ...
end</code></pre><p>Expanded model definition</p><pre><code class="language-julia"># Allows passing arguments as kwargs
model_generator(; x = nothing, y = nothing)) = model_generator(x, y)
function model_generator(x = nothing, y = nothing)
    pvars, dvars = Turing.get_vars(Tuple{:x, :y}, (x = x, y = y))
    data = Turing.get_data(dvars, (x = x, y = y))
    defaults = Turing.get_default_values(dvars, (x = default_x, y = nothing))
    
    inner_function(sampler::Turing.AnySampler, model) = inner_function(model)
    function inner_function(model)
        return inner_function(Turing.VarInfo(), Turing.SampleFromPrior(), model)
    end
    function inner_function(vi::Turing.VarInfo, model)
        return inner_function(vi, Turing.SampleFromPrior(), model)
    end
    # Define the main inner function
    function inner_function(vi::Turing.VarInfo, sampler::Turing.AnySampler, model)
        local x
        if isdefined(model.data, :x)
            x = model.data.x
        else
            x = model_defaults.x
        end
        local y
        if isdefined(model.data, :y)
            y = model.data.y
        else
            y = model.defaults.y
        end

        vi.logp = zero(Real)
        ...
    end
    model = Turing.Model{pvars, dvars}(inner_function, data, defaults)
    return model
end</code></pre><p>Generating a model: <code>model_generator(x_value)::Model</code>.</p></div></div></section><pre><code class="language-none">Turing.AbstractMixtureModel</code></pre><pre><code class="language-none">Turing.AbstractMvNormal</code></pre><pre><code class="language-none">Turing.AbstractSampler</code></pre><pre><code class="language-none">Turing.Arcsine</code></pre><pre><code class="language-none">Turing.Bernoulli</code></pre><pre><code class="language-none">Turing.Beta</code></pre><pre><code class="language-none">Turing.BetaBinomial</code></pre><pre><code class="language-none">Turing.BetaPrime</code></pre><pre><code class="language-none">Turing.Binomial</code></pre><pre><code class="language-none">Turing.BinomialLogit</code></pre><pre><code class="language-none">Turing.Biweight</code></pre><pre><code class="language-none">Turing.CACHEIDCS</code></pre><pre><code class="language-none">Turing.CACHERANGES</code></pre><pre><code class="language-none">Turing.CACHERESET</code></pre><pre><code class="language-none">Turing.CSMC</code></pre><pre><code class="language-none">Turing.CTask</code></pre><pre><code class="language-none">Turing.Categorical</code></pre><pre><code class="language-none">Turing.Cauchy</code></pre><pre><code class="language-none">Turing.Chains</code></pre><pre><code class="language-none">Turing.Chi</code></pre><pre><code class="language-none">Turing.Chisq</code></pre><pre><code class="language-none">Turing.Continuous</code></pre><pre><code class="language-none">Turing.ContinuousDistribution</code></pre><pre><code class="language-none">Turing.ContinuousMatrixDistribution</code></pre><pre><code class="language-none">Turing.ContinuousMultivariateDistribution</code></pre><pre><code class="language-none">Turing.ContinuousUnivariateDistribution</code></pre><pre><code class="language-none">Turing.Core</code></pre><pre><code class="language-none">Turing.Cosine</code></pre><pre><code class="language-none">Turing.DiagNormal</code></pre><pre><code class="language-none">Turing.DiagNormalCanon</code></pre><pre><code class="language-none">Turing.Dirichlet</code></pre><pre><code class="language-none">Turing.DirichletMultinomial</code></pre><pre><code class="language-none">Turing.Discrete</code></pre><pre><code class="language-none">Turing.DiscreteDistribution</code></pre><pre><code class="language-none">Turing.DiscreteMatrixDistribution</code></pre><pre><code class="language-none">Turing.DiscreteMultivariateDistribution</code></pre><pre><code class="language-none">Turing.DiscreteUniform</code></pre><pre><code class="language-none">Turing.DiscreteUnivariateDistribution</code></pre><pre><code class="language-none">Turing.Distribution</code></pre><pre><code class="language-none">Turing.Distributions</code></pre><pre><code class="language-none">Turing.DoubleExponential</code></pre><pre><code class="language-none">Turing.DynamicHMC</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.DynamicNUTS" href="#Turing.Inference.DynamicNUTS"><code>Turing.Inference.DynamicNUTS</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">DynamicNUTS(n_iters::Integer)</code></pre><p>Dynamic No U-Turn Sampling algorithm provided by the DynamicHMC package. To use it, make sure you have the DynamicHMC package installed.</p><pre><code class="language-julia"># Import Turing and DynamicHMC.
using DynamicHMC, Turing

# Model definition.
@model gdemo(x, y) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0,sqrt(s))
  x ~ Normal(m, sqrt(s))
  y ~ Normal(m, sqrt(s))
  return s, m
end

# Pull 2,000 samples using DynamicNUTS.
chn = sample(gdemo(1.5, 2.0), DynamicNUTS(2000))</code></pre></div></div></section><pre><code class="language-none">Turing.EdgeworthMean</code></pre><pre><code class="language-none">Turing.EdgeworthSum</code></pre><pre><code class="language-none">Turing.EdgeworthZ</code></pre><pre><code class="language-none">Turing.EmpiricalUnivariateDistribution</code></pre><pre><code class="language-none">Turing.Epanechnikov</code></pre><pre><code class="language-none">Turing.Erlang</code></pre><pre><code class="language-none">Turing.Estimator</code></pre><pre><code class="language-none">Turing.Exponential</code></pre><pre><code class="language-none">Turing.FDist</code></pre><pre><code class="language-none">Turing.FisherNoncentralHypergeometric</code></pre><pre><code class="language-none">Turing.Flat</code></pre><pre><code class="language-none">Turing.FlatPos</code></pre><pre><code class="language-none">Turing.Frechet</code></pre><pre><code class="language-none">Turing.FullNormal</code></pre><pre><code class="language-none">Turing.FullNormalCanon</code></pre><pre><code class="language-none">Turing.Gamma</code></pre><pre><code class="language-none">Turing.GeneralizedExtremeValue</code></pre><pre><code class="language-none">Turing.GeneralizedPareto</code></pre><pre><code class="language-none">Turing.Geometric</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.Gibbs" href="#Turing.Inference.Gibbs"><code>Turing.Inference.Gibbs</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Gibbs(n_iters, algs...)</code></pre><p>Compositional MCMC interface. Gibbs sampling combines one or more sampling algorithms, each of which samples from a different set of variables in a model.</p><p>Example:</p><pre><code class="language-julia">@model gibbs_example(x) = begin
    v1 ~ Normal(0,1)
    v2 ~ Categorical(5)
        ...
end

# Use PG for a &#39;v2&#39; variable, and use HMC for the &#39;v1&#39; variable.
# Note that v2 is discrete, so the PG sampler is more appropriate
# than is HMC.
alg = Gibbs(1000, HMC(1, 0.2, 3, :v1), PG(20, 1, :v2))</code></pre><p>Tips:</p><ul><li><code>HMC</code> and <code>NUTS</code> are fast samplers, and can throw off particle-based</li></ul><p>methods like Particle Gibbs. You can increase the effectiveness of particle sampling by including more particles in the particle sampler.</p></div></div></section><pre><code class="language-none">Turing.Gumbel</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.HMC" href="#Turing.Inference.HMC"><code>Turing.Inference.HMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">HMC(n_iters::Int, epsilon::Float64, tau::Int)</code></pre><p>Hamiltonian Monte Carlo sampler.</p><p>Arguments:</p><ul><li><code>n_iters::Int</code> : The number of samples to pull.</li><li><code>epsilon::Float64</code> : The leapfrog step size to use.</li><li><code>tau::Int</code> : The number of leapfrop steps to use.</li></ul><p>Usage:</p><pre><code class="language-julia">HMC(1000, 0.05, 10)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
    s ~ InverseGamma(2,3)
    m ~ Normal(0, sqrt(s))
    x[1] ~ Normal(m, sqrt(s))
    x[2] ~ Normal(m, sqrt(s))
    return s, m
end

sample(gdemo([1.5, 2]), HMC(1000, 0.05, 10))</code></pre><p>Tips:</p><ul><li>If you are receiving gradient errors when using <code>HMC</code>, try reducing the</li></ul><p><code>step_size</code> parameter.</p><pre><code class="language-julia"># Original step_size
sample(gdemo([1.5, 2]), HMC(1000, 0.1, 10))

# Reduced step_size.
sample(gdemo([1.5, 2]), HMC(1000, 0.01, 10))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.HMCDA" href="#Turing.Inference.HMCDA"><code>Turing.Inference.HMCDA</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">HMCDA(n_iters::Int, n_adapts::Int, delta::Float64, lambda::Float64)</code></pre><p>Hamiltonian Monte Carlo sampler with Dual Averaging algorithm.</p><p>Usage:</p><pre><code class="language-julia">HMCDA(1000, 200, 0.65, 0.3)</code></pre><p>Arguments:</p><ul><li><code>n_iters::Int</code> : Number of samples to pull.</li><li><code>n_adapts::Int</code> : Numbers of samples to use for adaptation.</li><li><code>delta::Float64</code> : Target acceptance rate. 65% is often recommended.</li><li><code>lambda::Float64</code> : Target leapfrop length.</li></ul><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), HMCDA(1000, 200, 0.65, 0.3))</code></pre><p>For more information, please view the following paper (<a href="https://arxiv.org/abs/1111.4246">arXiv link</a>):</p><p>Hoffman, Matthew D., and Andrew Gelman. &quot;The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.&quot; Journal of Machine Learning Research 15, no. 1 (2014): 1593-1623.</p></div></div></section><pre><code class="language-none">Turing.Hypergeometric</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.IPMCMC" href="#Turing.Inference.IPMCMC"><code>Turing.Inference.IPMCMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">IPMCMC(n_particles::Int, n_iters::Int, n_nodes::Int, n_csmc_nodes::Int)</code></pre><p>Particle Gibbs sampler.</p><p>Note that this method is particle-based, and arrays of variables must be stored in a <a href="@ref"><code>TArray</code></a> object.</p><p>Usage:</p><pre><code class="language-julia">IPMCMC(100, 100, 4, 2)</code></pre><p>Arguments:</p><ul><li><code>n_particles::Int</code> : Number of particles to use.</li><li><code>n_iters::Int</code> : Number of iterations to employ.</li><li><code>n_nodes::Int</code> : The number of nodes running SMC and CSMC.</li><li><code>n_csmc_nodes::Int</code> : The number of CSMC nodes.</li></ul><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0,sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), IPMCMC(100, 100, 4, 2))</code></pre><p>A paper on this can be found <a href="https://arxiv.org/abs/1602.05128">here</a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.IS" href="#Turing.Inference.IS"><code>Turing.Inference.IS</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">IS(n_particles::Int)</code></pre><p>Importance sampling algorithm.</p><p>Note that this method is particle-based, and arrays of variables must be stored in a <a href="@ref"><code>TArray</code></a> object.</p><p>Arguments:</p><ul><li><code>n_particles</code> is the number of particles to use.</li></ul><p>Usage:</p><pre><code class="language-julia">IS(1000)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
    s ~ InverseGamma(2,3)
    m ~ Normal(0,sqrt.(s))
    x[1] ~ Normal(m, sqrt.(s))
    x[2] ~ Normal(m, sqrt.(s))
    return s, m
end

sample(gdemo([1.5, 2]), IS(1000))</code></pre></div></div></section><pre><code class="language-none">Turing.Inference</code></pre><pre><code class="language-none">Turing.InverseGamma</code></pre><pre><code class="language-none">Turing.InverseGaussian</code></pre><pre><code class="language-none">Turing.InverseWishart</code></pre><pre><code class="language-none">Turing.IsoNormal</code></pre><pre><code class="language-none">Turing.IsoNormalCanon</code></pre><pre><code class="language-none">Turing.KSDist</code></pre><pre><code class="language-none">Turing.KSOneSided</code></pre><pre><code class="language-none">Turing.Kolmogorov</code></pre><pre><code class="language-none">Turing.Laplace</code></pre><pre><code class="language-none">Turing.Levy</code></pre><pre><code class="language-none">Turing.Libtask</code></pre><pre><code class="language-none">Turing.LocationScale</code></pre><pre><code class="language-none">Turing.LogDensityProblems</code></pre><pre><code class="language-none">Turing.LogNormal</code></pre><pre><code class="language-none">Turing.Logistic</code></pre><pre><code class="language-none">Turing.MCMCChain</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.MH" href="#Turing.Inference.MH"><code>Turing.Inference.MH</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">MH(n_iters::Int)</code></pre><p>Metropolis-Hastings sampler.</p><p>Usage:</p><pre><code class="language-julia">MH(100, (:m, (x) -&gt; Normal(x, 0.1)))</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0,sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

chn = sample(gdemo([1.5, 2]), MH(1000))</code></pre></div></div></section><pre><code class="language-none">Turing.MLEstimator</code></pre><pre><code class="language-none">Turing.MatrixDistribution</code></pre><pre><code class="language-none">Turing.Matrixvariate</code></pre><pre><code class="language-none">Turing.MixtureModel</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Model" href="#Turing.Model"><code>Turing.Model</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">struct Model{pvars, dvars, F, TData, TDefaults}
    f::F
    data::TData
    defaults::TDefaults
end</code></pre><p>A <code>Model</code> struct with parameter variables <code>pvars</code>, data variables <code>dvars</code>, inner  function <code>f</code>, <code>data::NamedTuple</code> and <code>defaults::NamedTuple</code>.</p></div></div></section><pre><code class="language-none">Turing.Multinomial</code></pre><pre><code class="language-none">Turing.Multivariate</code></pre><pre><code class="language-none">Turing.MultivariateDistribution</code></pre><pre><code class="language-none">Turing.MultivariateMixture</code></pre><pre><code class="language-none">Turing.MultivariateNormal</code></pre><pre><code class="language-none">Turing.MvLogNormal</code></pre><pre><code class="language-none">Turing.MvNormal</code></pre><pre><code class="language-none">Turing.MvNormalCanon</code></pre><pre><code class="language-none">Turing.MvNormalKnownCov</code></pre><pre><code class="language-none">Turing.MvTDist</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.NUTS" href="#Turing.Inference.NUTS"><code>Turing.Inference.NUTS</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">NUTS(n_iters::Int, n_adapts::Int, delta::Float64)</code></pre><p>No-U-Turn Sampler (NUTS) sampler.</p><p>Usage:</p><pre><code class="language-julia">NUTS(1000, 200, 0.6j_max)</code></pre><p>Arguments:</p><ul><li><code>n_iters::Int</code> : The number of samples to pull.</li><li><code>n_adapts::Int</code> : The number of samples to use with adapatation.</li><li><code>delta::Float64</code> : Target acceptance rate.</li></ul><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.j_max, 2]), NUTS(1000, 200, 0.6j_max))</code></pre></div></div></section><pre><code class="language-none">Turing.NegativeBinomial</code></pre><pre><code class="language-none">Turing.NonMatrixDistribution</code></pre><pre><code class="language-none">Turing.NoncentralBeta</code></pre><pre><code class="language-none">Turing.NoncentralChisq</code></pre><pre><code class="language-none">Turing.NoncentralF</code></pre><pre><code class="language-none">Turing.NoncentralHypergeometric</code></pre><pre><code class="language-none">Turing.NoncentralT</code></pre><pre><code class="language-none">Turing.Normal</code></pre><pre><code class="language-none">Turing.NormalCanon</code></pre><pre><code class="language-none">Turing.NormalInverseGaussian</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.PG" href="#Turing.Inference.PG"><code>Turing.Inference.PG</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PG(n_particles::Int, n_iters::Int)</code></pre><p>Particle Gibbs sampler.</p><p>Note that this method is particle-based, and arrays of variables must be stored in a <a href="@ref"><code>TArray</code></a> object.</p><p>Usage:</p><pre><code class="language-julia">PG(100, 100)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), PG(100, 100))</code></pre></div></div></section><pre><code class="language-none">Turing.PIMH</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.PMMH" href="#Turing.Inference.PMMH"><code>Turing.Inference.PMMH</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PMMH(n_iters::Int, smc_alg:::SMC, parameters_algs::Tuple{MH})</code></pre><p>Particle independant Metropolis–Hastings and Particle marginal Metropolis–Hastings samplers.</p><p>Note that this method is particle-based, and arrays of variables must be stored in a <a href="@ref"><code>TArray</code></a> object.</p><p>Usage:</p><pre><code class="language-julia">alg = PMMH(100, SMC(20, :v1), MH(1,:v2))
alg = PMMH(100, SMC(20, :v1), MH(1,(:v2, (x) -&gt; Normal(x, 1))))</code></pre><p>Arguments:</p><ul><li><code>n_iters::Int</code> : Number of iterations to run.</li><li><code>smc_alg:::SMC</code> : An <a href="#Turing.Inference.SMC"><code>SMC</code></a> algorithm to use.</li><li><code>parameters_algs::Tuple{MH}</code> : An <a href="#Turing.Inference.MH"><code>MH</code></a> algorithm, which includes a</li></ul><p>sample space specification.</p></div></div></section><pre><code class="language-none">Turing.PROGRESS</code></pre><pre><code class="language-none">Turing.Pareto</code></pre><pre><code class="language-none">Turing.Poisson</code></pre><pre><code class="language-none">Turing.PoissonBinomial</code></pre><pre><code class="language-none">Turing.QQPair</code></pre><pre><code class="language-none">Turing.Rayleigh</code></pre><pre><code class="language-none">Turing.RealInterval</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.SGHMC" href="#Turing.Inference.SGHMC"><code>Turing.Inference.SGHMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SGHMC(n_iters::Int, learning_rate::Float64, momentum_decay::Float64)</code></pre><p>Stochastic Gradient Hamiltonian Monte Carlo sampler.</p><p>Usage:</p><pre><code class="language-julia">SGHMC(1000, 0.01, 0.1)</code></pre><p>Arguments:</p><ul><li><code>n_iters::Int</code> : Number of samples to pull.</li><li><code>learning_rate::Float64</code> : The learning rate.</li><li><code>momentum_decay::Float64</code> : Momentum decay variable.</li></ul><p>Example:</p><pre><code class="language-julia">@model example begin
  ...
end

sample(example, SGHMC(1000, 0.01, 0.1))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.SGLD" href="#Turing.Inference.SGLD"><code>Turing.Inference.SGLD</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SGLD(n_iters::Int, epsilon::Float64)</code></pre><p>Stochastic Gradient Langevin Dynamics sampler.</p><p>Usage:</p><pre><code class="language-julia">SGLD(1000, 0.5)</code></pre><p>Arguments:</p><ul><li><code>n_iters::Int</code> : Number of samples to pull.</li><li><code>epsilon::Float64</code> : The scaling factor for the learing rate.</li></ul><p>Example:</p><pre><code class="language-julia">@model example begin
  ...
end

sample(example, SGLD(1000, 0.5))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Inference.SMC" href="#Turing.Inference.SMC"><code>Turing.Inference.SMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SMC(n_particles::Int)</code></pre><p>Sequential Monte Carlo sampler.</p><p>Note that this method is particle-based, and arrays of variables must be stored in a <a href="@ref"><code>TArray</code></a> object.</p><p>Usage:</p><pre><code class="language-julia">SMC(1000)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), SMC(1000))</code></pre></div></div></section><pre><code class="language-none">Turing.Sampleable</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Sampler" href="#Turing.Sampler"><code>Turing.Sampler</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Sampler{T}</code></pre><p>Generic interface for implementing inference algorithms. An implementation of an algorithm should include the following:</p><ol><li>A type specifying the algorithm and its parameters, derived from InferenceAlgorithm</li><li>A method of <code>sample</code> function that produces results of inference, which is where actual inference happens.</li></ol><p>Turing translates models to chunks that call the modelling functions at specified points. The dispatch is based on the value of a <code>sampler</code> variable. To include a new inference algorithm implements the requirements mentioned above in a separate file, then include that file at the end of this one.</p></div></div></section><pre><code class="language-none">Turing.Semicircle</code></pre><pre><code class="language-none">Turing.Skellam</code></pre><pre><code class="language-none">Turing.SufficientStats</code></pre><pre><code class="language-none">Turing.SymTriangularDist</code></pre><pre><code class="language-none">Turing.TArray</code></pre><pre><code class="language-none">Turing.TDist</code></pre><pre><code class="language-none">Turing.TRef</code></pre><pre><code class="language-none">Turing.TriangularDist</code></pre><pre><code class="language-none">Turing.Triweight</code></pre><pre><code class="language-none">Turing.Truncated</code></pre><pre><code class="language-none">Turing.TruncatedNormal</code></pre><pre><code class="language-none">Turing.Turing</code></pre><pre><code class="language-none">Turing.Uniform</code></pre><pre><code class="language-none">Turing.Univariate</code></pre><pre><code class="language-none">Turing.UnivariateDistribution</code></pre><pre><code class="language-none">Turing.UnivariateGMM</code></pre><pre><code class="language-none">Turing.UnivariateMixture</code></pre><pre><code class="language-none">Turing.Utilities</code></pre><pre><code class="language-none">Turing.ValueSupport</code></pre><pre><code class="language-none">Turing.VariateForm</code></pre><pre><code class="language-none">Turing.VecBinomialLogit</code></pre><pre><code class="language-none">Turing.VonMises</code></pre><pre><code class="language-none">Turing.VonMisesFisher</code></pre><pre><code class="language-none">Turing.WalleniusNoncentralHypergeometric</code></pre><pre><code class="language-none">Turing.Weibull</code></pre><pre><code class="language-none">Turing.Wishart</code></pre><pre><code class="language-none">Turing.ZeroMeanDiagNormal</code></pre><pre><code class="language-none">Turing.ZeroMeanDiagNormalCanon</code></pre><pre><code class="language-none">Turing.ZeroMeanFullNormal</code></pre><pre><code class="language-none">Turing.ZeroMeanFullNormalCanon</code></pre><pre><code class="language-none">Turing.ZeroMeanIsoNormal</code></pre><pre><code class="language-none">Turing.ZeroMeanIsoNormalCanon</code></pre><pre><code class="language-none">Turing.__init__</code></pre><pre><code class="language-none">Turing.__inits__</code></pre><pre><code class="language-none">Turing.autcorplot</code></pre><pre><code class="language-none">Turing.auto_tune_chunk_size!</code></pre><pre><code class="language-none">Turing.autocorplot</code></pre><pre><code class="language-none">Turing.autocorplot!</code></pre><pre><code class="language-none">Turing.binaryentropy</code></pre><pre><code class="language-none">Turing.canonform</code></pre><pre><code class="language-none">Turing.ccdf</code></pre><pre><code class="language-none">Turing.cdf</code></pre><pre><code class="language-none">Turing.cf</code></pre><pre><code class="language-none">Turing.cgf</code></pre><pre><code class="language-none">Turing.circvar</code></pre><pre><code class="language-none">Turing.component</code></pre><pre><code class="language-none">Turing.components</code></pre><pre><code class="language-none">Turing.componentwise_logpdf</code></pre><pre><code class="language-none">Turing.componentwise_pdf</code></pre><pre><code class="language-none">Turing.concentration</code></pre><pre><code class="language-none">Turing.consume</code></pre><pre><code class="language-none">Turing.cor</code></pre><pre><code class="language-none">Turing.corner</code></pre><pre><code class="language-none">Turing.corner!</code></pre><pre><code class="language-none">Turing.cov</code></pre><pre><code class="language-none">Turing.cquantile</code></pre><pre><code class="language-none">Turing.cumulant</code></pre><pre><code class="language-none">Turing.densityplot</code></pre><pre><code class="language-none">Turing.describe</code></pre><pre><code class="language-none">Turing.dim</code></pre><pre><code class="language-none">Turing.discretediag</code></pre><pre><code class="language-none">Turing.dof</code></pre><pre><code class="language-none">Turing.enable_stack_copying</code></pre><pre><code class="language-none">Turing.entropy</code></pre><pre><code class="language-none">Turing.estimate</code></pre><pre><code class="language-none">Turing.eval</code></pre><pre><code class="language-none">Turing.expected_logdet</code></pre><pre><code class="language-none">Turing.failprob</code></pre><pre><code class="language-none">Turing.fit</code></pre><pre><code class="language-none">Turing.fit_map</code></pre><pre><code class="language-none">Turing.fit_map!</code></pre><pre><code class="language-none">Turing.fit_mle</code></pre><pre><code class="language-none">Turing.fit_mle!</code></pre><pre><code class="language-none">Turing.freecumulant</code></pre><pre><code class="language-none">Turing.gelmandiag</code></pre><pre><code class="language-none">Turing.get</code></pre><pre><code class="language-none">Turing.get_defaults</code></pre><pre><code class="language-none">Turing.get_dvars</code></pre><pre><code class="language-none">Turing.get_pvars</code></pre><pre><code class="language-none">Turing.getindex</code></pre><pre><code class="language-none">Turing.gewekediag</code></pre><pre><code class="language-none">Turing.gradlogpdf</code></pre><pre><code class="language-none">Turing.hasfinitesupport</code></pre><pre><code class="language-none">Turing.heideldiag</code></pre><pre><code class="language-none">Turing.histogramplot</code></pre><pre><code class="language-none">Turing.in_dvars</code></pre><pre><code class="language-none">Turing.in_pvars</code></pre><pre><code class="language-none">Turing.include</code></pre><pre><code class="language-none">Turing.insupport</code></pre><pre><code class="language-none">Turing.invcov</code></pre><pre><code class="language-none">Turing.invlogccdf</code></pre><pre><code class="language-none">Turing.invlogcdf</code></pre><pre><code class="language-none">Turing.invscale</code></pre><pre><code class="language-none">Turing.isbounded</code></pre><pre><code class="language-none">Turing.isleptokurtic</code></pre><pre><code class="language-none">Turing.islowerbounded</code></pre><pre><code class="language-none">Turing.ismesokurtic</code></pre><pre><code class="language-none">Turing.isplatykurtic</code></pre><pre><code class="language-none">Turing.isprobvec</code></pre><pre><code class="language-none">Turing.isupperbounded</code></pre><pre><code class="language-none">Turing.kde</code></pre><pre><code class="language-none">Turing.kurtosis</code></pre><pre><code class="language-none">Turing.location</code></pre><pre><code class="language-none">Turing.location!</code></pre><pre><code class="language-none">Turing.logccdf</code></pre><pre><code class="language-none">Turing.logcdf</code></pre><pre><code class="language-none">Turing.logdetcov</code></pre><pre><code class="language-none">Turing.loglikelihood</code></pre><pre><code class="language-none">Turing.logpdf</code></pre><pre><code class="language-none">Turing.logpdf!</code></pre><pre><code class="language-none">Turing.mean</code></pre><pre><code class="language-none">Turing.meandir</code></pre><pre><code class="language-none">Turing.meanform</code></pre><pre><code class="language-none">Turing.meanlogx</code></pre><pre><code class="language-none">Turing.meanplot</code></pre><pre><code class="language-none">Turing.meanplot!</code></pre><pre><code class="language-none">Turing.median</code></pre><pre><code class="language-none">Turing.mgf</code></pre><pre><code class="language-none">Turing.mixeddensity</code></pre><pre><code class="language-none">Turing.mixeddensity!</code></pre><pre><code class="language-none">Turing.mixeddensityplot</code></pre><pre><code class="language-none">Turing.mode</code></pre><pre><code class="language-none">Turing.modes</code></pre><pre><code class="language-none">Turing.moment</code></pre><pre><code class="language-none">Turing.ncategories</code></pre><pre><code class="language-none">Turing.ncomponents</code></pre><pre><code class="language-none">Turing.nsamples</code></pre><pre><code class="language-none">Turing.ntrials</code></pre><pre><code class="language-none">Turing.params</code></pre><pre><code class="language-none">Turing.params!</code></pre><pre><code class="language-none">Turing.partype</code></pre><pre><code class="language-none">Turing.pdf</code></pre><pre><code class="language-none">Turing.plot</code></pre><pre><code class="language-none">Turing.probs</code></pre><pre><code class="language-none">Turing.probval</code></pre><pre><code class="language-none">Turing.produce</code></pre><pre><code class="language-none">Turing.qqbuild</code></pre><pre><code class="language-none">Turing.quantile</code></pre><pre><code class="language-none">Turing.rafterydiag</code></pre><pre><code class="language-none">Turing.rate</code></pre><pre><code class="language-none">Turing.resume</code></pre><pre><code class="language-none">Turing.runmodel!</code></pre><pre><code class="language-none">Turing.sample</code></pre><pre><code class="language-none">Turing.sample!</code></pre><pre><code class="language-none">Turing.sampler</code></pre><pre><code class="language-none">Turing.scale</code></pre><pre><code class="language-none">Turing.scale!</code></pre><pre><code class="language-none">Turing.setadbackend</code></pre><pre><code class="language-none">Turing.setadsafe</code></pre><pre><code class="language-none">Turing.setchunksize</code></pre><pre><code class="language-none">Turing.setindex!</code></pre><pre><code class="language-none">Turing.shape</code></pre><pre><code class="language-none">Turing.skewness</code></pre><pre><code class="language-none">Turing.span</code></pre><pre><code class="language-none">Turing.sqmahal</code></pre><pre><code class="language-none">Turing.sqmahal!</code></pre><pre><code class="language-none">Turing.std</code></pre><pre><code class="language-none">Turing.stdlogx</code></pre><pre><code class="language-none">Turing.succprob</code></pre><pre><code class="language-none">Turing.suffstats</code></pre><pre><code class="language-none">Turing.support</code></pre><pre><code class="language-none">Turing.test_distr</code></pre><pre><code class="language-none">Turing.test_samples</code></pre><pre><code class="language-none">Turing.tfill</code></pre><pre><code class="language-none">Turing.traceplot</code></pre><pre><code class="language-none">Turing.traceplot!</code></pre><pre><code class="language-none">Turing.turnprogress</code></pre><pre><code class="language-none">Turing.tzeros</code></pre><pre><code class="language-none">Turing.var</code></pre><pre><code class="language-none">Turing.varlogx</code></pre><pre><code class="language-none">Turing.wsample</code></pre><pre><code class="language-none">Turing.wsample!</code></pre><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>
