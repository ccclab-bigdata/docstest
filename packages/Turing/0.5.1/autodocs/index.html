<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · Turing.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Turing.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><pre><code class="language-none">Turing.+</code></pre><pre><code class="language-none">Turing.-</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.@VarName" href="#Turing.@VarName"><code>Turing.@VarName</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><p>Usage: @VarName x[1,2][1+5][45][3]   return: (:x,[1,2],6,45,3)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.@model" href="#Turing.@model"><code>Turing.@model</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><pre><code class="language-none">@model(name, fbody)</code></pre><p>Macro to specify a probabilistic model.</p><p>Example:</p><pre><code class="language-julia">@model Gaussian(x) = begin
    s ~ InverseGamma(2,3)
    m ~ Normal(0,sqrt.(s))
    for i in 1:length(x)
        x[i] ~ Normal(m, sqrt.(s))
    end
    return (s, m)
end</code></pre><p>Compiler design: <code>sample(fname(x,y), sampler)</code>.</p><pre><code class="language-julia">fname(x=nothing,y=nothing; compiler=compiler) = begin
    ex = quote
        # Pour in kwargs for those args where value != nothing.
        fname_model(vi::VarInfo, sampler::Sampler; x = x, y = y) = begin
            vi.logp = zero(Real)
          
            # Pour in model definition.
            x ~ Normal(0,1)
            y ~ Normal(x, 1)
            return x, y
        end
    end
    return Main.eval(ex)
end</code></pre></div></div></section><pre><code class="language-none">Turing.@sym_str</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.@~" href="#Turing.@~"><code>Turing.@~</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><pre><code class="language-none">macro: @~ var Distribution()</code></pre><p>Tilde notation macro. This macro constructs Turing.observe or Turing.assume calls depending on the left-hand argument. Note that the macro is interconnected with the @model macro and assumes that a <code>compiler</code> struct is available.</p><p>Example:</p><pre><code class="language-julia">@~ x Normal()</code></pre></div></div></section><pre><code class="language-none">Turing.ADBACKEND</code></pre><pre><code class="language-none">Turing.ADSAFE</code></pre><pre><code class="language-none">Turing.AbstractMixtureModel</code></pre><pre><code class="language-none">Turing.AbstractMvNormal</code></pre><pre><code class="language-none">Turing.AbstractSampler</code></pre><pre><code class="language-none">Turing.AnySampler</code></pre><pre><code class="language-none">Turing.Arcsine</code></pre><pre><code class="language-none">Turing.Bernoulli</code></pre><pre><code class="language-none">Turing.Beta</code></pre><pre><code class="language-none">Turing.BetaBinomial</code></pre><pre><code class="language-none">Turing.BetaPrime</code></pre><pre><code class="language-none">Turing.Binomial</code></pre><pre><code class="language-none">Turing.Biweight</code></pre><pre><code class="language-none">Turing.CACHEIDCS</code></pre><pre><code class="language-none">Turing.CACHERANGES</code></pre><pre><code class="language-none">Turing.CACHERESET</code></pre><pre><code class="language-none">Turing.CHUNKSIZE</code></pre><pre><code class="language-none">Turing.CSMC</code></pre><pre><code class="language-none">Turing.Categorical</code></pre><pre><code class="language-none">Turing.Cauchy</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Chain" href="#Turing.Chain"><code>Turing.Chain</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Chain(weight::Float64, value::Array{Sample})</code></pre><p>A wrapper of output trajactory of samplers.</p><p>Example:</p><pre><code class="language-julia"># Define a model
@model xxx begin
  ...
  return(mu,sigma)
end

# Run the inference engine
chain = sample(xxx, SMC(1000))

chain[:logevidence]   # show the log model evidence
chain[:mu]            # show the weighted trajactory for :mu
chain[:sigma]         # show the weighted trajactory for :sigma
mean(chain[:mu])      # find the mean of :mu
mean(chain[:sigma])   # find the mean of :sigma</code></pre></div></div></section><pre><code class="language-none">Turing.Chains</code></pre><pre><code class="language-none">Turing.Chi</code></pre><pre><code class="language-none">Turing.Chisq</code></pre><pre><code class="language-none">Turing.Continuous</code></pre><pre><code class="language-none">Turing.ContinuousDistribution</code></pre><pre><code class="language-none">Turing.ContinuousMatrixDistribution</code></pre><pre><code class="language-none">Turing.ContinuousMultivariateDistribution</code></pre><pre><code class="language-none">Turing.ContinuousUnivariateDistribution</code></pre><pre><code class="language-none">Turing.Cosine</code></pre><pre><code class="language-none">Turing.DEFAULT_ADAPT_CONF_TYPE</code></pre><pre><code class="language-none">Turing.DiagNormal</code></pre><pre><code class="language-none">Turing.DiagNormalCanon</code></pre><pre><code class="language-none">Turing.Dirichlet</code></pre><pre><code class="language-none">Turing.DirichletMultinomial</code></pre><pre><code class="language-none">Turing.Discrete</code></pre><pre><code class="language-none">Turing.DiscreteDistribution</code></pre><pre><code class="language-none">Turing.DiscreteMatrixDistribution</code></pre><pre><code class="language-none">Turing.DiscreteMultivariateDistribution</code></pre><pre><code class="language-none">Turing.DiscreteUniform</code></pre><pre><code class="language-none">Turing.DiscreteUnivariateDistribution</code></pre><pre><code class="language-none">Turing.Distribution</code></pre><pre><code class="language-none">Turing.Distributions</code></pre><pre><code class="language-none">Turing.DoubleExponential</code></pre><pre><code class="language-none">Turing.DynamicNUTS</code></pre><pre><code class="language-none">Turing.EdgeworthMean</code></pre><pre><code class="language-none">Turing.EdgeworthSum</code></pre><pre><code class="language-none">Turing.EdgeworthZ</code></pre><pre><code class="language-none">Turing.EmpiricalUnivariateDistribution</code></pre><pre><code class="language-none">Turing.Epanechnikov</code></pre><pre><code class="language-none">Turing.Erlang</code></pre><pre><code class="language-none">Turing.Estimator</code></pre><pre><code class="language-none">Turing.Exponential</code></pre><pre><code class="language-none">Turing.FDist</code></pre><pre><code class="language-none">Turing.FisherNoncentralHypergeometric</code></pre><pre><code class="language-none">Turing.Flat</code></pre><pre><code class="language-none">Turing.FlatPos</code></pre><pre><code class="language-none">Turing.Frechet</code></pre><pre><code class="language-none">Turing.FullNormal</code></pre><pre><code class="language-none">Turing.FullNormalCanon</code></pre><pre><code class="language-none">Turing.Gamma</code></pre><pre><code class="language-none">Turing.GeneralizedExtremeValue</code></pre><pre><code class="language-none">Turing.GeneralizedPareto</code></pre><pre><code class="language-none">Turing.Geometric</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Gibbs" href="#Turing.Gibbs"><code>Turing.Gibbs</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Gibbs(n_iters, alg_1, alg_2)</code></pre><p>Compositional MCMC interface.</p><p>Example:</p><pre><code class="language-julia">alg = Gibbs(1000, HMC(1, 0.2, 3, :v1), PG(20, 1, :v2))</code></pre></div></div></section><pre><code class="language-none">Turing.GibbsComponent</code></pre><pre><code class="language-none">Turing.Gumbel</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.HMC" href="#Turing.HMC"><code>Turing.HMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">HMC(n_iters::Int, epsilon::Float64, tau::Int)</code></pre><p>Hamiltonian Monte Carlo sampler.</p><p>Usage:</p><pre><code class="language-julia">HMC(1000, 0.05, 10)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
    s ~ InverseGamma(2,3)
    m ~ Normal(0, sqrt(s))
    x[1] ~ Normal(m, sqrt(s))
    x[2] ~ Normal(m, sqrt(s))
    return s, m
end

sample(gdemo([1.5, 2]), HMC(1000, 0.05, 10))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.HMCDA" href="#Turing.HMCDA"><code>Turing.HMCDA</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">HMCDA(n_iters::Int, n_adapt::Int, delta::Float64, lambda::Float64)</code></pre><p>Hamiltonian Monte Carlo sampler wiht Dual Averaging algorithm.</p><p>Usage:</p><pre><code class="language-julia">HMCDA(1000, 200, 0.65, 0.3)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), HMCDA(1000, 200, 0.65, 0.3))</code></pre></div></div></section><pre><code class="language-none">Turing.Hamiltonian</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.HamiltonianRobustInit" href="#Turing.HamiltonianRobustInit"><code>Turing.HamiltonianRobustInit</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Robust initialization method for model parameters in Hamiltonian samplers.</p></div></div></section><pre><code class="language-none">Turing.Hypergeometric</code></pre><pre><code class="language-none">Turing.IArray</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.IPMCMC" href="#Turing.IPMCMC"><code>Turing.IPMCMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">IPMCMC(n_particles::Int, n_iters::Int, n_nodes::Int, n_csmc_nodes::Int)</code></pre><p>Particle Gibbs sampler.</p><p>Usage:</p><pre><code class="language-julia">IPMCMC(100, 100, 4, 2)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0,sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), IPMCMC(100, 100, 4, 2))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.IS" href="#Turing.IS"><code>Turing.IS</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">IS(n_particles::Int)</code></pre><p>Importance sampling algorithm object.</p><ul><li><code>n_particles</code> is the number of particles to use</li></ul><p>Usage:</p><pre><code class="language-julia">IS(1000)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
    s ~ InverseGamma(2,3)
    m ~ Normal(0,sqrt.(s))
    x[1] ~ Normal(m, sqrt.(s))
    x[2] ~ Normal(m, sqrt.(s))
    return s, m
end

sample(gdemo([1.5, 2]), IS(1000))</code></pre></div></div></section><pre><code class="language-none">Turing.InferenceAlgorithm</code></pre><pre><code class="language-none">Turing.InverseGamma</code></pre><pre><code class="language-none">Turing.InverseGaussian</code></pre><pre><code class="language-none">Turing.InverseWishart</code></pre><pre><code class="language-none">Turing.IsoNormal</code></pre><pre><code class="language-none">Turing.IsoNormalCanon</code></pre><pre><code class="language-none">Turing.KSDist</code></pre><pre><code class="language-none">Turing.KSOneSided</code></pre><pre><code class="language-none">Turing.Kolmogorov</code></pre><pre><code class="language-none">Turing.Laplace</code></pre><pre><code class="language-none">Turing.Levy</code></pre><pre><code class="language-none">Turing.LocationScale</code></pre><pre><code class="language-none">Turing.LogNormal</code></pre><pre><code class="language-none">Turing.Logistic</code></pre><pre><code class="language-none">Turing.MCMCChain</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.MH" href="#Turing.MH"><code>Turing.MH</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">MH(n_iters::Int)</code></pre><p>Metropolis-Hasting sampler.</p><p>Usage:</p><pre><code class="language-julia">MH(100, (:m, (x) -&gt; Normal(x, 0.1)))</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0,sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), MH(1000, (:m, (x) -&gt; Normal(x, 0.1)), :s)))</code></pre></div></div></section><pre><code class="language-none">Turing.MLEstimator</code></pre><pre><code class="language-none">Turing.MatrixDistribution</code></pre><pre><code class="language-none">Turing.Matrixvariate</code></pre><pre><code class="language-none">Turing.MixtureModel</code></pre><pre><code class="language-none">Turing.Multinomial</code></pre><pre><code class="language-none">Turing.Multivariate</code></pre><pre><code class="language-none">Turing.MultivariateDistribution</code></pre><pre><code class="language-none">Turing.MultivariateMixture</code></pre><pre><code class="language-none">Turing.MultivariateNormal</code></pre><pre><code class="language-none">Turing.MvLogNormal</code></pre><pre><code class="language-none">Turing.MvNormal</code></pre><pre><code class="language-none">Turing.MvNormalCanon</code></pre><pre><code class="language-none">Turing.MvNormalKnownCov</code></pre><pre><code class="language-none">Turing.MvTDist</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.NUTS" href="#Turing.NUTS"><code>Turing.NUTS</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">NUTS(n_iters::Int, n_adapt::Int, delta::Float64)</code></pre><p>No-U-Turn Sampler (NUTS) sampler.</p><p>Usage:</p><pre><code class="language-julia">NUTS(1000, 200, 0.6j_max)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.j_max, 2]), NUTS(1000, 200, 0.6j_max))</code></pre></div></div></section><pre><code class="language-none">Turing.NegativeBinomial</code></pre><pre><code class="language-none">Turing.NonMatrixDistribution</code></pre><pre><code class="language-none">Turing.NoncentralBeta</code></pre><pre><code class="language-none">Turing.NoncentralChisq</code></pre><pre><code class="language-none">Turing.NoncentralF</code></pre><pre><code class="language-none">Turing.NoncentralHypergeometric</code></pre><pre><code class="language-none">Turing.NoncentralT</code></pre><pre><code class="language-none">Turing.Normal</code></pre><pre><code class="language-none">Turing.NormalCanon</code></pre><pre><code class="language-none">Turing.NormalInverseGaussian</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.PG" href="#Turing.PG"><code>Turing.PG</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PG(n_particles::Int, n_iters::Int)</code></pre><p>Particle Gibbs sampler.</p><p>Usage:</p><pre><code class="language-julia">PG(100, 100)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), PG(100, 100))</code></pre></div></div></section><pre><code class="language-none">Turing.PIMH</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.PMMH" href="#Turing.PMMH"><code>Turing.PMMH</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">PMMH(n_iters::Int, smc_alg:::SMC, parameters_algs::Tuple{MH})</code></pre><p>Particle independant Metropolis–Hastings and Particle marginal Metropolis–Hastings samplers.</p><p>Usage:</p><pre><code class="language-julia">alg = PMMH(100, SMC(20, :v1), MH(1,:v2))
alg = PMMH(100, SMC(20, :v1), MH(1,(:v2, (x) -&gt; Normal(x, 1))))</code></pre></div></div></section><pre><code class="language-none">Turing.PROGRESS</code></pre><pre><code class="language-none">Turing.Pareto</code></pre><pre><code class="language-none">Turing.Particle</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.ParticleContainer" href="#Turing.ParticleContainer"><code>Turing.ParticleContainer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Data structure for particle filters</p><ul><li>effectiveSampleSize(pc :: ParticleContainer)</li><li>normalise!(pc::ParticleContainer)</li><li>consume(pc::ParticleContainer): return incremental likelihood</li></ul></div></div></section><pre><code class="language-none">Turing.Poisson</code></pre><pre><code class="language-none">Turing.PoissonBinomial</code></pre><pre><code class="language-none">Turing.QQPair</code></pre><pre><code class="language-none">Turing.Rayleigh</code></pre><pre><code class="language-none">Turing.RealInterval</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.SGHMC" href="#Turing.SGHMC"><code>Turing.SGHMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SGHMC(n_iters::Int, learning_rate::Float64, momentum_decay::Float64)</code></pre><p>Stochastic Gradient Hamiltonian Monte Carlo sampler.</p><p>Usage:</p><pre><code class="language-julia">SGHMC(1000, 0.01, 0.1)</code></pre><p>Example:</p><pre><code class="language-julia">@model example begin
  ...
end

sample(example, SGHMC(1000, 0.01, 0.1))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.SGLD" href="#Turing.SGLD"><code>Turing.SGLD</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SGLD(n_iters::Int, step_size::Float64)</code></pre><p>Stochastic Gradient Langevin Dynamics sampler.</p><p>Usage:</p><pre><code class="language-julia">SGLD(1000, 0.5)</code></pre><p>Example:</p><pre><code class="language-julia">@model example begin
  ...
end

sample(example, SGLD(1000, 0.5))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.SMC" href="#Turing.SMC"><code>Turing.SMC</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">SMC(n_particles::Int)</code></pre><p>Sequential Monte Carlo sampler.</p><p>Usage:</p><pre><code class="language-julia">SMC(1000)</code></pre><p>Example:</p><pre><code class="language-julia"># Define a simple Normal model with unknown mean and variance.
@model gdemo(x) = begin
  s ~ InverseGamma(2,3)
  m ~ Normal(0, sqrt(s))
  x[1] ~ Normal(m, sqrt(s))
  x[2] ~ Normal(m, sqrt(s))
  return s, m
end

sample(gdemo([1.5, 2]), SMC(1000))</code></pre></div></div></section><pre><code class="language-none">Turing.STAN_DEFAULT_ADAPT_CONF</code></pre><pre><code class="language-none">Turing.Sample</code></pre><pre><code class="language-none">Turing.SampleFromPrior</code></pre><pre><code class="language-none">Turing.Sampleable</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.Sampler" href="#Turing.Sampler"><code>Turing.Sampler</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Sampler{T}</code></pre><p>Generic interface for implementing inference algorithms. An implementation of an algorithm should include the following:</p><ol><li>A type specifying the algorithm and its parameters, derived from InferenceAlgorithm</li><li>A method of <code>sample</code> function that produces results of inference, which is where actual inference happens.</li></ol><p>Turing translates models to chunks that call the modelling functions at specified points. The dispatch is based on the value of a <code>sampler</code> variable. To include a new inference algorithm implements the requirements mentioned above in a separate file, then include that file at the end of this one.</p></div></div></section><pre><code class="language-none">Turing.Semicircle</code></pre><pre><code class="language-none">Turing.Skellam</code></pre><pre><code class="language-none">Turing.SufficientStats</code></pre><pre><code class="language-none">Turing.SymTriangularDist</code></pre><pre><code class="language-none">Turing.TArray</code></pre><pre><code class="language-none">Turing.TDist</code></pre><pre><code class="language-none">Turing.Trace</code></pre><pre><code class="language-none">Turing.Transformable</code></pre><pre><code class="language-none">Turing.TriangularDist</code></pre><pre><code class="language-none">Turing.Triweight</code></pre><pre><code class="language-none">Turing.Truncated</code></pre><pre><code class="language-none">Turing.TruncatedNormal</code></pre><pre><code class="language-none">Turing.Turing</code></pre><pre><code class="language-none">Turing.Uniform</code></pre><pre><code class="language-none">Turing.Univariate</code></pre><pre><code class="language-none">Turing.UnivariateDistribution</code></pre><pre><code class="language-none">Turing.UnivariateGMM</code></pre><pre><code class="language-none">Turing.UnivariateMixture</code></pre><pre><code class="language-none">Turing.ValueSupport</code></pre><pre><code class="language-none">Turing.VarEstimator</code></pre><pre><code class="language-none">Turing.VarReplay</code></pre><pre><code class="language-none">Turing.VariateForm</code></pre><pre><code class="language-none">Turing.VonMises</code></pre><pre><code class="language-none">Turing.VonMisesFisher</code></pre><pre><code class="language-none">Turing.WalleniusNoncentralHypergeometric</code></pre><pre><code class="language-none">Turing.WarmUpManager</code></pre><pre><code class="language-none">Turing.Weibull</code></pre><pre><code class="language-none">Turing.Wishart</code></pre><pre><code class="language-none">Turing.ZeroMeanDiagNormal</code></pre><pre><code class="language-none">Turing.ZeroMeanDiagNormalCanon</code></pre><pre><code class="language-none">Turing.ZeroMeanFullNormal</code></pre><pre><code class="language-none">Turing.ZeroMeanFullNormalCanon</code></pre><pre><code class="language-none">Turing.ZeroMeanIsoNormal</code></pre><pre><code class="language-none">Turing.ZeroMeanIsoNormalCanon</code></pre><pre><code class="language-none">Turing.__init__</code></pre><pre><code class="language-none">Turing.__inits__</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing._build_tree" href="#Turing._build_tree"><code>Turing._build_tree</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>function <em>build</em>tree(θ::T, r::AbstractVector, logu::AbstractFloat, v::Int, j::Int, ϵ::AbstractFloat,                        H0::AbstractFloat,lj<em>func::Function, grad</em>func::Function, stds::AbstractVector;                        Δ_max::AbstractFloat=1000) where {T&lt;:Union{Vector,SubArray}}</p><p>Recursively build balanced tree.</p><p>Ref: Algorithm 6 on http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf</p><p>Arguments:</p><ul><li><code>θ</code>         : model parameter</li><li><code>r</code>         : momentum variable</li><li><code>logu</code>      : slice variable (in log scale)</li><li><code>v</code>         : direction ∈ {-1, 1}</li><li><code>j</code>         : depth of tree</li><li><code>ϵ</code>         : leapfrog step size</li><li><code>H0</code>        : initial H</li><li><code>lj_func</code>   : function for log-joint</li><li><code>grad_func</code> : function for the gradient of log-joint</li><li><code>stds</code>      : pre-conditioning matrix</li><li><code>Δ_max</code>     : threshold for exploeration error tolerance</li></ul></div></div></section><pre><code class="language-none">Turing._find_H</code></pre><pre><code class="language-none">Turing._hmc_step</code></pre><pre><code class="language-none">Turing._leapfrog</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing._nuts_step" href="#Turing._nuts_step"><code>Turing._nuts_step</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>function <em>nuts</em>step(θ::T, ϵ::AbstractFloat, lj<em>func::Function, grad</em>func::Function, stds::AbstractVector;                       j<em>max::Int=j</em>max) where {T&lt;:Union{AbstractVector,SubArray}}</p><p>Perform one NUTS step.</p><p>Ref: Algorithm 6 on http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf</p><p>Arguments:</p><ul><li><code>θ</code>         : model parameter</li><li><code>ϵ</code>         : leapfrog step size</li><li><code>lj_func</code>   : function for log-joint</li><li><code>grad_func</code> : function for the gradient of log-joint</li><li><code>stds</code>      : pre-conditioning matrix</li><li><code>j_max</code>     : maximum expanding of doubling tree</li></ul></div></div></section><pre><code class="language-none">Turing._sample_momentum</code></pre><pre><code class="language-none">Turing.adapt!</code></pre><pre><code class="language-none">Turing.adapt_step_size!</code></pre><pre><code class="language-none">Turing.add_sample!</code></pre><pre><code class="language-none">Turing.assume</code></pre><pre><code class="language-none">Turing.autcorplot</code></pre><pre><code class="language-none">Turing.auto_tune_chunk_size!</code></pre><pre><code class="language-none">Turing.autocorplot</code></pre><pre><code class="language-none">Turing.autocorplot!</code></pre><pre><code class="language-none">Turing.binaryentropy</code></pre><pre><code class="language-none">Turing.canonform</code></pre><pre><code class="language-none">Turing.ccdf</code></pre><pre><code class="language-none">Turing.cdf</code></pre><pre><code class="language-none">Turing.cf</code></pre><pre><code class="language-none">Turing.cgf</code></pre><pre><code class="language-none">Turing.circvar</code></pre><pre><code class="language-none">Turing.component</code></pre><pre><code class="language-none">Turing.components</code></pre><pre><code class="language-none">Turing.componentwise_logpdf</code></pre><pre><code class="language-none">Turing.componentwise_pdf</code></pre><pre><code class="language-none">Turing.compute_next_window</code></pre><pre><code class="language-none">Turing.concentration</code></pre><pre><code class="language-none">Turing.consume</code></pre><pre><code class="language-none">Turing.cor</code></pre><pre><code class="language-none">Turing.corner</code></pre><pre><code class="language-none">Turing.corner!</code></pre><pre><code class="language-none">Turing.cov</code></pre><pre><code class="language-none">Turing.cquantile</code></pre><pre><code class="language-none">Turing.cumulant</code></pre><pre><code class="language-none">Turing.current_trace</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.data" href="#Turing.data"><code>Turing.data</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">data(dict::Dict, keys::Vector{Symbol})</code></pre><p>Construct a tuple with values filled according to <code>dict</code> and keys according to <code>keys</code>.</p></div></div></section><pre><code class="language-none">Turing.data_insertion</code></pre><pre><code class="language-none">Turing.densityplot</code></pre><pre><code class="language-none">Turing.describe</code></pre><pre><code class="language-none">Turing.dim</code></pre><pre><code class="language-none">Turing.discretediag</code></pre><pre><code class="language-none">Turing.dof</code></pre><pre><code class="language-none">Turing.effectiveSampleSize</code></pre><pre><code class="language-none">Turing.entropy</code></pre><pre><code class="language-none">Turing.estimate</code></pre><pre><code class="language-none">Turing.eval</code></pre><pre><code class="language-none">Turing.expected_logdet</code></pre><pre><code class="language-none">Turing.failprob</code></pre><pre><code class="language-none">Turing.find_H</code></pre><pre><code class="language-none">Turing.find_good_eps</code></pre><pre><code class="language-none">Turing.fit</code></pre><pre><code class="language-none">Turing.fit_map</code></pre><pre><code class="language-none">Turing.fit_map!</code></pre><pre><code class="language-none">Turing.fit_mle</code></pre><pre><code class="language-none">Turing.fit_mle!</code></pre><pre><code class="language-none">Turing.flatten</code></pre><pre><code class="language-none">Turing.flatten!</code></pre><pre><code class="language-none">Turing.fork</code></pre><pre><code class="language-none">Turing.forkr</code></pre><pre><code class="language-none">Turing.freecumulant</code></pre><pre><code class="language-none">Turing.gelmandiag</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.gen_grad_func" href="#Turing.gen_grad_func"><code>Turing.gen_grad_func</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">gen_grad_func(vi::VarInfo, sampler::Sampler, model)</code></pre><p>Generate a function that takes a vector of reals <code>θ</code> and compute the logpdf and gradient at <code>θ</code> for the model specified by <code>(vi, sampler, model)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.gen_lj_func" href="#Turing.gen_lj_func"><code>Turing.gen_lj_func</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">gen_lj_func(vi::VarInfo, sampler::Sampler, model)</code></pre><p>Generate a function that takes <code>θ</code> and returns logpdf at <code>θ</code> for the model specified by <code>(vi, sampler, model)</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.gen_log_func" href="#Turing.gen_log_func"><code>Turing.gen_log_func</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">gen_log_func(sampler::Sampler)</code></pre><p>Generate a function that takes no argument and performs logging for the number of leapfrog steps used in <code>sampler</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.gen_rev_func" href="#Turing.gen_rev_func"><code>Turing.gen_rev_func</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>gen<em>rev</em>func(vi::VarInfo, sampler::Sampler)</p><p>Generate a function on <code>(θ, logp)</code> that sets the variables referenced by <code>sampler</code> to <code>θ</code> and the current <code>vi.logp</code> to <code>logp</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.generate_assume" href="#Turing.generate_assume"><code>Turing.generate_assume</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">generate_assume(variable, distribution, syms)</code></pre><p>Generate an assume expression.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.generate_observe" href="#Turing.generate_observe"><code>Turing.generate_observe</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">generate_observe(observation, distribution)</code></pre><p>Generate an observe expression.</p></div></div></section><pre><code class="language-none">Turing.get_var</code></pre><pre><code class="language-none">Turing.getindex</code></pre><pre><code class="language-none">Turing.getjuliatype</code></pre><pre><code class="language-none">Turing.getsample</code></pre><pre><code class="language-none">Turing.getvsym</code></pre><pre><code class="language-none">Turing.gewekediag</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.gradient_forward" href="#Turing.gradient_forward"><code>Turing.gradient_forward</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>gradient<em>forward(     θ::AbstractVector{&lt;:Real},     vi::VarInfo,     model::Function,     spl::Union{Nothing, Sampler}=nothing,     chunk</em>size::Int=CHUNKSIZE[], )</p><p>Computes the gradient of the log joint of <code>θ</code> for the model specified by <code>(vi, spl, model)</code> using forwards-mode AD from ForwardDiff.jl.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.gradient_reverse" href="#Turing.gradient_reverse"><code>Turing.gradient_reverse</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>gradient_reverse(     θ::AbstractVector{&lt;:Real},     vi::VarInfo,     model::Function,     sampler::Union{Nothing, Sampler}=nothing, )</p><p>Computes the gradient of the log joint of <code>θ</code> for the model specified by <code>(vi, sampler, model)</code> using reverse-mode AD from Flux.jl.</p></div></div></section><pre><code class="language-none">Turing.gradlogpdf</code></pre><pre><code class="language-none">Turing.hasfinitesupport</code></pre><pre><code class="language-none">Turing.heideldiag</code></pre><pre><code class="language-none">Turing.histogramplot</code></pre><pre><code class="language-none">Turing.in_adaptation</code></pre><pre><code class="language-none">Turing.include</code></pre><pre><code class="language-none">Turing.increase_logevidence</code></pre><pre><code class="language-none">Turing.increase_logweight</code></pre><pre><code class="language-none">Turing.ind2sub</code></pre><pre><code class="language-none">Turing.init</code></pre><pre><code class="language-none">Turing.init_warm_up_params</code></pre><pre><code class="language-none">Turing.inittrans</code></pre><pre><code class="language-none">Turing.insupport</code></pre><pre><code class="language-none">Turing.invcov</code></pre><pre><code class="language-none">Turing.invlogccdf</code></pre><pre><code class="language-none">Turing.invlogcdf</code></pre><pre><code class="language-none">Turing.invscale</code></pre><pre><code class="language-none">Turing.is_window_end</code></pre><pre><code class="language-none">Turing.isbounded</code></pre><pre><code class="language-none">Turing.isleptokurtic</code></pre><pre><code class="language-none">Turing.islowerbounded</code></pre><pre><code class="language-none">Turing.ismesokurtic</code></pre><pre><code class="language-none">Turing.isplatykurtic</code></pre><pre><code class="language-none">Turing.isprobvec</code></pre><pre><code class="language-none">Turing.isupperbounded</code></pre><pre><code class="language-none">Turing.kde</code></pre><pre><code class="language-none">Turing.kurtosis</code></pre><pre><code class="language-none">Turing.leapfrog</code></pre><pre><code class="language-none">Turing.localcopy</code></pre><pre><code class="language-none">Turing.location</code></pre><pre><code class="language-none">Turing.location!</code></pre><pre><code class="language-none">Turing.logccdf</code></pre><pre><code class="language-none">Turing.logcdf</code></pre><pre><code class="language-none">Turing.logdetcov</code></pre><pre><code class="language-none">Turing.loglikelihood</code></pre><pre><code class="language-none">Turing.logpdf</code></pre><pre><code class="language-none">Turing.logpdf!</code></pre><pre><code class="language-none">Turing.mean</code></pre><pre><code class="language-none">Turing.meandir</code></pre><pre><code class="language-none">Turing.meanform</code></pre><pre><code class="language-none">Turing.meanlogx</code></pre><pre><code class="language-none">Turing.meanplot</code></pre><pre><code class="language-none">Turing.meanplot!</code></pre><pre><code class="language-none">Turing.median</code></pre><pre><code class="language-none">Turing.mgf</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Turing.mh_accept" href="#Turing.mh_accept"><code>Turing.mh_accept</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">mh_accept(H::Real, H_new::Real)
mh_accept(H::Real, H_new::Real, log_proposal_ratio::Real)</code></pre><p>Peform MH accept criteria. Returns a boolean for whether or not accept and the  acceptance ratio in log space.</p></div></div></section><pre><code class="language-none">Turing.mixeddensity</code></pre><pre><code class="language-none">Turing.mixeddensity!</code></pre><pre><code class="language-none">Turing.mixeddensityplot</code></pre><pre><code class="language-none">Turing.mode</code></pre><pre><code class="language-none">Turing.modes</code></pre><pre><code class="language-none">Turing.moment</code></pre><pre><code class="language-none">Turing.ncategories</code></pre><pre><code class="language-none">Turing.ncomponents</code></pre><pre><code class="language-none">Turing.nsamples</code></pre><pre><code class="language-none">Turing.ntrials</code></pre><pre><code class="language-none">Turing.observe</code></pre><pre><code class="language-none">Turing.params</code></pre><pre><code class="language-none">Turing.params!</code></pre><pre><code class="language-none">Turing.partype</code></pre><pre><code class="language-none">Turing.pdf</code></pre><pre><code class="language-none">Turing.plot</code></pre><pre><code class="language-none">Turing.probs</code></pre><pre><code class="language-none">Turing.probval</code></pre><pre><code class="language-none">Turing.produce</code></pre><pre><code class="language-none">Turing.propose</code></pre><pre><code class="language-none">Turing.qqbuild</code></pre><pre><code class="language-none">Turing.quantile</code></pre><pre><code class="language-none">Turing.rafterydiag</code></pre><pre><code class="language-none">Turing.randcat</code></pre><pre><code class="language-none">Turing.randrealuni</code></pre><pre><code class="language-none">Turing.rate</code></pre><pre><code class="language-none">Turing.reconstruct</code></pre><pre><code class="language-none">Turing.reconstruct!</code></pre><pre><code class="language-none">Turing.require_gradient</code></pre><pre><code class="language-none">Turing.require_particles</code></pre><pre><code class="language-none">Turing.resample</code></pre><pre><code class="language-none">Turing.resample!</code></pre><pre><code class="language-none">Turing.resampleMultinomial</code></pre><pre><code class="language-none">Turing.resampleResidual</code></pre><pre><code class="language-none">Turing.resampleStratified</code></pre><pre><code class="language-none">Turing.resampleSystematic</code></pre><pre><code class="language-none">Turing.reset!</code></pre><pre><code class="language-none">Turing.restart_da</code></pre><pre><code class="language-none">Turing.resume</code></pre><pre><code class="language-none">Turing.runmodel!</code></pre><pre><code class="language-none">Turing.sample</code></pre><pre><code class="language-none">Turing.sample!</code></pre><pre><code class="language-none">Turing.sample_momentum</code></pre><pre><code class="language-none">Turing.sampler</code></pre><pre><code class="language-none">Turing.save!</code></pre><pre><code class="language-none">Turing.scale</code></pre><pre><code class="language-none">Turing.scale!</code></pre><pre><code class="language-none">Turing.setadbackend</code></pre><pre><code class="language-none">Turing.setadsafe</code></pre><pre><code class="language-none">Turing.setchunksize</code></pre><pre><code class="language-none">Turing.setindex!</code></pre><pre><code class="language-none">Turing.setkwargs</code></pre><pre><code class="language-none">Turing.shape</code></pre><pre><code class="language-none">Turing.skewness</code></pre><pre><code class="language-none">Turing.span</code></pre><pre><code class="language-none">Turing.sqmahal</code></pre><pre><code class="language-none">Turing.sqmahal!</code></pre><pre><code class="language-none">Turing.std</code></pre><pre><code class="language-none">Turing.stdlogx</code></pre><pre><code class="language-none">Turing.step</code></pre><pre><code class="language-none">Turing.succprob</code></pre><pre><code class="language-none">Turing.suffstats</code></pre><pre><code class="language-none">Turing.support</code></pre><pre><code class="language-none">Turing.test_distr</code></pre><pre><code class="language-none">Turing.test_samples</code></pre><pre><code class="language-none">Turing.tilde</code></pre><pre><code class="language-none">Turing.traceplot</code></pre><pre><code class="language-none">Turing.traceplot!</code></pre><pre><code class="language-none">Turing.translate</code></pre><pre><code class="language-none">Turing.translate!</code></pre><pre><code class="language-none">Turing.turnprogress</code></pre><pre><code class="language-none">Turing.tzeros</code></pre><pre><code class="language-none">Turing.update_da_μ</code></pre><pre><code class="language-none">Turing.update_pre_cond!</code></pre><pre><code class="language-none">Turing.var</code></pre><pre><code class="language-none">Turing.var_tuple</code></pre><pre><code class="language-none">Turing.varlogx</code></pre><pre><code class="language-none">Turing.vectorize</code></pre><pre><code class="language-none">Turing.verifygrad</code></pre><pre><code class="language-none">Turing.weights</code></pre><pre><code class="language-none">Turing.wsample</code></pre><pre><code class="language-none">Turing.wsample!</code></pre><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>
