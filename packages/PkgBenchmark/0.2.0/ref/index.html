<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · PkgBenchmark.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>PkgBenchmark.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><a class="toctext" href="../define_benchmarks/">Defining a benchmark suite</a></li><li><a class="toctext" href="../run_benchmarks/">Running a benchmark suite</a></li><li><a class="toctext" href="../comparing_commits/">Comparing commits</a></li><li><a class="toctext" href="../export_markdown/">Export to markdown</a></li><li class="current"><a class="toctext" href>Reference</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Reference</a></li></ul></nav><hr/><div id="topbar"><span>Reference</span><a class="fa fa-bars" href="#"></a></div></header><ul><li><a href="#PkgBenchmark.BenchmarkConfig"><code>PkgBenchmark.BenchmarkConfig</code></a></li><li><a href="#PkgBenchmark.BenchmarkConfig-Tuple{}"><code>PkgBenchmark.BenchmarkConfig</code></a></li><li><a href="#PkgBenchmark.BenchmarkJudgement"><code>PkgBenchmark.BenchmarkJudgement</code></a></li><li><a href="#PkgBenchmark.benchmarkpkg"><code>PkgBenchmark.benchmarkpkg</code></a></li><li><a href="#PkgBenchmark.export_markdown-Tuple{String,BenchmarkResults}"><code>PkgBenchmark.export_markdown</code></a></li><li><a href="#PkgBenchmark.readresults-Tuple{String}"><code>PkgBenchmark.readresults</code></a></li><li><a href="#PkgBenchmark.writeresults-Tuple{String,BenchmarkResults}"><code>PkgBenchmark.writeresults</code></a></li></ul><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PkgBenchmark.BenchmarkConfig" href="#PkgBenchmark.BenchmarkConfig"><code>PkgBenchmark.BenchmarkConfig</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">BenchmarkConfig</code></pre><p>A <code>BenchmarkConfig</code> contains the configuration for the benchmarks to be executed by <a href="../run_benchmarks/#PkgBenchmark.benchmarkpkg"><code>benchmarkpkg</code></a>.</p><p>This includes the following:</p><ul><li>The commit of the package the benchmarks are run on.</li><li>What julia command should be run, i.e. the path to the Julia executable and the command flags used (e.g. optimization level with <code>-O</code>).</li><li>Custom environment variables (e.g. <code>JULIA_NUM_THREADS</code>).</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PkgBenchmark.BenchmarkConfig-Tuple{}" href="#PkgBenchmark.BenchmarkConfig-Tuple{}"><code>PkgBenchmark.BenchmarkConfig</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">BenchmarkConfig(;id::Union{String, Nothing} = nothing,
                 juliacmd::Cmd = `joinpath(Sys.BINDIR, Base.julia_exename())`,
                 env::Dict{String, Any} = Dict{String, Any}())</code></pre><p>Creates a <code>BenchmarkConfig</code> from the following keyword arguments:</p><ul><li><code>id</code> - A git identifier like a commit, branch, tag, &quot;HEAD&quot;, &quot;HEAD~1&quot; etc.        If <code>id == nothing</code> then benchmark will be done on the current state        of the repo (even if it is dirty).</li><li><code>juliacmd</code> - Used to exectue the benchmarks, defaults to the julia executable              that the Pkgbenchmark-functions are called from. Can also include command flags.</li><li><code>env</code> - Contains custom environment variables that will be active when the         benchmarks are run.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia">julia&gt; using Pkgbenchmark

julia&gt; BenchmarkConfig(id = &quot;performance_improvements&quot;,
                       juliacmd = `julia -O3`,
                       env = Dict(&quot;JULIA_NUM_THREADS&quot; =&gt; 4))
BenchmarkConfig:
    id: performance_improvements
    juliacmd: `julia -O3`
    env: JULIA_NUM_THREADS =&gt; 4</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PkgBenchmark.BenchmarkJudgement" href="#PkgBenchmark.BenchmarkJudgement"><code>PkgBenchmark.BenchmarkJudgement</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Stores the results from running a judgement, see <a href="../comparing_commits/#BenchmarkTools.judge"><code>judge</code></a>.</p><p>The following (unexported) methods are defined on a <code>BenchmarkJudgement</code> (written below as <code>judgement</code>):</p><ul><li><code>target_result(judgement)::BenchmarkResults</code> - the <a href="../run_benchmarks/#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a> of the <code>target</code>.</li><li><code>baseline_result(judgement)::BenchmarkResults</code> -  the <a href="../run_benchmarks/#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a> of the <code>baseline</code>.</li><li><code>benchmarkgroup(judgement)::BenchmarkGroup</code> - a <a href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/master/doc/manual.md#the-benchmarkgroup-type"><code>BenchmarkGroup</code></a>  contaning the estimated results</li></ul><p>A <code>BenchmarkJudgement</code> can be exported to markdown using the function <a href="../export_markdown/#PkgBenchmark.export_markdown"><code>export_markdown</code></a>.</p><p>See also <a href="../run_benchmarks/#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BenchmarkTools.judge" href="#BenchmarkTools.judge"><code>BenchmarkTools.judge</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">judge(target::BenchmarkResults, baseline::BenchmarkResults, f;
      judgekwargs = Dict())</code></pre><p>Judges the two <a href="../run_benchmarks/#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a> in <code>target</code> and <code>baseline</code> using the function <code>f</code>.</p><p><strong>Return value</strong></p><p>Returns a <a href="../ref/#PkgBenchmark.BenchmarkJudgement"><code>BenchmarkJudgement</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BenchmarkTools.judge-Tuple{String,Union{String, BenchmarkConfig},Union{String, BenchmarkConfig}}" href="#BenchmarkTools.judge-Tuple{String,Union{String, BenchmarkConfig},Union{String, BenchmarkConfig}}"><code>BenchmarkTools.judge</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">judge(pkg::String,
      [target]::Union{String, BenchmarkConfig},
      baseline::Union{String, BenchmarkConfig};
      kwargs...)</code></pre><p><strong>Arguments</strong>:</p><ul><li><code>pkg</code> - The path to the package to benchmark, use <code>pathof(Package)</code></li><li><code>target</code> - What do judge, given as a git id or a <a href="../ref/#PkgBenchmark.BenchmarkConfig"><code>BenchmarkConfig</code></a>. If skipped, use the current state of the package repo.</li><li><code>baseline</code> - The commit / <a href="../ref/#PkgBenchmark.BenchmarkConfig"><code>BenchmarkConfig</code></a> to compare <code>target</code> against.</li></ul><p><strong>Keyword arguments</strong>:</p><ul><li><code>f</code> - Estimator function to use in the <a href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/master/doc/manual.md#trialratio-and-trialjudgement">judging</a>.</li><li><code>judgekwargs::Dict{Symbol, Any}</code> - keyword arguments to pass to the <code>judge</code> function in BenchmarkTools</li></ul><p>The remaining keyword arguments are passed to <a href="../run_benchmarks/#PkgBenchmark.benchmarkpkg"><code>benchmarkpkg</code></a></p><p><strong>Return value</strong>:</p><p>Returns a <a href="../ref/#PkgBenchmark.BenchmarkJudgement"><code>BenchmarkJudgement</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PkgBenchmark.benchmarkpkg" href="#PkgBenchmark.benchmarkpkg"><code>PkgBenchmark.benchmarkpkg</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">benchmarkpkg(pkg, [target]::Union{String, BenchmarkConfig}; kwargs...)</code></pre><p>Run a benchmark on the package <code>pkg</code> using the <a href="../ref/#PkgBenchmark.BenchmarkConfig"><code>BenchmarkConfig</code></a> or git identifier <code>target</code>. Examples of git identifiers are commit shas, branch names, or e.g. &quot;HEAD~1&quot;. Return a <a href="#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a>.</p><p>The argument <code>pkg</code> can be a name of a package or a path to a directory to a package.</p><p><strong>Keyword arguments</strong>:</p><ul><li><code>script</code> - The script with the benchmarks, if not given, defaults to <code>benchmark/benchmarks.jl</code> in the package folder.</li><li><code>resultfile</code> - If set, saves the output to <code>resultfile</code></li><li><code>retune</code> - Force a re-tune, saving the new tuning to the tune file.</li></ul><p>The result can be used by functions such as <a href="../comparing_commits/#BenchmarkTools.judge"><code>judge</code></a>. If you choose to, you can save the results manually using <a href="../ref/#PkgBenchmark.writeresults-Tuple{String,BenchmarkResults}"><code>writeresults</code></a> where <code>results</code> is the return value of this function. It can be read back with <a href="../ref/#PkgBenchmark.readresults-Tuple{String}"><code>readresults</code></a>.</p><p><strong>Example invocations:</strong></p><pre><code class="language-julia">using PkgBenchmark

import MyPkg
benchmarkpkg(pathof(MyPkg)) # run the benchmarks at the current state of the repository
benchmarkpkg(pathof(MyPkg), &quot;my-feature&quot;) # run the benchmarks for a particular branch/commit/tag
benchmarkpkg(pathof(MyPkg), &quot;my-feature&quot;; script=&quot;/home/me/mycustombenchmark.jl&quot;)
benchmarkpkg(pathof(MyPkg), BenchmarkConfig(id = &quot;my-feature&quot;,
                                            env = Dict(&quot;JULIA_NUM_THREADS&quot; =&gt; 4),
                                            juliacmd = `julia -O3`))</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PkgBenchmark.export_markdown-Tuple{String,BenchmarkResults}" href="#PkgBenchmark.export_markdown-Tuple{String,BenchmarkResults}"><code>PkgBenchmark.export_markdown</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">export_markdown(file::String, results::Union{BenchmarkResults, BenchmarkJudgement})
export_markdown(io::IO,       results::Union{BenchmarkResults, BenchmarkJudgement})</code></pre><p>Writes the <code>results</code> to <code>file</code> or <code>io</code> in markdown format.</p><p>See also: <a href="../run_benchmarks/#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a>, <a href="../ref/#PkgBenchmark.BenchmarkJudgement"><code>BenchmarkJudgement</code></a></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PkgBenchmark.readresults-Tuple{String}" href="#PkgBenchmark.readresults-Tuple{String}"><code>PkgBenchmark.readresults</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">readresults(file::String)</code></pre><p>Reads the <a href="../run_benchmarks/#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a> stored in <code>file</code> (given as a path).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PkgBenchmark.writeresults-Tuple{String,BenchmarkResults}" href="#PkgBenchmark.writeresults-Tuple{String,BenchmarkResults}"><code>PkgBenchmark.writeresults</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">writeresults(file::String, results::BenchmarkResults)</code></pre><p>Writes the <a href="../run_benchmarks/#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a> to <code>file</code>.</p></div></div></section><footer><hr/><a class="previous" href="../export_markdown/"><span class="direction">Previous</span><span class="title">Export to markdown</span></a></footer></article></body></html>
