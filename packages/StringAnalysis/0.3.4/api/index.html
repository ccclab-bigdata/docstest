<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference Â·   </title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../index.html"><img class="logo" src="../assets/logo.png" alt="   logo"/></a><h1>  </h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Introduction</a></li><li><a class="toctext" href="../examples/">Usage examples</a></li><li class="current"><a class="toctext" href>API Reference</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>API Reference</a></li></ul></nav><hr/><div id="topbar"><span>API Reference</span><a class="fa fa-bars" href="#"></a></div></header><ul><li><a href="#StringAnalysis.StringAnalysis"><code>StringAnalysis.StringAnalysis</code></a></li><li><a href="#StringAnalysis.CooMatrix-Union{Tuple{T}, Tuple{Corpus,Array{String,1}}} where T&lt;:AbstractFloat"><code>StringAnalysis.CooMatrix</code></a></li><li><a href="#StringAnalysis.CooMatrix"><code>StringAnalysis.CooMatrix</code></a></li><li><a href="#StringAnalysis.DocumentTermMatrix"><code>StringAnalysis.DocumentTermMatrix</code></a></li><li><a href="#StringAnalysis.DocumentTermMatrix-Union{Tuple{T}, Tuple{Corpus,Array{String,1}}} where T&lt;:Real"><code>StringAnalysis.DocumentTermMatrix</code></a></li><li><a href="#StringAnalysis.LSAModel"><code>StringAnalysis.LSAModel</code></a></li><li><a href="#StringAnalysis.RPModel"><code>StringAnalysis.RPModel</code></a></li><li><a href="#StringAnalysis.TextHashFunction"><code>StringAnalysis.TextHashFunction</code></a></li><li><a href="#Base.size-Tuple{LSAModel}"><code>Base.size</code></a></li><li><a href="#Base.size-Tuple{RPModel}"><code>Base.size</code></a></li><li><a href="#Base.summary-Tuple{AbstractDocument}"><code>Base.summary</code></a></li><li><a href="#Base.summary-Tuple{Corpus}"><code>Base.summary</code></a></li><li><a href="#StringAnalysis.columnindices"><code>StringAnalysis.columnindices</code></a></li><li><a href="#StringAnalysis.coo_matrix-Union{Tuple{T}, Tuple{Type{T},Array{#s29,1} where #s29&lt;:AbstractString,OrderedDict{#s28,Int64} where #s28&lt;:AbstractString,Int64}, Tuple{Type{T},Array{#s27,1} where #s27&lt;:AbstractString,OrderedDict{#s26,Int64} where #s26&lt;:AbstractString,Int64,Bool}} where T&lt;:AbstractFloat"><code>StringAnalysis.coo_matrix</code></a></li><li><a href="#StringAnalysis.coom-Tuple{CooMatrix}"><code>StringAnalysis.coom</code></a></li><li><a href="#StringAnalysis.coom-Union{Tuple{Any}, Tuple{T}, Tuple{Any,Type{T}}} where T&lt;:AbstractFloat"><code>StringAnalysis.coom</code></a></li><li><a href="#StringAnalysis.cosine"><code>StringAnalysis.cosine</code></a></li><li><a href="#StringAnalysis.dtm-Union{Tuple{Corpus}, Tuple{T}, Tuple{Corpus,Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtm</code></a></li><li><a href="#StringAnalysis.dtm-Tuple{DocumentTermMatrix}"><code>StringAnalysis.dtm</code></a></li><li><a href="#StringAnalysis.dtv-Union{Tuple{T}, Tuple{Any,OrderedDict{String,Int64}}, Tuple{Any,OrderedDict{String,Int64},Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtv</code></a></li><li><a href="#StringAnalysis.dtv-Union{Tuple{T}, Tuple{Corpus,Int64}, Tuple{Corpus,Int64,Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtv</code></a></li><li><a href="#StringAnalysis.dtv_regex-Union{Tuple{T}, Tuple{Any,OrderedDict{String,Int64}}, Tuple{Any,OrderedDict{String,Int64},Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtv_regex</code></a></li><li><a href="#StringAnalysis.each_dtv-Union{Tuple{Corpus}, Tuple{U}} where U&lt;:Real"><code>StringAnalysis.each_dtv</code></a></li><li><a href="#StringAnalysis.each_hash_dtv-Union{Tuple{Corpus}, Tuple{U}} where U&lt;:Real"><code>StringAnalysis.each_hash_dtv</code></a></li><li><a href="#StringAnalysis.embed_document-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},AbstractDocument}} where H where A where T where S"><code>StringAnalysis.embed_document</code></a></li><li><a href="#StringAnalysis.embed_document-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},AbstractDocument}} where H where A where T where S"><code>StringAnalysis.embed_document</code></a></li><li><a href="#StringAnalysis.embed_word-Tuple{LSAModel,Any}"><code>StringAnalysis.embed_word</code></a></li><li><a href="#StringAnalysis.frequent_terms"><code>StringAnalysis.frequent_terms</code></a></li><li><a href="#StringAnalysis.frequent_terms"><code>StringAnalysis.frequent_terms</code></a></li><li><a href="#StringAnalysis.get_vector-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},Any}} where H where A where T where S"><code>StringAnalysis.get_vector</code></a></li><li><a href="#StringAnalysis.get_vector-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},Any}} where H where A where T where S"><code>StringAnalysis.get_vector</code></a></li><li><a href="#StringAnalysis.hash_dtm-Union{Tuple{T}, Tuple{Corpus,TextHashFunction}, Tuple{Corpus,TextHashFunction,Type{T}}} where T&lt;:Real"><code>StringAnalysis.hash_dtm</code></a></li><li><a href="#StringAnalysis.hash_dtv-Union{Tuple{T}, Tuple{Any,TextHashFunction}, Tuple{Any,TextHashFunction,Type{T}}} where T&lt;:Real"><code>StringAnalysis.hash_dtv</code></a></li><li><a href="#StringAnalysis.in_vocabulary-Tuple{LSAModel,AbstractString}"><code>StringAnalysis.in_vocabulary</code></a></li><li><a href="#StringAnalysis.in_vocabulary-Tuple{RPModel,AbstractString}"><code>StringAnalysis.in_vocabulary</code></a></li><li><a href="#StringAnalysis.index-Tuple{LSAModel,Any}"><code>StringAnalysis.index</code></a></li><li><a href="#StringAnalysis.index-Tuple{RPModel,Any}"><code>StringAnalysis.index</code></a></li><li><a href="#StringAnalysis.lda-Tuple{DocumentTermMatrix,Int64,Int64,Float64,Float64}"><code>StringAnalysis.lda</code></a></li><li><a href="#StringAnalysis.load_lsa_model-Union{Tuple{AbstractString}, Tuple{T}, Tuple{AbstractString,Type{T}}} where T&lt;:AbstractFloat"><code>StringAnalysis.load_lsa_model</code></a></li><li><a href="#StringAnalysis.load_rp_model-Union{Tuple{AbstractString}, Tuple{T}, Tuple{AbstractString,Type{T}}} where T&lt;:AbstractFloat"><code>StringAnalysis.load_rp_model</code></a></li><li><a href="#StringAnalysis.lsa-Union{Tuple{DocumentTermMatrix{T}}, Tuple{T}} where T&lt;:AbstractFloat"><code>StringAnalysis.lsa</code></a></li><li><a href="#StringAnalysis.ngrams"><code>StringAnalysis.ngrams</code></a></li><li><a href="#StringAnalysis.ngrams!-Union{Tuple{T}, Tuple{NGramDocument{T},Dict{T,Int64}}} where T&lt;:AbstractString"><code>StringAnalysis.ngrams!</code></a></li><li><a href="#StringAnalysis.random_projection_matrix-Union{Tuple{T}, Tuple{Int64,Int64,Type{T},Float64}} where T&lt;:AbstractFloat"><code>StringAnalysis.random_projection_matrix</code></a></li><li><a href="#StringAnalysis.remove_patterns-Tuple{AbstractString,Regex}"><code>StringAnalysis.remove_patterns</code></a></li><li><a href="#StringAnalysis.remove_patterns!-Tuple{FileDocument,Regex}"><code>StringAnalysis.remove_patterns!</code></a></li><li><a href="#StringAnalysis.rowindices-Tuple{Array{String,1}}"><code>StringAnalysis.rowindices</code></a></li><li><a href="#StringAnalysis.rp-Union{Tuple{DocumentTermMatrix{T}}, Tuple{T}} where T&lt;:AbstractFloat"><code>StringAnalysis.rp</code></a></li><li><a href="#StringAnalysis.save_lsa_model-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},AbstractString}} where H where A where T where S"><code>StringAnalysis.save_lsa_model</code></a></li><li><a href="#StringAnalysis.save_rp_model-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},AbstractString}} where H where A where T where S"><code>StringAnalysis.save_rp_model</code></a></li><li><a href="#StringAnalysis.sentence_tokenize-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractString"><code>StringAnalysis.sentence_tokenize</code></a></li><li><a href="#StringAnalysis.similarity-Tuple{Any,Any,Any}"><code>StringAnalysis.similarity</code></a></li><li><a href="#StringAnalysis.sparse_terms"><code>StringAnalysis.sparse_terms</code></a></li><li><a href="#StringAnalysis.sparse_terms"><code>StringAnalysis.sparse_terms</code></a></li><li><a href="#StringAnalysis.text-Tuple{AbstractString}"><code>StringAnalysis.text</code></a></li><li><a href="#StringAnalysis.text!-Union{Tuple{T}, Tuple{StringDocument{T},T}} where T&lt;:AbstractString"><code>StringAnalysis.text!</code></a></li><li><a href="#StringAnalysis.tokenize-Tuple{Any}"><code>StringAnalysis.tokenize</code></a></li><li><a href="#StringAnalysis.tokenize_fast-Union{Tuple{Array{S,1}}, Tuple{S}} where S&lt;:AbstractString"><code>StringAnalysis.tokenize_fast</code></a></li><li><a href="#StringAnalysis.tokenize_slow-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractString"><code>StringAnalysis.tokenize_slow</code></a></li><li><a href="#StringAnalysis.tokens-Tuple{AbstractString}"><code>StringAnalysis.tokens</code></a></li><li><a href="#StringAnalysis.tokens!-Union{Tuple{T}, Tuple{TokenDocument{T},Array{T,1}}} where T&lt;:AbstractString"><code>StringAnalysis.tokens!</code></a></li><li><a href="#StringAnalysis.vocabulary-Tuple{RPModel}"><code>StringAnalysis.vocabulary</code></a></li><li><a href="#StringAnalysis.vocabulary-Tuple{LSAModel}"><code>StringAnalysis.vocabulary</code></a></li></ul><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.StringAnalysis" href="#StringAnalysis.StringAnalysis"><code>StringAnalysis.StringAnalysis</code></a> â <span class="docstring-category">Module</span>.</div><div><div><p>A Julia library for working with text, hard-forked from TextAnalysis.jl.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.CooMatrix" href="#StringAnalysis.CooMatrix"><code>StringAnalysis.CooMatrix</code></a> â <span class="docstring-category">Type</span>.</div><div><div><p>Basic Co-occurrence Matrix (COOM) type.</p><p><strong>Fields</strong></p><ul><li><code>coomm::SparseMatriCSC{T,Int}</code> the actual COOM; elements represent</li></ul><p>co-occurrences of two terms within a given window</p><ul><li><code>terms::Vector{String}</code> a list of terms that represent the lexicon of</li></ul><p>the document or corpus</p><ul><li><code>column_indices::OrderedDict{String, Int}</code> a map between the <code>terms</code> and the</li></ul><p>columns of the co-occurrence matrix</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.CooMatrix-Union{Tuple{T}, Tuple{Corpus,Array{String,1}}} where T&lt;:AbstractFloat" href="#StringAnalysis.CooMatrix-Union{Tuple{T}, Tuple{Corpus,Array{String,1}}} where T&lt;:AbstractFloat"><code>StringAnalysis.CooMatrix</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">CooMatrix{T}(crps::Corpus [,terms] [;window=5, normalize=true])</code></pre><p>Auxiliary constructor(s) of the <code>CooMatrix</code> type. The type <code>T</code> has to be a subtype of <code>AbstractFloat</code>. The constructor(s) requires a corpus <code>crps</code> and a <code>terms</code> structure representing the lexicon of the corpus. The latter can be a <code>Vector{String}</code>, an <code>AbstractDict</code> where the keys are the lexicon, or can be omitted, in which case the <code>lexicon</code> field of the corpus is used.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.DocumentTermMatrix" href="#StringAnalysis.DocumentTermMatrix"><code>StringAnalysis.DocumentTermMatrix</code></a> â <span class="docstring-category">Type</span>.</div><div><div><p>Basic Document-Term-Matrix (DTM) type.</p><p><strong>Fields</strong></p><ul><li><code>dtm::SparseMatriCSC{T,Int}</code> the actual DTM; rows represent terms</li></ul><p>and columns represent documents</p><ul><li><code>terms::Vector{String}</code> a list of terms that represent the lexicon of</li></ul><p>the corpus associated with the DTM</p><ul><li><code>row_indices::OrderedDict{String, Int}</code> a map between the <code>terms</code> and the</li></ul><p>rows of the <code>dtm</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.DocumentTermMatrix-Union{Tuple{T}, Tuple{Corpus,Array{String,1}}} where T&lt;:Real" href="#StringAnalysis.DocumentTermMatrix-Union{Tuple{T}, Tuple{Corpus,Array{String,1}}} where T&lt;:Real"><code>StringAnalysis.DocumentTermMatrix</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">DocumentTermMatrix{T}(crps::Corpus [,terms] [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Auxiliary constructor(s) of the <code>DocumentTermMatrix</code> type. The type <code>T</code> has to be a subtype of <code>Real</code>. The constructor(s) requires a corpus <code>crps</code> and a <code>terms</code> structure representing the lexicon of the corpus. The latter can be a <code>Vector{String}</code>, an <code>AbstractDict</code> where the keys are the lexicon, or can be missing, in which case the <code>lexicon</code> field of the corpus is used.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.LSAModel" href="#StringAnalysis.LSAModel"><code>StringAnalysis.LSAModel</code></a> â <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">LSAModel{S&lt;:AbstractString, T&lt;:AbstractFloat, A&lt;:AbstractMatrix{T}, H&lt;:Integer}</code></pre><p>LSA (latent semantic analysis) model. It constructs from a document term matrix (dtm) a model that can be used to embed documents in a latent semantic space pertaining to the data. The model requires that the document term matrix be a <code>DocumentTermMatrix{T&lt;:AbstractFloat}</code> because the elements of the matrices resulted from the SVD operation are floating point numbers and these have to match or be convertible to type <code>T</code>.</p><p><strong>Fields</strong></p><ul><li><code>vocab::Vector{S}</code> a vector with all the words in the corpus</li><li><code>vocab_hash::OrderedDict{S,H}</code> a word to index in word embeddings matrix mapping</li><li><code>Î£inv::A</code> inverse of the singular value matrix</li><li><code>Uáµ::A</code> transpose of the word embedding matrix</li><li><code>stats::Symbol</code> the statistical measure to use for word importances in documents. Available values are: <code>:count</code> (term count), <code>:tf</code> (term frequency), <code>:tfidf</code> (default, term frequency-inverse document frequency) and <code>:bm25</code> (Okapi BM25)</li><li><code>idf::Vector{T}</code> inverse document frequencies for the words in the vocabulary</li><li><code>nwords::T</code> averge number of words in a document</li><li><code>Îº::Int</code> the <code>Îº</code> parameter of the BM25 statistic</li><li><code>Î²::Float64</code> the <code>Î²</code> parameter of the BM25 statistic</li><li><code>tol::T</code> minimum size of the vector components (default <code>T(1e-15)</code>)</li></ul><p><strong>SVD matrices <code>U</code>, <code>Î£inv</code> and <code>V</code>:</strong></p><p>If <code>X</code> is a <code>m</code>Ã<code>n</code> document-term-matrix with <code>n</code> documents and <code>m</code> words so that <code>X[i,j]</code> represents a statistical indicator of the importance of term <code>i</code> in document <code>j</code> then:</p><ul><li><code>U, Î£, V = svd(X)</code></li><li><code>Î£inv = inv(Î£)</code></li><li><code>Uáµ = U&#39;</code></li><li><code>X â U * Î£ * V&#39;</code></li></ul><p>The matrix <code>V</code> of document embeddings is not actually stored in the model.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; using StringAnalysis

       doc1 = StringDocument(&quot;This is a text about an apple. There are many texts about apples.&quot;)
       doc2 = StringDocument(&quot;Pears and apples are good but not exotic. An apple a day keeps the doctor away.&quot;)
       doc3 = StringDocument(&quot;Fruits are good for you.&quot;)
       doc4 = StringDocument(&quot;This phrase has nothing to do with the others...&quot;)
       doc5 = StringDocument(&quot;Simple text, little info inside&quot;)

       crps = Corpus(AbstractDocument[doc1, doc2, doc3, doc4, doc5])
       prepare!(crps, strip_punctuation)
       update_lexicon!(crps)
       dtm = DocumentTermMatrix{Float32}(crps, collect(keys(crps.lexicon)))

       ### Build LSA Model ###
       lsa_model = LSAModel(dtm, k=3, stats=:tf)

       query = StringDocument(&quot;Apples and an exotic fruit.&quot;)
       idxs, corrs = cosine(lsa_model, crps, query)

       println(&quot;Query: &quot;$(query.text)&quot;&quot;)
       for (idx, corr) in zip(idxs, corrs)
           println(&quot;$corr -&gt; &quot;$(crps[idx].text)&quot;&quot;)
       end
Query: &quot;Apples and an exotic fruit.&quot;
0.9746108 -&gt; &quot;Pears and apples are good but not exotic  An apple a day keeps the doctor away &quot;
0.870703 -&gt; &quot;This is a text about an apple  There are many texts about apples &quot;
0.7122063 -&gt; &quot;Fruits are good for you &quot;
0.22725986 -&gt; &quot;This phrase has nothing to do with the others &quot;
0.076901935 -&gt; &quot;Simple text  little info inside &quot;</code></pre><p><strong>References:</strong></p><ul><li><a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">The LSA wiki page</a></li><li><a href="http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf">Deerwester et al. 1990</a></li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.RPModel" href="#StringAnalysis.RPModel"><code>StringAnalysis.RPModel</code></a> â <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">RPModel{S&lt;:AbstractString, T&lt;:AbstractFloat, A&lt;:AbstractMatrix{T}, H&lt;:Integer}</code></pre><p>Random projection model. It constructs from a document term matrix (DTM) a model that can be used to embed documents in a random sub-space. The model requires that the document term matrix be a <code>DocumentTermMatrix{T&lt;:AbstractFloat}</code> because the elements of the matrices resulted projection operation are floating point numbers and these have to match or be convertible to type <code>T</code>. The approach is based on the effects of the <a href="https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma">Johnson-Lindenstrauss lemma</a>.</p><p><strong>Fields</strong></p><ul><li><code>vocab::Vector{S}</code> a vector with all the words in the corpus</li><li><code>vocab_hash::OrderedDict{S,H}</code> a word to index in the random projection maatrix mapping</li><li><code>R::A</code> the random projection matrix</li><li><code>stats::Symbol</code> the statistical measure to use for word importances in documents. Available values are: <code>:count</code> (term count), <code>:tf</code> (term frequency), <code>:tfidf</code> (default, term frequency-inverse document frequency) and <code>:bm25</code> (Okapi BM25)</li><li><code>idf::Vector{T}</code> inverse document frequencies for the words in the vocabulary</li><li><code>nwords::T</code> averge number of words in a document</li><li><code>Îº::Int</code> the <code>Îº</code> parameter of the BM25 statistic</li><li><code>Î²::Float64</code> the <code>Î²</code> parameter of the BM25 statistic</li><li><code>project::Bool</code> specifies whether the model actually performs the projection or not; it is false if the number of dimensions provided is zero or negative</li></ul><p><strong>References:</strong></p><ul><li><a href="http://www.academia.edu/371863/Dimensionality_Reduction_by_Random_Mapping_Fast_Similarity_Computation_for_Clustering">Kaski 1998</a></li><li><a href="https://users.soe.ucsc.edu/~optas/papers/jl.pdf">Achlioptas 2001</a></li><li><a href="http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf">Li et al. 2006</a></li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.TextHashFunction" href="#StringAnalysis.TextHashFunction"><code>StringAnalysis.TextHashFunction</code></a> â <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">TextHashFunction(hash_function::Function, cardinality::Int)</code></pre><p>The basic structure for performing text hashing: uses the <code>hash_function</code> to generate feature vectors of length <code>cardinality</code>.</p><p><strong>Details</strong></p><p>The hash trick is the use a hash function instead of a lexicon to determine the columns of a DocumentTermMatrix-like encoding of the data. To produce a DTM for a Corpus for which we do not have an existing lexicon, we need someway to map the terms from each document into column indices. We use the now standard &quot;Hash Trick&quot; in which we hash strings and then reduce the resulting integers modulo N, which defines the numbers of columns we want our DTM to have. This amounts to doing a non-linear dimensionality reduction with low probability that similar terms hash to the same dimension.</p><p>To make things easier, we wrap Julia&#39;s hash functions in a new type, TextHashFunction, which maintains information about the desired cardinality of the hashes.</p><p><strong>References:</strong></p><ul><li><a href="https://en.wikipedia.org/wiki/Feature_hashing">The &quot;Hash Trick&quot; wiki page</a></li><li><a href="http://papers.nips.cc/paper/175-fast-learning-in-multi-resolution-hierarchies.pdf">Moody, John 1989</a></li></ul><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; doc = StringDocument(&quot;this is a text&quot;)
       thf = TextHashFunction(hash, 13)
       hash_dtv(doc, thf, Float16)
13-element Array{Float16,1}:
 1.0
 1.0
 0.0
 0.0
 0.0
 0.0
 0.0
 2.0
 0.0
 0.0
 0.0
 0.0
 0.0</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.coom-Tuple{CooMatrix}" href="#StringAnalysis.coom-Tuple{CooMatrix}"><code>StringAnalysis.coom</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">coom(c::CooMatrix)</code></pre><p>Access the co-occurrence matrix field <code>coom</code> of a <code>CooMatrix</code> <code>c</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.coom-Union{Tuple{Any}, Tuple{T}, Tuple{Any,Type{T}}} where T&lt;:AbstractFloat" href="#StringAnalysis.coom-Union{Tuple{Any}, Tuple{T}, Tuple{Any,Type{T}}} where T&lt;:AbstractFloat"><code>StringAnalysis.coom</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">coom(entity, eltype=DEFAULT_FLOAT_TYPE [;window=5, normalize=true])</code></pre><p>Access the co-occurrence matrix of the <code>CooMatrix</code> associated with the <code>entity</code>. The <code>CooMatrix{T}</code> will first have to be created in order for the actual matrix to be accessed.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.cosine" href="#StringAnalysis.cosine"><code>StringAnalysis.cosine</code></a> â <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">cosine(model, docs, doc, n=10)</code></pre><p>Return the positions of the <code>n</code> closest neighboring documents to <code>doc</code> found in <code>docs</code>. <code>docs</code> can be a corpus or document term matrix. The vector representations of <code>docs</code> and <code>doc</code> are obtained with the <code>model</code> which can be either a <code>LSAModel</code> or <code>RPModel</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.dtm-Tuple{DocumentTermMatrix}" href="#StringAnalysis.dtm-Tuple{DocumentTermMatrix}"><code>StringAnalysis.dtm</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">dtm(d::DocumentTermMatrix)</code></pre><p>Access the matrix of a <code>DocumentTermMatrix</code> <code>d</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.dtm-Union{Tuple{Corpus}, Tuple{T}, Tuple{Corpus,Type{T}}} where T&lt;:Real" href="#StringAnalysis.dtm-Union{Tuple{Corpus}, Tuple{T}, Tuple{Corpus,Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtm</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">dtm(crps::Corpus, eltype::Type{T}=DEFAULT_DTM_TYPE [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Access the matrix of the DTM associated with the corpus <code>crps</code>. The <code>DocumentTermMatrix{T}</code> will first have to be created in order for the actual matrix to be accessed.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.dtv-Union{Tuple{T}, Tuple{Any,OrderedDict{String,Int64}}, Tuple{Any,OrderedDict{String,Int64},Type{T}}} where T&lt;:Real" href="#StringAnalysis.dtv-Union{Tuple{T}, Tuple{Any,OrderedDict{String,Int64}}, Tuple{Any,OrderedDict{String,Int64},Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtv</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">dtv(d, lex::OrderedDict{String,Int}, eltype::Type{T}=DEFAULT_DTM_TYPE [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Creates a document-term-vector with elements of type <code>T</code> for document <code>d</code> using the lexicon <code>lex</code>. <code>d</code> can be an <code>AbstractString</code> or an <code>AbstractDocument</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.dtv-Union{Tuple{T}, Tuple{Corpus,Int64}, Tuple{Corpus,Int64,Type{T}}} where T&lt;:Real" href="#StringAnalysis.dtv-Union{Tuple{T}, Tuple{Corpus,Int64}, Tuple{Corpus,Int64,Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtv</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">dtv(crps::Corpus, idx::Int, eltype::Type{T}=DEFAULT_DTM_TYPE [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Creates a document-term-vector with elements of type <code>T</code> for document <code>idx</code> of the corpus <code>crps</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.dtv_regex-Union{Tuple{T}, Tuple{Any,OrderedDict{String,Int64}}, Tuple{Any,OrderedDict{String,Int64},Type{T}}} where T&lt;:Real" href="#StringAnalysis.dtv_regex-Union{Tuple{T}, Tuple{Any,OrderedDict{String,Int64}}, Tuple{Any,OrderedDict{String,Int64},Type{T}}} where T&lt;:Real"><code>StringAnalysis.dtv_regex</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">dtv_regex(d, lex::OrderedDict{String,Int}, eltype::Type{T}=DEFAULT_DTM_TYPE [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Creates a document-term-vector with elements of type <code>T</code> for document <code>d</code> using the lexicon <code>lex</code>. The tokens of document <code>d</code> are assumed to be regular expressions in text format. <code>d</code> can be an <code>AbstractString</code> or an <code>AbstractDocument</code>.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; dtv_regex(NGramDocument(&quot;a..b&quot;), OrderedDict(&quot;aaa&quot;=&gt;1, &quot;aaab&quot;=&gt;2, &quot;accb&quot;=&gt;3, &quot;bbb&quot;=&gt;4), Float32)
4-element Array{Float32,1}:
 0.0
 1.0
 1.0
 0.0</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.each_dtv-Union{Tuple{Corpus}, Tuple{U}} where U&lt;:Real" href="#StringAnalysis.each_dtv-Union{Tuple{Corpus}, Tuple{U}} where U&lt;:Real"><code>StringAnalysis.each_dtv</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">each_dtv(crps::Corpus [; eltype::Type{U}=DEFAULT_DTM_TYPE, tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Iterates through the columns of the DTM of the corpus <code>crps</code> without constructing it. Useful when the DTM would not fit in memory. <code>eltype</code> specifies the element type of the generated vectors.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.each_hash_dtv-Union{Tuple{Corpus}, Tuple{U}} where U&lt;:Real" href="#StringAnalysis.each_hash_dtv-Union{Tuple{Corpus}, Tuple{U}} where U&lt;:Real"><code>StringAnalysis.each_hash_dtv</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">each_hash_dtv(crps::Corpus [; eltype::Type{U}=DEFAULT_DTM_TYPE, tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Iterates through the columns of the hashed DTM of the corpus <code>crps</code> without constructing it. Useful when the DTM would not fit in memory. <code>eltype</code> specifies the element type of the generated vectors.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.embed_document-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},AbstractDocument}} where H where A where T where S" href="#StringAnalysis.embed_document-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},AbstractDocument}} where H where A where T where S"><code>StringAnalysis.embed_document</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">embed_document(lm, doc)</code></pre><p>Return the vector representation of <code>doc</code>, obtained using the LSA model <code>lm</code>. <code>doc</code> can be an <code>AbstractDocument</code>, <code>Corpus</code> or DTV or DTM.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.embed_document-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},AbstractDocument}} where H where A where T where S" href="#StringAnalysis.embed_document-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},AbstractDocument}} where H where A where T where S"><code>StringAnalysis.embed_document</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">embed_document(rpm, doc)</code></pre><p>Return the vector representation of <code>doc</code>, obtained using the random projection model <code>rpm</code>. <code>doc</code> can be an <code>AbstractDocument</code>, <code>Corpus</code> or DTV or DTM.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.frequent_terms" href="#StringAnalysis.frequent_terms"><code>StringAnalysis.frequent_terms</code></a> â <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">frequent_terms(doc, alpha)</code></pre><p>Returns a vector with frequent terms in the document <code>doc</code>. The parameter <code>alpha</code> indicates the sparsity threshold (a frequency &lt;= alpha means sparse).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.frequent_terms" href="#StringAnalysis.frequent_terms"><code>StringAnalysis.frequent_terms</code></a> â <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">frequent_terms(crps::Corpus, alpha)</code></pre><p>Returns a vector with frequent terms among all documents. The parameter <code>alpha</code> indicates the sparsity threshold (a frequency &lt;= alpha means sparse).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.get_vector-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},Any}} where H where A where T where S" href="#StringAnalysis.get_vector-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},Any}} where H where A where T where S"><code>StringAnalysis.get_vector</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">get_vector(lm, word)</code></pre><p>Returns the vector representation of <code>word</code> from the LSA model <code>lm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.get_vector-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},Any}} where H where A where T where S" href="#StringAnalysis.get_vector-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},Any}} where H where A where T where S"><code>StringAnalysis.get_vector</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">get_vector(rpm, word)</code></pre><p>Returns the random projection vector corresponding to <code>word</code> in the random projection model <code>rpm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.hash_dtm-Union{Tuple{T}, Tuple{Corpus,TextHashFunction}, Tuple{Corpus,TextHashFunction,Type{T}}} where T&lt;:Real" href="#StringAnalysis.hash_dtm-Union{Tuple{T}, Tuple{Corpus,TextHashFunction}, Tuple{Corpus,TextHashFunction,Type{T}}} where T&lt;:Real"><code>StringAnalysis.hash_dtm</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hash_dtm(crps::Corpus [,h::TextHashFunction], eltype::Type{T}=DEFAULT_DTM_TYPE [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Creates a hashed DTM with elements of type <code>T</code> for corpus <code>crps</code> using the the hashing function <code>h</code>. If <code>h</code> is missing, the hash function of the <code>Corpus</code> is used.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.hash_dtv-Union{Tuple{T}, Tuple{Any,TextHashFunction}, Tuple{Any,TextHashFunction,Type{T}}} where T&lt;:Real" href="#StringAnalysis.hash_dtv-Union{Tuple{T}, Tuple{Any,TextHashFunction}, Tuple{Any,TextHashFunction,Type{T}}} where T&lt;:Real"><code>StringAnalysis.hash_dtv</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">hash_dtv(d, h::TextHashFunction, eltype::Type{T}=DEFAULT_DTM_TYPE [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Creates a hashed document-term-vector with elements of type <code>T</code> for document <code>d</code> using the hashing function <code>h</code>. <code>d</code> can be an <code>AbstractString</code> or an <code>AbstractDocument</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.in_vocabulary-Tuple{LSAModel,AbstractString}" href="#StringAnalysis.in_vocabulary-Tuple{LSAModel,AbstractString}"><code>StringAnalysis.in_vocabulary</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">in_vocabulary(lm, word)</code></pre><p>Return <code>true</code> if <code>word</code> is part of the vocabulary of the LSA model <code>lm</code> and <code>false</code> otherwise.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.in_vocabulary-Tuple{RPModel,AbstractString}" href="#StringAnalysis.in_vocabulary-Tuple{RPModel,AbstractString}"><code>StringAnalysis.in_vocabulary</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">in_vocabulary(rpm, word)</code></pre><p>Return <code>true</code> if <code>word</code> is part of the vocabulary of the random projection model <code>rpm</code> and <code>false</code> otherwise.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.index-Tuple{LSAModel,Any}" href="#StringAnalysis.index-Tuple{LSAModel,Any}"><code>StringAnalysis.index</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">index(lm, word)</code></pre><p>Return the index of <code>word</code> from the LSA model <code>lm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.index-Tuple{RPModel,Any}" href="#StringAnalysis.index-Tuple{RPModel,Any}"><code>StringAnalysis.index</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">index(rpm, word)</code></pre><p>Return the index of <code>word</code> from the random projection model <code>rpm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.lda-Tuple{DocumentTermMatrix,Int64,Int64,Float64,Float64}" href="#StringAnalysis.lda-Tuple{DocumentTermMatrix,Int64,Int64,Float64,Float64}"><code>StringAnalysis.lda</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">Ï, Î¸ = lda(dtm::DocumentTermMatrix, ntopics::Int, iterations::Int, Î±::Float64, Î²::Float64)</code></pre><p>Perform <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet allocation</a>.</p><p><strong>Arguments</strong></p><ul><li><code>Î±</code> Dirichlet dist. hyperparameter for topic distribution per document. <code>Î±&lt;1</code> yields a sparse topic mixture for each document. <code>Î±&gt;1</code> yields a more uniform topic mixture for each document.</li><li><code>Î²</code> Dirichlet dist. hyperparameter for word distribution per topic. <code>Î²&lt;1</code> yields a sparse word mixture for each topic. <code>Î²&gt;1</code> yields a more uniform word mixture for each topic.</li></ul><p><strong>Return values</strong></p><ul><li><code>Ï</code>: <code>ntopics Ã nwords</code> Sparse matrix of probabilities s.t. <code>sum(Ï, 1) == 1</code></li><li><code>Î¸</code>: <code>ntopics Ã ndocs</code> Dense matrix of probabilities s.t. <code>sum(Î¸, 1) == 1</code></li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.load_lsa_model-Union{Tuple{AbstractString}, Tuple{T}, Tuple{AbstractString,Type{T}}} where T&lt;:AbstractFloat" href="#StringAnalysis.load_lsa_model-Union{Tuple{AbstractString}, Tuple{T}, Tuple{AbstractString,Type{T}}} where T&lt;:AbstractFloat"><code>StringAnalysis.load_lsa_model</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">load_lsa_model(filename, eltype; [sparse=true])</code></pre><p>Loads an LSA model from <code>filename</code> into an LSA model object. The embeddings matrix element type is specified by <code>eltype</code> (default <code>DEFAULT_FLOAT_TYPE</code>) while the keyword argument <code>sparse</code> specifies whether the matrix should be sparse or not.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.load_rp_model-Union{Tuple{AbstractString}, Tuple{T}, Tuple{AbstractString,Type{T}}} where T&lt;:AbstractFloat" href="#StringAnalysis.load_rp_model-Union{Tuple{AbstractString}, Tuple{T}, Tuple{AbstractString,Type{T}}} where T&lt;:AbstractFloat"><code>StringAnalysis.load_rp_model</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">load_rp_model(filename, eltype; [sparse=true])</code></pre><p>Loads an random projection model from <code>filename</code> into an random projection model object. The projection matrix element type is specified by <code>eltype</code> (default <code>DEFAULT_FLOAT_TYPE</code>) while the keyword argument <code>sparse</code> specifies whether the matrix should be sparse or not.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.lsa-Union{Tuple{DocumentTermMatrix{T}}, Tuple{T}} where T&lt;:AbstractFloat" href="#StringAnalysis.lsa-Union{Tuple{DocumentTermMatrix{T}}, Tuple{T}} where T&lt;:AbstractFloat"><code>StringAnalysis.lsa</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">lsa(X [;k=&lt;num documents&gt;, stats=:tfidf, Îº=2, Î²=0.75, tol=1e-15])</code></pre><p>Constructs a LSA model. The input <code>X</code> can be a <code>Corpus</code> or a <code>DocumentTermMatrix</code>. Use <code>?LSAModel</code> for more details. Vector components smaller than <code>tol</code> will be zeroed out.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.ngrams" href="#StringAnalysis.ngrams"><code>StringAnalysis.ngrams</code></a> â <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">ngrams(d, n=DEFAULT_GRAM_COMPLEXITY [; tokenizer=DEFAULT_TOKENIZER])</code></pre><p>Access the document text of <code>d</code> as n-gram counts. The ngrams contain at most <code>n</code> tokens which are obtained using <code>tokenizer</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.ngrams!-Union{Tuple{T}, Tuple{NGramDocument{T},Dict{T,Int64}}} where T&lt;:AbstractString" href="#StringAnalysis.ngrams!-Union{Tuple{T}, Tuple{NGramDocument{T},Dict{T,Int64}}} where T&lt;:AbstractString"><code>StringAnalysis.ngrams!</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">ngrams!(d, new_ngrams)</code></pre><p>Replace the original n-grams of document <code>d</code> with <code>new_ngrams</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.rp-Union{Tuple{DocumentTermMatrix{T}}, Tuple{T}} where T&lt;:AbstractFloat" href="#StringAnalysis.rp-Union{Tuple{DocumentTermMatrix{T}}, Tuple{T}} where T&lt;:AbstractFloat"><code>StringAnalysis.rp</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">rp(X [;k=m, density=1/sqrt(k), stats=:tfidf, Îº=2, Î²=0.75])</code></pre><p>Constructs a random projection model. The input <code>X</code> can be a <code>Corpus</code> or a <code>DocumentTermMatrix</code> with <code>m</code> words in the lexicon. The model does not store the corpus or DTM document embeddings, just the projection matrix. Use <code>?RPModel</code> for more details.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.save_lsa_model-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},AbstractString}} where H where A where T where S" href="#StringAnalysis.save_lsa_model-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{LSAModel{S,T,A,H},AbstractString}} where H where A where T where S"><code>StringAnalysis.save_lsa_model</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">save(lm, filename)</code></pre><p>Saves an LSA model <code>lm</code> to disc in file <code>filename</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.save_rp_model-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},AbstractString}} where H where A where T where S" href="#StringAnalysis.save_rp_model-Union{Tuple{H}, Tuple{A}, Tuple{T}, Tuple{S}, Tuple{RPModel{S,T,A,H},AbstractString}} where H where A where T where S"><code>StringAnalysis.save_rp_model</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">save_rp_model(rpm, filename)</code></pre><p>Saves an random projection model <code>rpm</code> to disc in file <code>filename</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.sentence_tokenize-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractString" href="#StringAnalysis.sentence_tokenize-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractString"><code>StringAnalysis.sentence_tokenize</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">sentence_tokenize([lang,] s)</code></pre><p>Splits string <code>s</code> into sentences using <code>WordTokenizers.split_sentences</code> function to perform the tokenization. If a language <code>lang</code> is provided, it ignores it ;)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.similarity-Tuple{Any,Any,Any}" href="#StringAnalysis.similarity-Tuple{Any,Any,Any}"><code>StringAnalysis.similarity</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">similarity(model, doc1, doc2)</code></pre><p>Return the cosine similarity value between two documents <code>doc1</code> and <code>doc2</code> whose vector representations have been obtained using the <code>model</code>, which can be either a <code>LSAModel</code> or <code>RPModel</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.sparse_terms" href="#StringAnalysis.sparse_terms"><code>StringAnalysis.sparse_terms</code></a> â <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">sparse_terms(doc, alpha)</code></pre><p>Returns a vector with rare terms in the document <code>doc</code>. The parameter <code>alpha</code> indicates the sparsity threshold (a frequency &lt;= alpha means sparse).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.sparse_terms" href="#StringAnalysis.sparse_terms"><code>StringAnalysis.sparse_terms</code></a> â <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">sparse_terms(crps::Corpus, alpha)</code></pre><p>Returns a vector with rare terms among all documents. The parameter <code>alpha</code> indicates the sparsity threshold (a frequency &lt;= alpha means sparse).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.text!-Union{Tuple{T}, Tuple{StringDocument{T},T}} where T&lt;:AbstractString" href="#StringAnalysis.text!-Union{Tuple{T}, Tuple{StringDocument{T},T}} where T&lt;:AbstractString"><code>StringAnalysis.text!</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">text!(d, new_text)</code></pre><p>Replace the original text of document <code>d</code> with <code>new_text</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.text-Tuple{AbstractString}" href="#StringAnalysis.text-Tuple{AbstractString}"><code>StringAnalysis.text</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">text(d)</code></pre><p>Access the text of document <code>d</code> if possible.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.tokenize-Tuple{Any}" href="#StringAnalysis.tokenize-Tuple{Any}"><code>StringAnalysis.tokenize</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">tokenize(s [;method])</code></pre><p>Tokenizes based on either the <code>tokenize_slow</code> or <code>tokenize_fast</code> functions.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.tokenize_fast-Union{Tuple{Array{S,1}}, Tuple{S}} where S&lt;:AbstractString" href="#StringAnalysis.tokenize_fast-Union{Tuple{Array{S,1}}, Tuple{S}} where S&lt;:AbstractString"><code>StringAnalysis.tokenize_fast</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">tokenize_fast(doc [;splitter])</code></pre><p>Function that quickly tokenizes <code>doc</code> based on the splitting pattern specified by <code>splitter::RegEx</code>. Supported types for <code>doc</code> are: <code>AbstractString</code>, <code>Vector{AbstractString}</code>, <code>StringDocument</code> and <code>NGramDocument</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.tokenize_slow-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractString" href="#StringAnalysis.tokenize_slow-Union{Tuple{T}, Tuple{T}} where T&lt;:AbstractString"><code>StringAnalysis.tokenize_slow</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">tokenize_slow([lang,] s)</code></pre><p>Splits string <code>s</code> into tokens on whitespace using <code>WordTokenizers.tokenize</code> function to perform the tokenization. If a language <code>lang</code> is provided, it ignores it ;)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.tokens!-Union{Tuple{T}, Tuple{TokenDocument{T},Array{T,1}}} where T&lt;:AbstractString" href="#StringAnalysis.tokens!-Union{Tuple{T}, Tuple{TokenDocument{T},Array{T,1}}} where T&lt;:AbstractString"><code>StringAnalysis.tokens!</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">tokens!(d, new_tokens)</code></pre><p>Replace the original tokens of document <code>d</code> with <code>new_tokens</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.tokens-Tuple{AbstractString}" href="#StringAnalysis.tokens-Tuple{AbstractString}"><code>StringAnalysis.tokens</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">tokens(d [; method=DEFAULT_TOKENIZER])</code></pre><p>Access the tokens of document <code>d</code> as a token array. The <code>method</code> keyword argument specifies the type of tokenization to perform. Available options are <code>:slow</code> and <code>:fast</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.vocabulary-Tuple{LSAModel}" href="#StringAnalysis.vocabulary-Tuple{LSAModel}"><code>StringAnalysis.vocabulary</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">vocabulary(lm)</code></pre><p>Return the vocabulary as a vector of words of the LSA model <code>lm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.vocabulary-Tuple{RPModel}" href="#StringAnalysis.vocabulary-Tuple{RPModel}"><code>StringAnalysis.vocabulary</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">vocabulary(rpm)</code></pre><p>Return the vocabulary as a vector of words of the random projection model <code>rpm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.size-Tuple{LSAModel}" href="#Base.size-Tuple{LSAModel}"><code>Base.size</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">size(lm)</code></pre><p>Return a tuple containin input and output dimensionalities of the LSA model <code>lm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.size-Tuple{RPModel}" href="#Base.size-Tuple{RPModel}"><code>Base.size</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">size(rpm)</code></pre><p>Return a tuple containing the input data and projection sub-space dimensionalities of the random projection model <code>rpm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.summary-Tuple{AbstractDocument}" href="#Base.summary-Tuple{AbstractDocument}"><code>Base.summary</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">summary(doc)</code></pre><p>Shows information about the document <code>doc</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.summary-Tuple{Corpus}" href="#Base.summary-Tuple{Corpus}"><code>Base.summary</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">summary(crps)</code></pre><p>Shows information about the corpus <code>crps</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.columnindices" href="#StringAnalysis.columnindices"><code>StringAnalysis.columnindices</code></a> â <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">columnindices(terms)</code></pre><p>Identical to <code>rowindices</code>. Returns a dictionary that maps each term from the vector <code>terms</code> to a integer idex.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.coo_matrix-Union{Tuple{T}, Tuple{Type{T},Array{#s29,1} where #s29&lt;:AbstractString,OrderedDict{#s28,Int64} where #s28&lt;:AbstractString,Int64}, Tuple{Type{T},Array{#s27,1} where #s27&lt;:AbstractString,OrderedDict{#s26,Int64} where #s26&lt;:AbstractString,Int64,Bool}} where T&lt;:AbstractFloat" href="#StringAnalysis.coo_matrix-Union{Tuple{T}, Tuple{Type{T},Array{#s29,1} where #s29&lt;:AbstractString,OrderedDict{#s28,Int64} where #s28&lt;:AbstractString,Int64}, Tuple{Type{T},Array{#s27,1} where #s27&lt;:AbstractString,OrderedDict{#s26,Int64} where #s26&lt;:AbstractString,Int64,Bool}} where T&lt;:AbstractFloat"><code>StringAnalysis.coo_matrix</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">coo_matrix(::Type{T}, doc::Vector{AbstractString}, vocab::OrderedDict{AbstractString, Int}, window::Int, normalize::Bool)</code></pre><p>Basic low-level function that calculates the co-occurence matrix of a document. Returns a sparse co-occurence matrix sized <code>n Ã n</code> where <code>n = length(vocab)</code> with elements of type <code>T</code>. The document <code>doc</code> is represented by a vector of its terms (in order)<code>. The keywords</code>window<code>and</code>normalize` indicate the size of the sliding word window in which co-occurrences are counted and whether to normalize of not the counts by the distance between word positions.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; using StringAnalysis
       doc = StringDocument(&quot;This is a text about an apple. There are many texts about apples.&quot;)
       docv = tokenize(text(doc))
       vocab = OrderedDict(&quot;This&quot;=&gt;1, &quot;is&quot;=&gt;2, &quot;apple.&quot;=&gt;3)
       StringAnalysis.coo_matrix(Float16, docv, vocab, 5, true)
3Ã3 SparseArrays.SparseMatrixCSC{Float16,Int64} with 4 stored entries:
  [2, 1]  =  2.0
  [1, 2]  =  2.0
  [3, 2]  =  0.3999
  [2, 3]  =  0.3999</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.embed_word-Tuple{LSAModel,Any}" href="#StringAnalysis.embed_word-Tuple{LSAModel,Any}"><code>StringAnalysis.embed_word</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">embed_word(lm, word)</code></pre><p>Return the vector representation of <code>word</code> using the LSA model <code>lm</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.random_projection_matrix-Union{Tuple{T}, Tuple{Int64,Int64,Type{T},Float64}} where T&lt;:AbstractFloat" href="#StringAnalysis.random_projection_matrix-Union{Tuple{T}, Tuple{Int64,Int64,Type{T},Float64}} where T&lt;:AbstractFloat"><code>StringAnalysis.random_projection_matrix</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">random_projection_matrix(k::Int, m::Int, eltype::Type{T&lt;:AbstractFloat}, density::Float64)</code></pre><p>Builds a <code>k</code>Ã<code>m</code> sparse random projection matrix with elements of type <code>T</code> and a non-zero element frequency of <code>density</code>. <code>k</code> and <code>m</code> are the output and input dimensionalities.</p><p><strong>Matrix Probabilities</strong></p><p>If we note <code>s = 1 / density</code>, the components of the random matrix are drawn from:</p><ul><li><code>-sqrt(s) / sqrt(k)</code> with probability <code>1/2s</code></li><li><code>0</code> with probability <code>1 - 1/s</code></li><li><code>+sqrt(s) / sqrt(k)</code>   with probability <code>1/2s</code></li></ul><p><strong>No projection hack</strong></p><p>If <code>k&lt;=0</code> no projection is performed and the function returns an identity matrix sized <code>m</code>Ã<code>m</code> with elements of type <code>T</code>. This is useful if one does not want to embed documents but rather calculate term frequencies, BM25 and other statistical indicators (similar to <code>dtv</code>).</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.remove_patterns!-Tuple{FileDocument,Regex}" href="#StringAnalysis.remove_patterns!-Tuple{FileDocument,Regex}"><code>StringAnalysis.remove_patterns!</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">remove_patterns!(d, rex)</code></pre><p>Removes from the document or corpus <code>d</code> the text matching the pattern described by the regular expression <code>rex</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.remove_patterns-Tuple{AbstractString,Regex}" href="#StringAnalysis.remove_patterns-Tuple{AbstractString,Regex}"><code>StringAnalysis.remove_patterns</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">remove_patterns(s, rex)</code></pre><p>Removes from the string <code>s</code> the text matching the pattern described by the regular expression <code>rex</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StringAnalysis.rowindices-Tuple{Array{String,1}}" href="#StringAnalysis.rowindices-Tuple{Array{String,1}}"><code>StringAnalysis.rowindices</code></a> â <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">rowindices(terms)</code></pre><p>Returns a dictionary that maps each term from the vector <code>terms</code> to a integer idex.</p></div></div></section><footer><hr/><a class="previous" href="../examples/"><span class="direction">Previous</span><span class="title">Usage examples</span></a></footer></article></body></html>
