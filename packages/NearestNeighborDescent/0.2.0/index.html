<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Readme Â· NearestNeighborDescent.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>NearestNeighborDescent.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Readme</a><ul class="internal"><li><a class="toctext" href="#Usage-1">Usage</a></li></ul></li><li><a class="toctext" href="autodocs/">Docstrings</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Readme</a></li></ul></nav><hr/><div id="topbar"><span>Readme</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="NearestNeighborDescent.jl-1" href="#NearestNeighborDescent.jl-1">NearestNeighborDescent.jl</a></h1><p><a href="https://travis-ci.com/dillondaudert/NearestNeighborDescent.jl"><img src="https://travis-ci.com/dillondaudert/NearestNeighborDescent.jl.svg?branch=master" alt="Build Status"/></a> <a href="https://ci.appveyor.com/project/dillondaudert/nearestneighbordescent-jl"><img src="https://ci.appveyor.com/api/projects/status/lr49p9vxkr8a3uv0?svg=true" alt="Build status"/></a>  <a href="https://codecov.io/gh/dillondaudert/NearestNeighborDescent.jl"><img src="https://codecov.io/gh/dillondaudert/NearestNeighborDescent.jl/branch/master/graph/badge.svg" alt="codecov"/></a> <a href="https://coveralls.io/github/dillondaudert/NearestNeighborDescent.jl?branch=master"><img src="https://coveralls.io/repos/github/dillondaudert/NearestNeighborDescent.jl/badge.svg?branch=master" alt="Coverage Status"/></a></p><p>Julia implementation of the nearest neighbor descent algorithm described in:</p><blockquote><p>Dong, Wei <em>et al.</em> Efficient K-Nearest Neighbor Graph Construction for Generic Similarity Measures. <em>WWW</em> (2011).</p></blockquote><h2><a class="nav-anchor" id="Usage-1" href="#Usage-1">Usage</a></h2><p>The <code>DescentGraph</code> constructor builds the approximate kNN graph:</p><pre><code class="language-jl">DescentGraph(data, n_neighbors, metric; max_iters, sample_rate, precision)</code></pre><ul><li><code>data</code>: The set of points to build the tree from. This must be of type</li></ul><p><code>Vector{V}</code>, where <code>V &lt;: AbstractVector</code> <strong>or</strong> <code>AbstractMatrix</code>.</p><ul><li><code>n_neighbors</code>: An integer specifies the number of neighbors to find</li><li><code>metric</code>: Any metric <code>M</code> where <code>M &lt;: SemiMetric</code> from the Distances.jl package. Default is <code>Euclidean()</code>.</li></ul><p>The performance of NN Descent can be tuned with several keyword arguments.</p><ul><li><code>max_iters</code>: This controls the maximum number of iterations to search for</li></ul><p>neighbors. Default is <code>10</code>.</p><ul><li><code>sample_rate</code>: The algorithm performs a local join around the candidate</li></ul><p>neighbors of each point during execution. The sample rate is the likelihood that each candidate be included in the local join for an iteration. Default is <code>1.</code>.</p><ul><li><code>precision</code>: This argument roughly corresponds to the fraction of true</li></ul><p>nearest neighbors that will be missed by the algorithm. Default <code>.001</code>.</p><p>The k-nearest neighbors can be accessed through the <code>indices</code> and <code>distances</code> attributes. These are both <code>KxN</code> matrices containing ids and distances to each point&#39;s neighbors, respectively, where <code>K = n_neighbors</code> and <code>N = length(data)</code>.</p><p>Example:</p><pre><code class="language-jl">using NearestNeighborDescent
data = [rand(10) for _ in 1:1000]
# OR data = rand(10, 1000)
n_neighbors = 5

# nn descent search
graph = DescentGraph(data, n_neighbors)

# access point i&#39;s jth nearest neighbor:
graph.indices[j, i]
graph.distances[j, i]</code></pre><p>Once constructed, the <code>DescentGraph</code> can be used to find the nearest neighbors to new points. This is done via the <code>search</code> method:</p><pre><code class="language-jl">search(graph, queries, n_neighbors, queue_size) -&gt; indices, distances</code></pre><ul><li><code>graph</code>: An instance of <code>DescentGraph</code></li><li><code>queries</code>: A vector of new data points of type <code>Vector{V}</code> or <code>AbstractMatrix</code>. </li></ul><p>Note that the dimensionality of the queries should match that of the data used to  originally construct the graph.</p><ul><li><code>n_neighbors</code>: The number of neighbors to find for each query. This does</li></ul><p><em>not</em> have to be the same as the number used to construct <code>graph</code>.</p><ul><li><code>queue_size</code>: Each query maintains a heap of candidate neighbors.</li></ul><p><code>queue_size</code> controls the maximum number of candidates as a multiple of <code>n_neighbors</code>. Default is <code>1.</code>.</p><p>Similar to <code>DescentGraph</code>, this returns two matrices for the indices and distances to the nearest neighbors of each query.</p><p>Example:</p><pre><code class="language-jl">queries = [rand(10) for _ in 1:100]
# OR queries = rand(10, 100)
idxs, dists = search(knngraph, queries, 4)</code></pre><footer><hr/><a class="next" href="autodocs/"><span class="direction">Next</span><span class="title">Docstrings</span></a></footer></article></body></html>
